{"id": 2270, "title": "Ticket #2270: spinning pie algorithm + preemption = unfair allocation", "description": "<blockquote>\nHere is a simple scenario in which the spinning pie algorithm does not converge to the expected fair share allocation.  In fact, it is wildly off.\n\n<p>1000 slots and 2 submitters: A &amp; B\n\n</p><p>At time T1, A &amp; B are running 501 and 499 jobs respectively and have steady-state priorities of the same (i.e. roughly equal shares of the pool but not exactly equal).\n\n</p><p>At time T2, the 1000 running jobs are still running and the priorities of the users have diverged sufficiently so that B could preempt A if B had any idle jobs.  User B submits 1000 more jobs.  Condor has free reign to preempt in order to reallocate resources to the fair share levels as quickly as possible (PREEMPTION_REQUIREMENTS = True).  What happens in the next negotiation cycle?\n\n</p><p>B preempts all of A's jobs and claims all 1000 slots.  This is not what I would expect!\n\n</p><p>This happens because in the first spin of the pie, A gets dropped from future consideration, because A has no more jobs that match.  Then in the second spin of the pie, B is alone and gets a computed \"fair share\" of 100%.\n\n</p><p>It seems that the intent of the spinning pie is to avoid portions of the pie going uneaten when some submitters have big enough appetites to keep eating.  However, as it iterates, it doesn't appear to correctly take into account portions of the pie that have already been dished out fairly.\n\n</p><p>I believe we have obscured this problem in the past by using PREEMPTION_REQUIREMENTS expressions that only allow preemption when the user priorities are sufficiently different that we are not surprised to see big shifts in resource allocation.  But this does not really solve the quirkiness of the allocation.\n\n</p><p>The current matchmaking algorithm also does not handle immediate resource allocation when a user with a worse priority currently has fewer than his fair share of resources claimed (e.g. user A in the negotiation cycle after the one described above where A loses everything).  We only allow preemption when the preempting user has better priority than the existing user, irrespective of whether the preempting user deserves more machines based on fair share considerations.  This is the case even if PREEMPTION_REQUIREMENTS is true.  We rely on the longer-term effect of user-priority decay to eventually promote the unfairly treated user to a position that allows preemption.</p></blockquote>", "remarks": "<blockquote>\n<em>2012-Dec-07 10:52:44 by danb:</em> <br/>\n\nAnother quirk relating to resource allocation and preemption: while in preempting state, the resources are counted towards the total usage by the preempted user and not at all towards the total use of the preempting user.  Therefore, if preemption lasts for longer than a matchmaking cycle, the preempting user may be given a bigger chunk of the pool than desired.  In the extreme case, this can lead to an oscillation in which the entire pool flops back and forth from one user to the other, rather than converging on the fair share ratio.  This effect also applies to the Claimed/Retiring state.  Since this state can last for considerable time, the problem can be quite noticeable.\n<hr/>\n<em>2013-Mar-28 17:16:00 by johnkn:</em> <br/>\n\nBulk change of target version from v070808 to v070809 using ./ticket-target-mover.</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "defect", "last_change": "2013-Mar-28 17:16", "status": "new", "created": "2011-Jun-27 10:23", "fixed_version": "2011-Jun-27 10:23", "broken_version": "v070000", "priority": "4", "subsystem": "", "assigned_to": "", "derived_from": "", "creator": "danb", "rust": "", "customer_group": "other", "visibility": "public", "notify": "dan@hep.wisc.edu eje@redhat.com matt@cs.wisc.edu tannenba@cs.wisc.edu", "due_date": ""}