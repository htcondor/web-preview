{"id": 3567, "title": "Ticket #3567: BMRB OSG jobs going on hold because of broken pipe", "description": "<blockquote>\nBMRB has been having problems with their OSG jobs going on hold, because of a broken pipe between the shadow and one of the daemons on the Condor-C end.  Here's an excerpt from the shadow log:\n\n<p></p><pre>  04/04/13 13:42:12 (3003831.0) (23066): put_file: going to send from filename\n/minnow/bbee/Rosetta_Server_V3/jobs/running_jobs_unb_/IkDapd/bins/IkDapd.abi\nnitio\n  04/04/13 13:42:12 (3003831.0) (23066): put_file: Found file size 565\n  04/04/13 13:42:12 (3003831.0) (23066): put_file: sending 565 bytes\n  04/04/13 13:42:12 (3003831.0) (23066): ReliSock: put_file: sent 565 bytes\n  04/04/13 13:42:12 (3003831.0) (23066): DoUpload: exiting at 2996\n  04/04/13 13:42:12 (3003243.0) (23259): Inside RemoteResource::updateFromStarter()\n  04/04/13 13:42:12 (3003812.0) (23030): condor_write() failed: send() 65536\nbytes to &lt;198.32.44.213:60472&gt; returned -1, timeout=0, errno=32 Broken pipe.\n  04/04/13 13:42:12 (3003812.0) (23030): ReliSock::put_bytes_nobuffer: Send\nfailed.\n  04/04/13 13:42:12 (3003812.0) (23030): ReliSock::put_file: failed to put\n65536 bytes (put_bytes_nobuffer() returned -1)\n  04/04/13 13:42:12 (3003812.0) (23030): DoUpload: exiting at 2951\n  04/04/13 13:42:12 (3003812.0) (23030): condor_read(): Socket closed when\ntrying to read 5 bytes from &lt;198.32.44.213:60472&gt;\n  04/04/13 13:42:12 (3003812.0) (23030): IO: EOF reading packet header\n  04/04/13 13:42:12 (3003812.0) (23030): Failed to receive download\nacknowledgment from &lt;198.32.44.213:60472&gt;.\n  04/04/13 13:42:12 (3003812.0) (23030): DoUpload: SHADOW at 144.92.167.254\nfailed to send file(s) to &lt;198.32.44.213:60472&gt;: error sending\n/minnow/bbee/Rosetta_Server_V3/jobs/running_jobs_unb_/IkDapd/bins/IkDapd.abi\nnitiobin\n</pre>\n\n<p>Jon at BMRB reports that if the jobs are condor_released, they normally run okay -- so it's not a problem with the job; maybe it's a problem on the execute machine.\n\n</p><p>It seems like there are at least two questions:\n</p><ol>\n<li>What's actually going wrong?\n</li><li>Should we put the jobs on hold in this case?\n</li></ol>\n\n<p>We're in the process of implementing a periodic_release expression that should work around this, but it seems like the underlying problem should get solved. I'm going to try to find out what's going on on the execute end...</p></blockquote>", "remarks": "<blockquote>\n</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "defect", "last_change": "2013-Apr-08 16:49", "status": "new", "created": "2013-Apr-08 16:49", "fixed_version": "2013-Apr-08 16:49", "broken_version": "v070807", "priority": "3", "subsystem": "Daemons", "assigned_to": "", "derived_from": "", "creator": "wenger", "rust": "", "customer_group": "other", "visibility": "public", "notify": "wenger@cs.wisc.edu", "due_date": ""}