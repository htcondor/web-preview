{"id": 6874, "title": "Ticket #6874: Speed up DAG recovery using a  'digest' mode in the event log reader", "description": "<blockquote>\nRecovering the state of a set of jobs by reading the job event log is slow.  This impacts both the python bindings (HTMap in particular), and DAGman recovery mode.\n\n<p>Josh Karpel has done some testing in python and has discovered that he can read the eventlog using ordinary fileio about 100x faster than by using the event reader class - this is because the reader class parses the events, but reading the file does not.\n\n</p><p>He wrote a bit of python code that reads the eventlog, parses only the headers and throws away all by the last event of each type for each cluster.proc.  His code then creates a digest of the event log containing only those events, and then parses that file using the event log reader.\n\n</p><p>The result is 4 to 5 times faster than just reading the whole event log with the event log reader.\n\n</p><p>This suggests that there is a large performance improvement possible to both HTMap and to DAGman recovery if we make something like this first class in the event log reader c++ classes.</p></blockquote>", "remarks": "<blockquote>\n<em>2019-Jan-18 20:49:15 by karpel:</em> <br/>\n\nHere's my test code:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">import timeit\n\nimport re\nfrom pathlib import Path\n\nimport htcondor\n\n\ndef get_events(path):\n    reader = htcondor.JobEventLog(Path(path).absolute().as_posix()).events(0)\n    return list(reader)\n\n\nreg = re.compile(r'(\\d\\d\\d) \\((\\d*).(\\d*).(\\d*)\\)')\n\n\ndef make_digest(input_path, output_path):\n    events = {}\n    current_event_lines = []\n\n    for line in Path(input_path).open(mode = 'r'):\n        if line.startswith('...'):\n            header = current_event_lines[0]\n            key = reg.search(header).groups()\n            events[key] = ''.join(current_event_lines)\n\n            current_event_lines = []\n        else:\n            current_event_lines.append(line)\n\n    Path(output_path).write_text('...\\n'.join(events.values()))\n\n\ndef make_and_read_digest(input_path, output_path):\n    make_digest(input_path, output_path)\n    get_events(output_path)\n\n\nmake_digest('event_log', 'digest')\nmake_and_read_digest('event_log', 'digest')\n\nN = 10\ntiming_kwargs = dict(\n    globals = globals(),\n    number = N,\n)\n\nraw = timeit.timeit(\n    \"get_events('event_log')\",\n    **timing_kwargs,\n)\ndigested = timeit.timeit(\n    \"make_and_read_digest('event_log', 'digest')\",\n    **timing_kwargs,\n)\n\nprint(f'raw: {raw / N:.6f} seconds')\nprint(f'digested: {digested / N:.6f} seconds')\n</pre></div>\n</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2020-Nov-09 10:53", "status": "new", "created": "2019-Jan-18 16:43", "fixed_version": "2019-Jan-18 16:43", "broken_version": "", "priority": "4", "subsystem": "Tools", "assigned_to": "johnkn", "derived_from": "", "creator": "johnkn", "rust": "", "customer_group": "other", "visibility": "public", "notify": "karpel@wisc.edu", "due_date": ""}