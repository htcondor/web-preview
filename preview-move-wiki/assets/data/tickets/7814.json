{"id": 7814, "title": "Ticket #7814: Fix test_custom_machine_resources.py", "description": "<blockquote>\nThis Ornithological test is currently disabled; fix it and enable it.\n\n<p></p><hr/>\nThis test not pass consistently in the BaTLab, maybe \"because job ads don't get update synchronously\".</blockquote>", "remarks": "<blockquote>\n<em>2020-Sep-08 10:59:57 by karpel:</em> <br/>\n\nThe part of this test that fails is <code>test_reported_usage_in_job_ads_makes_sense</code>. This is the most intricate part of the test: it tries to verify that the reported usage number is actually reasonable given the resource increments we set up in the configuration. All of the other parts of the test pass, and cover the \"user-facing\" part of the CMR API.\n\n<p>The failing part is much harder than it sounds, because there are a lot of things that can go slightly weird when calculating usage that end up showing up in the final number reported to the user. The main problems have to do with rounding the period between monitor triggers and how many triggers occur while the job is running (i.e., how many increments occur while the job is running). The test attempts to account for all of these effects deterministically and decide whether the usage number is reasonable. The test is occasionally failing because it looks we haven't accounted for all possible effects: the reported number is never actually \"unreasonable\", it just doesn't match one of the finite possibilities we have accounted for. The reported number seems to always be within the bounds set by the smallest and largest of the finite possibilities we generate.\n\n</p><p>Ultimately, this part of the test is trying to capture some of the gooey internals of the CMR code. I think it is debatable whether we should even test it to this level of specificity (though it was a fun exercise), since it is certainly implementation-dependent. Given that, what <strong>should</strong> we test here? I think we want some kind of test that checks that the usage is within reasonable bounds given the setup.\n\n</p><p></p><hr/>\n<em>2020-Sep-09 09:41:12 by tlmiller:</em> <br/>\n\nI would rather only test for the specific values that we know are actually being reported by the monitor(s); the Perl test's approach was the smallest set of specific values that could be right.\n\n<p>Since I don't trust coincidences, I'd like to understand why we're seeing the values we are, rather than just hope for the best.\n\n</p><p></p><hr/>\n<em>2020-Sep-09 09:45:15 by karpel:</em> <br/>\n\nJust remember what \"because job ads don't get update synchronously\" was about...\n\n<p>Occasionally, the test fails because the <code>AssignedXXX</code> attribute is missing from job ads in the query. That is, the job would run, but the job ad wouldn't be updated with CMR information. That error was fairly ephemeral, presumably only occurring under high load (I only ever saw it in the batlab). If it crops up again, the jobs may need to run for longer to allow time for updates to propagate through the system.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "defect", "last_change": "2020-Sep-09 09:45", "status": "new", "created": "2020-Aug-25 19:07", "fixed_version": "2020-Aug-25 19:07", "broken_version": "", "priority": "3", "subsystem": "Tests", "assigned_to": "tlmiller", "derived_from": "#7811", "creator": "tlmiller", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tlmiller@cs.wisc.edu", "due_date": ""}