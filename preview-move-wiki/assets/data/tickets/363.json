{"id": 363, "title": "Ticket #363: Condor HDFS daemons should publish info to the collector", "description": "<blockquote>\nThe <code>condor_hdfs</code> daemons should publish a classad to the collector with interesting info.\n\n<p>Some ideas to get the juices flowing\n</p><ul>\n<li>Name node, backup name node, or data node?\n</li><li>Resource (disk space, RAM usage) utilization, etc.\n</li><li>Addresses\n</li><li>Performance Info (num of transfers in progress, etc)\n</li><li>Backup Info (time of last checkpoint, etc)\n</li></ul>\n\n<p>What else?</p></blockquote>", "remarks": "<blockquote>\n<em>2009-Jun-02 20:51:32 by faisal:</em> <br/>\n\nA new version of HDFS daemon is now in repository that is pushing following information to the collector along with the standard daemon ads.\n\n<p>Name-node:\n</p><ul>\n<li>IP/Port\n</li></ul>\n\n<p>Data-node:\n</p><ul>\n<li>IP/Port\n</li><li>Protocol version\n</li><li>State (running or stopped)\n</li><li>Blocks (Number of data blocks stored on a particular datanode)\n</li><li>Storage information (total, used and remaining capacity), updated regularly\n</li><li>&lt;More statistics to come here&gt;\n</li></ul>\n\n<p>I guess folks at Cycle Computing may be interested to tell us about other useful information that we can throw to collector. We are looking at consuming information related to file block location as rank expressions based on some previous work involving Condor and SAMGrid. I still need to talk to Todd T. about the implementation of SAMGrid work.\n\n</p><p></p><hr/>\n<em>2010-Oct-07 00:23:34 by ilikhan:</em> <br/>\n\nIn current implementation collector is informed about following data:\n\n<p><span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ServiceType\" title=\"Service Type\">ServiceType</a></span>: <br/>\n\nSafemode: ON/OFF <br/>\n\nConfigured Capacity:<br/>\n\nPresent Capacity:<br/>\n\nDFS Remaining:<br/>\n\nDFS Used:<br/>\n\nDFS Used%:<br/>\n\nUnder replicated blocks:<br/>\n\nBlocks with corrupt replicas:<br/>\n\nMissing blocks:<br/>\n\nDatanodes available:<br/>\n\n\n</p><p>for details see check-in <span class=\"chng\"><a href=\"chngview?cn=18681\">[18681]</a></span> and ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1547\" onclick=\"get_ticket_and_populate_wrapper('1547'); return false;\" title=\"Add reporting functionality of condor_hdfs\">#1547</a></span>.\n\n</p><p><strong>If no objection, I am marking this ticket as resolved.</strong>\n\n</p><p></p><hr/>\n<em>2010-Oct-07 01:01:01 by ilikhan:</em> <br/>\n\nFor additional, the other the ones I listed above, we should use C API that comes with Hadoop distribution. However, after some talk with Greg T, we decided NOT to use C API, at least for now.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jun-03 14:35</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14828\">[14828]</a></span>: Handle data types when publishing <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>) in hdfs daemon (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 19:39</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14754\">[14754]</a></span>: (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) Cleanly handled termination code from hadoop process. A basic substrate to publish <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> from Hadoop (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>). This commit also handles upgrading hadoop jar files to a newer version.  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 19:25</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14753\">[14753]</a></span>: Revert \"Cleanly handled termination code from hadoop process. A basic substrate to publish <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> from Hadoop (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>).\" There were few changes made by Greg on Master branch that I didn't realize when making this commit. This reverts commit e716f7d7f26578d5f7ee45f0f69e21566a84370a.  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 18:54</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14752\">[14752]</a></span>: Cleanly handled termination code from hadoop process. A basic substrate to publish <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> from Hadoop (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>). This commit also handles upgrading hadoop jar files to a newer version.  (By faisal )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2010-Nov-19 11:19", "status": "resolved", "created": "2009-Apr-06 14:12", "fixed_version": "2009-Apr-06 14:12", "broken_version": "", "priority": "4", "subsystem": "", "assigned_to": "faisal", "derived_from": "#4", "creator": "tannenba", "rust": "", "customer_group": "other", "visibility": "public", "notify": "jstowe@cyclecomputing.com,tannenba@cs.wisc.edu,achevignard@cyclecomputing.com,faisal@cs.wisc.edu", "due_date": ""}