{"id": 7315, "title": "Ticket #7315: Additional S3 improvements", "description": "<blockquote>\nAfter talking to a few folks around CHTC - and demoing what we have done for S3 integration, a number of solid ideas for future improvements have come about.  I'll write them into this ticket - but once we are ready to work on these, they really ought to be separate tickets.\n\n<p></p><ol>\n<li>\"Process each object in a bucket\" - that is, have a straightforward mechanism to generate a job per object in a given S3 bucket.\n</li><li>\"Transfer in all files to a S3 bucket\" - Lauren mentioned some user fan-out / fan-in DAGs may result in 100 output files from the \"fan out\" step all needing to be downloaded by a single \"fan-in\" job.  As it is today, users would need to list out 100 S3 URLs to accomplish this.\n</li><li>\"Check credentials early\" - try issuing a HEAD against a presigned URL to verify the credentials are valid <strong>prior</strong> to submitting jobs to the queue.\n</li><li>\"Check space early\" - As a part of (3), record the resulting file size and ensure request_disk is sufficiently large to transfer the input sandbox.\n</li><li>\"Allow default key files\" - add a config knob for each key file.\n</li></ol>\n\n<p>(Feel free to add other user-facing ideas...)</p></blockquote>", "remarks": "<blockquote>\n</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2019-Oct-11 14:40", "status": "new", "created": "2019-Oct-10 14:15", "fixed_version": "2019-Oct-10 14:15", "broken_version": "", "priority": "4", "subsystem": "", "assigned_to": "bbockelm", "derived_from": "", "creator": "bbockelm", "rust": "", "customer_group": "chtc", "visibility": "public", "notify": "bbockelman@morgridge.org tannenba@cs.wisc.edu tlmiller@cs.wisc.edu dabrown@syr.edu", "due_date": ""}