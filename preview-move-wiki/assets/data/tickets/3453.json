{"id": 3453, "title": "Ticket #3453: improve scheduling of condor_q processing in the schedd", "description": "<blockquote>\nThe schedd responds to condor_q queries in the same stream of requests as all other queue management commands.  It does not prioritize or schedule how it processes this stream.  It just responds to each command in the order they are received.  A burst of condor_q queries can therefore interfere with the processing of other commands, and can even cause the processing of running and completed jobs to fail.\n\n<p>We propose that if the schedd has been configured to fork sub-processes to handle read-only queries (i.e. condor_q), then when the maximum number of sub-processes has been reached, it should not process further read-only commands in the main process.  It should queue them, up to some limit.  During this time, it should continue to process other commands (such as queue management write commands).  This will have the effect of smoothing out bursts of condor_q queries or even chopping off the peak of the burst if it exceeds the request queue depth.\n\n</p><p>Some changes to the client may be needed to avoid timing out too quickly while in the request queue.\n\n</p><p>Some workarounds that may help in the current situation:\n\n</p><p></p><ul>\n<li>increase the time between updates of running jobs (SHADOW_QUEUE_UPDATE_INTERVAL and job_lease_duration).  This should reduce the rate at which copy-on-write causes pages to be unshared between the main schedd process and forked children.\n\n<p></p></li><li>increase SCHEDD_QUERY_WORKERS if there is enough memory (if not, get more memory)\n\n<p></p></li><li>find alternatives to condor_q, such as reading the user log to track job state\n</li></ul>\n\n<p>A longer-term solution would involve responding to queries without blocking the main process and without forking a sub-process, but we do not propose implementing that at this time.\n\n</p><p>This plan came out of a discussion with Todd, Jaime, Greg, TJ, and me (Dan).</p></blockquote>", "remarks": "<blockquote>\n<em>2013-Jan-22 18:05:20 by sfiligoi:</em> <br/>\n\nWhat are the downsides of making\n<div class=\"code\">\n<pre class=\"code\">SHADOW_QUEUE_UPDATE_INTERVAL</pre></div>\n\nreally big?\n\n<p>Just the fact that some descriptive attributes will be propagated with significant delay?<br/>\n\nOr will it also affect shadow reporting on job state changes?\n\n</p><p></p><hr/>\n<em>2013-Jan-23 18:29:55 by bbockelm:</em> <br/>\n\nMaybe the idea is too wild, but what about handing local condor_q instances a read-only file descriptor to the job log via unix domain sockets?\n\n<p>That way, the processing is done in the condor_q process (like Igor's user log patch) instead of in the schedd.\n\n</p><p></p><hr/>\n<em>2013-Jan-25 09:12:31 by sfiligoi:</em> <br/>\n\n@Brian:\n\n<p>Would not help... we still have condor_q from remote to deal with.\n\n</p><p></p><hr/>\n<em>2013-Jan-25 09:35:06 by sfiligoi:</em> <br/>\n\nOne more request:<br/>\n\nCan we prioritize authenticated requests ahead of unauthenticated ones?\n\n<p>We like to allow unauthenticated read access for debugging purposes, but this should not impact the main functionality of the system.\n\n</p><p></p><hr/>\n<em>2015-Aug-01 21:09:16 by bbockelm:</em> <br/>\n\nI believe the V3 protocol implements most of the goals of this ticket (except it doesn't have a queued query limit).  Marking as resolved for now.</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "enhance", "last_change": "2015-Aug-01 21:09", "status": "resolved", "created": "2013-Jan-22 17:52", "fixed_version": "2013-Jan-22 17:52", "broken_version": "v070904", "priority": "4", "subsystem": "", "assigned_to": "", "derived_from": "", "creator": "danb", "rust": "s8251", "customer_group": "cms", "visibility": "public", "notify": "isfiligoi@ucsd.edu,dan@hep.wisc.edu,tstclair@redhat.com", "due_date": ""}