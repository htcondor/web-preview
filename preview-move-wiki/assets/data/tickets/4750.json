{"id": 4750, "title": "Ticket #4750: Excessive port usage when using shared port and CCB (HIGHPORT/LOWPORT)", "description": "<blockquote>\nThis problem probably affects version earlier than 8.2.2, but that's the earliest version I've confirmed.\n\n<p>In the following scenario, the shared port daemon will rapidly become unable to forward/complete (CCB) connections.  I'm not sure what those connections do, but the visible symptom is slots falling out of the claimed status for no discernible reason.  <code>condor_shared_port</code> will fail to forward/complete connections because it can't bind a port when it calls connect_socketpair(), which it does under certain circumstances.  The following log snippet demonstrates the problem:\n\n</p><p></p><div class=\"verbatim\">\n<pre>12/03/14 11:40:58 CCBListener: received request to connect to STARTER\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;\nsock=24920_24ee_651&gt; on &lt;128.104.103.7:34013&gt; with reverse connect address\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;\nsock=28485_025f_3&gt;, request id 6536.\n12/03/14 11:40:58 Bypassing connection to shared port server\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&gt;,\nbecause that is me.\n12/03/14 11:40:58 get_port_range - (LOWPORT,HIGHPORT) is (9700,9800).\n12/03/14 11:40:58 Sock::bindWithin - failed to bind to port 9739: Address already in use\n...\n12/03/14 11:40:58 Sock::bindWithin - failed to bind any port within (9700 ~ 9800)\n12/03/14 11:40:58 connect_socketpair: failed in tmp_srv.bind()\n12/03/14 11:40:58 CLOSE &lt;128.104.103.7:0&gt; fd=14\n12/03/14 11:40:58 Failed to connect to loopback socket, so failing to connect\nvia local shared port access to daemon at &lt;128.104.103.7:9787&gt;.\n12/03/14 11:40:58 CLOSE &lt;128.104.103.7:9730&gt; fd=13\n12/03/14 11:40:58 CCBListener: failed to create reversed connection for request\nid 6536 to &lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3\n&amp;sock=28485_025f_3&gt;: failed to initiate connection\n</pre></div>\n\n\n<p>where \"because that is me\" <em>appears</em> to mean that the reverse address (\"call me back at this number\") includes the same shared port daemon as is currently doing the CCB reversal.  Do not depend on this analysis.\n\n</p><p>GregT suggests the problem is that connect_socketpair() is creating a socket either without SO_LINGER set to false (which I'm not sure is possible in our codebase), or perhaps SO_REUSEADDR (which is normally only set for command ports).  There may (also?) be another problem where we don't close sockets properly as part of our normal operation -- as far as I can tell, things are working as expected before this problem occurs.\n\n</p><p>The scenario is as follows: I have a central manager with a schedd and an execute node.  The execute node is configured to use CCB and shared port, and has HIGHPORT and LOWPORT set to a range of 100 ports.  (This generally seems to be sufficient for normal operation in the BaTLab.) This configuration is useful for testing, but it also currently our only way of specifying a range of ports for the shared port daemon to choose from, which is useful for glide-ins.  I submit 300 10-second sleep jobs; the execute node has 24 slots.  After about 100 jobs, this problem appears, and 'netstat' is full of sockets in TIME_WAIT.\n\n</p><p>The following message appears in the shadow logs:\n\n</p><p></p><div class=\"verbatim\">\n<pre>12/03/14 11:40:58 (240.99) (22376): ERROR \"Error from slot1@exec-7.batlab.org:\nFAILED TO SEND INITIAL KEEP ALIVE TO OUR PARENT\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;sock=24917_34bc_3&gt;\" at line 558\nin file /home/tlmiller/condor/source/src/condor_shadow.V6.1/pseudo_ops.cpp\n</pre></div>\n\n\n<p>and the following in slot 1's starter log:\n\n</p><p></p><div class=\"verbatim\">\n<pre>12/03/14 11:40:58 (pid:28501) CCBClient: received failure message from CCB server collector\n128.104.100.22:9764?noUDP&amp;sock=collector in response to request for reversed connection to daemon at\n&lt;128.104.103.7:9787&gt;: failed to initiate connection\n12/03/14 11:40:58 (pid:28501) Failed to reverse connect to daemon at &lt;128.104.103.7:9787&gt; via CCB.\n12/03/14 11:40:58 (pid:28501) ChildAliveMsg: failed to send DC_CHILDALIVE to parent daemon at\n&lt;128.104.103.7:9787&gt; (try 1 of 3): CEDAR:6001:Failed to connect to\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;sock=24917_34bc_3&gt;\n...\n12/03/14 11:40:58 (pid:28501) ChildAliveMsg: failed to send DC_CHILDALIVE to parent daemon at\n&lt;128.104.103.7:9787&gt; (try 3 of 3): CEDAR:6001:Failed to connect to\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3\nsock=24917_34bc_3&gt;|CEDAR:6001:Failed to connect to\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3sock=24917_34bc_3&gt;|CEDAR:6001:Fail\ned to connect to &lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;\nsock=24917_34bc_3&gt;\n12/03/14 11:40:58 (pid:28501) ERROR \"FAILED TO SEND INITIAL KEEP ALIVE TO OUR PARENT\n&lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;sock=24917_34bc_3&gt;\" at line 9470\nin file /slots/11/dir_20050/userdir/src/condor_daemon_core.V6/daemon_core.cpp\n</pre></div>\n\n\n<p>Which suggests that the starter is using CCB to send its child alive and the log message from the shared port daemon is erroneous or mistaken.  (It should say 'STARTD', but that ID is supplied by the client, IIRC, so the fix may be simple.)\n\n</p><p>The startd's command socket <em>is</em> &lt;128.104.103.7:9787?CCBID=128.104.100.22:9764%3fnoUDP%26sock%3dcollector#3&amp;\nsock=24917_34bc_3&gt;.  Its log contains:\n\n</p><p></p><div class=\"verbatim\">\n<pre>12/03/14 11:40:58 slot1: Remote job ID is 240.99\n12/03/14 11:40:58 slot1: Got universe \"VANILLA\" (5) from request classad\n12/03/14 11:40:58 slot1: State change: claim-activation protocol successful\n12/03/14 11:40:58 slot1: Changing activity: Idle -&gt; Busy\n...\n12/03/14 11:40:58 Starter pid 28501 exited with status 4\n12/03/14 11:40:59 slot1: State change: starter exited\n12/03/14 11:40:59 slot1: Changing activity: Busy -&gt; Idle\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "defect", "last_change": "2015-Feb-04 10:11", "status": "new", "created": "2014-Dec-03 14:52", "fixed_version": "2014-Dec-03 14:52", "broken_version": "v080202", "priority": "4", "subsystem": "DaemonsExecNode", "assigned_to": "", "derived_from": "", "creator": "tlmiller", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tlmiller@cs.wisc.edu", "due_date": ""}