{"id": 5034, "title": "Ticket #5034: Frequent schedd crashes on CMS global pool", "description": "<blockquote>\nFrom different parts of the code, but it seems that some failure-handling logic in DC message is resulting in an ASSERT instead of an error for the job.  I copied the two most common crash reasons below.\n\n<p>I suspect this host is running out of ephemeral ports (seems to happen at around 14k running jobs).\n\n</p><p>Example 1:\n\n</p><p></p><div class=\"verbatim\">\n<pre>04/30/15 11:40:34 (pid:743706) Sock::bind failed: errno = 98 Address already in use\n04/30/15 11:40:34 (pid:743706) Failed to send CCB_REQUEST to collector (IP):9834: CEDAR:6001:Failed to connect to &lt;(IP):9834&gt;\n04/30/15 11:40:34 (pid:743706) CCBClient: no more CCB servers to try for requesting reversed connection to startd glidein_14481_97204565@cabinet-6-6-8.t2.ucsd.edu &lt;(IP):42020?CCBID=(IP):9834#300757%20(IP):9834#296736&amp;noUDP&gt; for production.cmsdataops; giving up.\n04/30/15 11:40:34 (pid:743706) CallSocketHandler: called on non-registered socket!\n04/30/15 11:40:34 (pid:743706) Offending socket number -1\n04/30/15 11:40:34 (pid:743706) Failed to send RELEASE_CLAIM to startd glidein_14481_97204565@cabinet-6-6-8.t2.ucsd.edu &lt;(IP):42020?CCBID=128.142.141.17:9834#300757%20(IP):9834#296736&amp;noUDP&gt; for production.cmsdataops: SECMAN:2003:TCP connection to startd glidein_14481_97204565@cabinet-6-6-8.t2.ucsd.edu &lt;(IP):42020?CCBID=(IP):9834#300757%20(IP):9834#296736&amp;noUDP&gt; for production.cmsdataops failed.\n04/30/15 11:40:34 (pid:743706) Match record (glidein_14481_97204565@cabinet-6-6-8.t2.ucsd.edu &lt;(IP):42020?CCBID=(IP):9834#300757%20(IP):9834#296736&amp;noUDP&gt; for production.cmsdataops, 18658.52) deleted\n04/30/15 11:40:34 (pid:743706) Shadow pid 1127333 for job 18319.74 exited with status 100\n04/30/15 11:40:38 (pid:743706) ERROR \"Assertion ERROR on (!m_callback_msg.get())\" at line 321 in file /slots/03/dir_59220/userdir/src/condor_daemon_client/dc_message.cpp\n</pre></div>\n\n\n<p>Example 2:\n\n</p><p></p><div class=\"verbatim\">\n<pre>04/30/15 15:24:48 (pid:1035854) actOnJobs: couldn't send results to client: aborting\n04/30/15 15:24:51 (pid:1035854) Sock::bind failed: errno = 98 Address already in use\n04/30/15 15:24:51 (pid:1035854) ChildAliveMsg: failed to send DC_CHILDALIVE to parent daemon at &lt;(IP):4080&gt; (try 1 of 3): CEDAR:6001:Failed to connect to &lt;(IP):4080?noUDP&amp;sock=2094529_9234&gt;\n04/30/15 15:24:53 (pid:1035854) condor_write(): Socket closed when trying to write 265 bytes to &lt;(IP):50966&gt;, fd is 751\n04/30/15 15:24:53 (pid:1035854) Buf::write(): condor_write() failed\n04/30/15 15:24:53 (pid:1035854) actOnJobs: couldn't send results to client: aborting\n04/30/15 15:24:53 (pid:1035854) Shadow pid 1047791 for job 22969.31 exited with status 100\n04/30/15 15:24:55 (pid:1035854) condor_write(): Socket closed when trying to write 265 bytes to &lt;(IP):52639&gt;, fd is 823\n04/30/15 15:24:55 (pid:1035854) Buf::write(): condor_write() failed\n04/30/15 15:24:55 (pid:1035854) actOnJobs: couldn't send results to client: aborting\n04/30/15 15:24:55 (pid:1035854) condor_write(): Socket closed when trying to write 265 bytes to &lt;(IP):51132&gt;, fd is 716\n04/30/15 15:24:55 (pid:1035854) Buf::write(): condor_write() failed\n04/30/15 15:24:55 (pid:1035854) actOnJobs: couldn't send results to client: aborting\n04/30/15 15:24:55 (pid:1035854) condor_write(): Socket closed when trying to write 265 bytes to &lt;(IP):51146&gt;, fd is 1104\n04/30/15 15:24:55 (pid:1035854) Buf::write(): condor_write() failed\n04/30/15 15:24:55 (pid:1035854) actOnJobs: couldn't send results to client: aborting\n04/30/15 15:24:55 (pid:1035854) condor_write(): Socket closed when trying to write 265 bytes to &lt;(IP):51141&gt;, fd is 1125\n04/30/15 15:24:55 (pid:1035854) Buf::write(): condor_write() failed\n04/30/15 15:24:55 (pid:1035854) actOnJobs: couldn't send results to client: aborting\n04/30/15 15:24:56 (pid:1035854) ERROR \"Assertion ERROR on (!m_callback_msg.get())\" at line 321 in file /slots/03/dir_59220/userdir/src/condor_daemon_client/dc_message.cpp\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2015-Apr-30 08:41:02 by bbockelm:</em> <br/>\n\nNote:\n<ul>\n<li>This host has ephemeral ports set to 1024-65535\n</li><li>On the CMS global pool, so using shared_port &amp; CCB.\n</li><li>Here's a graph of the number of sockets in time-wait: <a class=\"external\" href=\"http://hcc-ganglia.unl.edu/graph_all_periods.php?c=crab-infrastructure&amp;h=vocms0310.cern.ch&amp;r=hour&amp;z=small&amp;jr=&amp;js=&amp;st=1430401174&amp;event=hide&amp;ts=0&amp;v=3545&amp;m=tcp_timewait&amp;vl=Sockets&amp;ti=tcp_timewait&amp;z=large\">http://hcc-ganglia.unl.edu/graph_all_periods.php?c=crab-infrastructure&amp;h=vocms0310.cern.ch&amp;r=hour&amp;z=small&amp;jr=&amp;js=&amp;st=1430401174&amp;event=hide&amp;ts=0&amp;v=3545&amp;m=tcp_timewait&amp;vl=Sockets&amp;ti=tcp_timewait&amp;z=large</a>\n<ul>\n<li>I think the ephemeral port usage is non-condor.\n</li></ul>\n</li></ul>\n\n<p></p><hr/>\n<em>2015-Apr-30 11:03:13 by bbockelm:</em> <br/>\n\nFurther updates:\n\n<p>Ephemeral ports were being exhausted by condor itself.  There was an external component doing a <code>condor_qedit</code> once every 5 minutes to adjust priorities.  The schedd sends a signal to the shadow (one short-lived TCP connection) and the shadow sends a <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=JobAction\" title=\"Job Action\">JobAction</a></span> to clear dirty attributes back to the schedd (a second short-lived TCP connection).\n\n</p><p>For now, I'm adjusting the constraint on <code>condor_qedit</code> to exclude jobs where the job priority is unchanged.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "incident", "last_change": "2017-Jul-12 15:59", "status": "new", "created": "2015-Apr-30 08:36", "fixed_version": "2015-Apr-30 08:36", "broken_version": "", "priority": "3", "subsystem": "DaemonsSubmitNode", "assigned_to": "", "derived_from": "", "creator": "bbockelm", "rust": "", "customer_group": "cms", "visibility": "public", "notify": "bbockelm@cse.unl.edu tannenba@cs.wisc.edu", "due_date": ""}