{"id": 1587, "title": "Ticket #1587: Problems with semantics of failed file transfer", "description": "<blockquote>\nNumber 1 should be in V7_4-branch, all other stuff in master branch.\n\n<p></p><ol>\n<li>it is a flat out bug that the <span class=\"quote\">ExitStatus</span>, <span class=\"quote\">ExitSignal</span>, and <span class=\"quote\">ExitedBySignal</span> attributes are not set when file transfer fails.  these attributes must be propagated into the job ad so the user can see them and make policy decisions using on_exit_hold and on_exit_remove. <strong>[DONE]</strong>\n\n<p></p></li><li>the behavior of transfer_output_files will change so that a failure does not\nput the job on hold.  (if the user desires this, they will be able to implement\nit using the on_exit_hold expression in the submit file... see items 3 and 4)\n\n<p></p></li><li>each file that is successfully transferred is added to a list of \"Good Files\"\nin the job ad.  each file that fails to transfer will be added to the list of\n\"Bad Files\" in the job ad.\n\n<p></p></li><li>using these lists, users can specify what should happen when errors occur.\n\n<p></p></li><li>if a file fails to be transferred for any reason other than not existing, the job will still go on hold as this is a system failure, not a problem with the job.  in this case condor should increment <span class=\"quote\">NumSystemHolds</span> for the job, which it currently does not.\n</li></ol>\n\n<p>to recreate the behavior we have today, you would simply add a line like this to the submit file:\n</p><div class=\"code\">\n<pre class=\"code\">  on_exit_hold == (BadFilesList != \"\")\n</pre></div>\n\n\n<p>(that is, if there are any files in the bad files list, put the job on hold, which is what happens now)\n\n</p><p>Additional:\n\n</p><p></p><ol>\n<li>The output files should be brought back smallest to largest first. If it is\neasy to specify an arbitrary ordering as well, then do it.</li></ol>\n</blockquote>", "remarks": "<blockquote>\n<em>2010-Aug-19 16:27:02 by psilord:</em> <br/>\n\nOk, implementing number 1 in 7.4 correctly is a non-backwards compatible rathole. To implement it incorrectly would require a <strong>terrible</strong> hack that would be a nasty surprise for someone in the future and difficult to maintain.\n\n<p>The reason is that in <code>JICShadow::transferOutput()</code> when the file transfer fails (and it doesn't know if it is a critical error or recoverable error!), we call <code>notifyStarterError()</code> passing in the hold reason, hold code, hold subcode and enforcing that it is a critical error. This call ends up calling <code>REMOTE_CONDOR_ulog()</code> in the starter with the hold information.\n\n</p><p>When the shadow sees the critical hold request via the pseudo op ulog, it updates the job ad with the hold information from the network packet, updates the schedd with the new ad, then <strong>immediately</strong> exits with the <code>JOB_SHOULD_HOLD</code> code for the schedd. At this point there is no opportunity to inject the exit information of the job into the job ad.\n\n</p><p><strong>One would think</strong> the correct way to fix this would be to implement a new pseudo call which simply updates whatever attributes in the sent ad into the job ad and commits it. Then I could call this just before <code>notifyStarterError()</code> and things would be happy. <strong>HOWEVER</strong> Doing this allows a race condition that if\nafter the update from the starter to the shadow about the job exit status, then if the file transfer fails and both daemons are taken down, the schedd thinks the job completed successfully. Bad.\n\n</p><p>But, if this is in the stable series, then I can't change the protocol between the starter and the shadow. So, the nasty hack would be to encode the exit status of the job into the hold reason string, and decode it on the shadow side, if present, and insert the attributes into the job ad along with the hold attributes and continue. This probably still suffers from the race condition mentioned above if the shadow manages to update the jobad in the schedd and die badly before exiting with <code>JOB_SHOULD_HOLD</code>.\n\n</p><p></p><hr/>\n<em>2010-Aug-19 16:29:54 by psilord:</em> <br/>\n\nAnother bad idea would be to touch all of the output files at the job completion so the file transfer couldn't fail at all due to nonexistence. This is bad because if the job core dumped, we touch all of its files, then it would leave the queue totally. This is different behavior that what 1 implies. Which is the job still goes on hold, but the exit information is still injected into the ad.\n\n<p></p><hr/>\n<em>2010-Aug-19 16:31:32 by psilord:</em> <br/>\n\nI'm going to explore making the file transfer failure a non-critical error and see what happens.\n\n<p></p><hr/>\n<em>2010-Aug-19 16:42:32 by psilord:</em> <br/>\n\nI tried it and it won't work. ANY hold event from the starter to the shadow results in the shadow exiting ASAP.\n\n<p></p><hr/>\n<em>2010-Aug-20 10:36:57 by psilord:</em> <br/>\n\nOk, new tactic. I'm going to expand the interface to <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RemoteErrorEvent\" title=\"Remote Error Event\">RemoteErrorEvent</a></span> to include\nthe exit information. Then, an updated starter and shadow can correctly serialize\nthe exit information across the ulog pseduo call. For updated starters and old\nshadows, the old shadow will simply ignore the new information in the serialized classad instance of the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RemoteErrorEvent\" title=\"Remote Error Event\">RemoteErrorEvent</a></span> and work as usual. This allows backwards compatibility in the stable series.\n\n<p></p><hr/>\n<em>2010-Aug-20 14:11:22 by psilord:</em> <br/>\n\nOk, expanding the interface wasn't a good idea.\n\n<p>I found REMOTE_CONDOR_set_job_attr() as a method of the starter setting job attrs in the jobad of the shadow. So I'm exploring that now.\n\n</p><p></p><hr/>\n<em>2010-Aug-24 13:30:33 by psilord:</em> <br/>\n\nOk, I have a different method, this one looks far better:\n\n<p></p><ol>\n<li>In <code>JICShadow::transferOutput()</code>, decouple the handling of the failed transfer from the transfer itself. Put the handling of the failed transfer in to a new function called <code>JICShadow::transferOutputMopUp()</code>.\n</li><li>Add a new remote system call in <code>NTsenders.cpp</code> which transmits the exit status of the job over to the shadow which calls <code>updateJob(U_TERMINATE)</code> with the information. This sets the process specific termination attributes in the job ad, but this code path will not treat the job as having exited wrt terminate events in the job log, etc, etc, etc.\n</li><li>In if <code>JICShadow::transferOutput()</code> fails, then if the shadow is of 7.4.4 or later, then send the new remote system call if the transfer failed due to the job having exited and not produced the whole of the <code>transfer_output_files</code> set. Then call <code>JICShadow::transferOutputMopUp()</code> which will notify the shadow of the failure and cause the shadow to drop the connection to the starter.\n</li></ol>\n\n<p></p><hr/>\n<em>2010-Aug-26 11:26:42 by psilord:</em> <br/>\n\nOk, the last proposal seems to be the right method. I've implemented the starter side, and am now just implementing the shadow side of what to do when it gets this termination information from the job.\n\n<p> Other than a nagging question of how to handle the <strong>list</strong> of jobs under the starter (like how do I know I picked the right job's exit status?) I think I'm on the downhill slide to completion.\n\n</p><p></p><hr/>\n<em>2010-Aug-30 16:05:06 by psilord:</em> <br/>\n\nI can pick the right job out of the list by looking for the published ad from the\nuser proc which contains ATTR_JOB_PID. All other jobs which are not the main job, like the pre/post scripts or condor_ssh, will name mangle that attribute name. A bit circuitous, but sufficient.\n\n<p></p><hr/>\n<em>2010-Aug-30 16:32:13 by psilord:</em> <br/>\n\nI had a little bit of a crappy merge with the master code. Hopefully it is all fixed up.\n<hr/>\n<em>2010-Oct-20 16:03:30 by jfrey:</em> <br/>\n\nBulk change of target version from v070504 to v070505 using ./ticket-target-mover.\n\n<p></p><hr/>\n<em>2010-Nov-01 15:34:26 by danb:</em> <br/>\n\nI think that the changes in commit b3ef6289 <span class=\"chng\"><a href=\"chngview?cn=18897\">[18897]</a></span> to improve handling of file transfer failures have somewhat broken disconnected shadow/starter handling.\n\n<p>The changes were intended to improve handling of the case where file transfer fails and wants to put the job on hold.  However, there are other types of failures (such as network disconnect) where file transfer can fail without trying to put the job on hold.  These cases used to be handled by  the shadow/starter disconnect behavior.  Now, the starter just blows up in an assert:\n\n</p><p></p><div class=\"verbatim\">\n<pre>11/01 14:58:57 Sandbox transfer failed.\n11/01 14:58:57 ERROR \"Assertion ERROR on (m_ft_info.hold_code != 0)\" at line 435 in file jic_shadow.cpp\n</pre></div>\n\n\n<p>I see the following responsible code:\n\n</p><p></p><div class=\"verbatim\">\n<pre>if(!m_ft_info.success) {\n   ASSERT(m_ft_info.hold_code != 0);\n}\n</pre></div>\n\n\n<p>One way to test this code path is to SIGSTOP the shadow while the job is running.  Then when the job finishes and the starter is blocked waiting for a response to its file transfer request, do condor_off -schedd.  The desired behavior is that the starter sees the connection to the shadow go bad and enters disconnected mode.  Turning the schedd back on should cause a new shadow to connect to the starter and successfully finish the file transfer.  I have verified that this worked in 7.4.2.\n\n</p><p>I have made a child ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1750\" onclick=\"get_ticket_and_populate_wrapper('1750'); return false;\" title=\"disconnect during file transfer causes starter to abort\">#1750</a></span> for the disconnect bug.\n</p><hr/>\n<em>2011-Jan-27 14:46:04 by danb:</em> <br/>\n\nBulk change of target version from v070505 to v070506 using ./ticket-target-mover.\n<hr/>\n<em>2011-Feb-01 16:19:13 by tannenba:</em> <br/>\n\nBulk change of target version from v070506 to NULL using ./ticket-target-mover.\n\n<p></p><hr/>\n<em>2011-Mar-31 17:10:20 by zmiller:</em> <br/>\n\nreviewed.  was committed long ago.  resolving ticket.</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1750\" onclick=\"get_ticket_and_populate_wrapper('1750'); return false;\" title=\"disconnect during file transfer causes starter to abort\">#1750</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\ndisconnect during file transfer causes starter to abort</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Nov-01 17:54</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=19289\">[19289]</a></span>: Restored handling of disconnect during file transfer. <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1750\" onclick=\"get_ticket_and_populate_wrapper('1750'); return false;\" title=\"disconnect during file transfer causes starter to abort\">#1750</a></span> The problem introduced in b3ef6289 (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1587\" onclick=\"get_ticket_and_populate_wrapper('1587'); return false;\" title=\"Problems with semantics of failed file transfer\">#1587</a></span>) is that the starter would abort if the file transfer failed with a transient failure, such as a disconnect.  (By Dan Bradley )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Aug-30 16:29</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=18897\">[18897]</a></span>: Merged <span class=\"chng\"><a href=\"chngview?cn=18283\">[18283]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18286\">[18286]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18307\">[18307]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18308\">[18308]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18309\">[18309]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18313\">[18313]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18316\">[18316]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18317\">[18317]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18319\">[18319]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18320\">[18320]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18322\">[18322]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18324\">[18324]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18414\">[18414]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18416\">[18416]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18423\">[18423]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18439\">[18439]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18440\">[18440]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18441\">[18441]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18445\">[18445]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18446\">[18446]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18510\">[18510]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18511\">[18511]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18513\">[18513]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18515\">[18515]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18519\">[18519]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18521\">[18521]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18522\">[18522]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18538\">[18538]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18544\">[18544]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18545\">[18545]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18546\">[18546]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18550\">[18550]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=18552\">[18552]</a></span>,\u00a0[...]\n (By Peter Keller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Aug-30 15:56</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=18895\">[18895]</a></span>: This fixes a problem in Condor's file transfer semantics. The problem is that if someone specifies transfer_output_files and is using file transfer, then if the job doesn't produce all of the files in question and exits (suppose by segfault), Condor will put the job on hold. In this circumstance there\u00a0[...]\n (By Peter Keller )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2012-May-03 11:59", "status": "resolved", "created": "2010-Aug-18 11:37", "fixed_version": "2010-Aug-18 11:37", "broken_version": "v070000", "priority": "2", "subsystem": "Daemons", "assigned_to": "zmiller", "derived_from": "", "creator": "zmiller", "rust": "", "customer_group": "other", "visibility": "public", "notify": "psilord@cs.wisc.edu, zmiller@cs.wisc.edu, matt@cs.wisc.edu, dan@hep.wisc.edu", "due_date": ""}