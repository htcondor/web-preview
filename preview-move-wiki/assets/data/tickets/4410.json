{"id": 4410, "title": "Ticket #4410: Job appears to crash standard universe starter.", "description": "<blockquote>\nJuan Barayoga writes:\n\n<p></p><div class=\"verbatim\">\n<pre>The truncated StartLog and slot StarterLog can be downloaded here:\nhttps://ldas-gridmon.ligo.caltech.edu/condor/node444.condor_logs.tgz\n</pre></div>\n\n\n<p>The log appears to have some of the program's output? inserted into the middle.\n\n</p><p></p><div class=\"verbatim\">\n<pre>04/20/14 22:08:34       *FSM* Transitioning to state \"TERMINATE_WAIT\"\ne+01    7.65295052670759590185e-01      0       1.23049810495175626635e+00      7.18089844438842495045e-01      9.36297432680357144541e-01      9.97113051422187979256e-01      7       16      0       1\n</pre></div>\n\n...\n<div class=\"verbatim\">\n<pre>04/20/14 22:08:34       *FSM* Executing state func \"asynch_wait()\" [ SUSPEND ALARM DIE CHILD_EXIT  ]\n04/20/14 22:08:34       *FSM* Got asynchronous event \"CHILD_EXIT\"\n04/20/14 22:08:34       *FSM* Executing transition function \"reaper\"\n04/20/14 22:08:34 Process 25963 killed by signal 6\n04/20/14 22:08:34 Process exited abnormally\n04/20/14 22:08:34       *FSM* Transitioning to state \"TERMINATE\"\n04/20/14 22:08:34       *FSM* Executing state func \"terminate_all()\" [  ]\n04/20/14 22:08:34 No core file to send - probably ran out of disk\n04/20/14 22:08:34       *FSM* Transitioning to state \"SEND_STATUS_ALL\"\n04/20/14 22:08:34       *FSM* Executing state func \"dispose_all()\" [  ]\n04/20/14 22:08:34 Sending final status for process 223657.0\n04/20/14 22:08:34 STATUS encoded as ABNORMAL, NO CORE\n04/20/14 22:08:34 User time = 7.700000 seconds\n04/20/14 22:08:34 System time = 4.600000 seconds\n04/20/14 22:08:34 condor_write(): Socket closed when trying to write 165 bytes to , fd is 17\n04/20/14 22:08:34 StdUnivBuf::write(): condor_write() failed\nStack dump for process 25489 at timestamp 1398056914 (14 frames)\n/usr/lib64/condor/libcondor_utils_8_0_6.so(dprintf_dump_stack+0x12d)[0x7fa940c39fcd]\n/usr/lib64/condor/libcondor_utils_8_0_6.so(+0x1401e2)[0x7fa940c2f1e2]\n/lib64/libpthread.so.0[0x33c580f710]\n/lib64/libc.so.6(gsignal+0x35)[0x33c5032925]\n/lib64/libc.so.6(abort+0x175)[0x33c5034105]\n/lib64/libc.so.6[0x33c502ba4e]\n/lib64/libc.so.6(__assert_perror_fail+0x0)[0x33c502bb10]\ncondor_starter(REMOTE_CONDOR_reallyexit+0x1db)[0x42898e]\ncondor_starter(_Z17send_final_statusP8UserProc+0x5c)[0x40e2fc]\ncondor_starter(_Z11dispose_allv+0x30)[0x40e3d0]\ncondor_starter(_ZN12StateMachine7executeEv+0x20a)[0x40c78a]\ncondor_starter(main+0x93)[0x40ea93]\n/lib64/libc.so.6(__libc_start_main+0xfd)[0x33c501ed1d]\ncondor_starter[0x40b169]\n\n\nChristopher Berry writes:\n\n{verbatim}\nWe're running LALInference Nest as part of a pipeline. The pipeline script\nis written in python and should be found here:\n\n/home/christopher.berry/code/lscsoft/\n\nI'm running pipe_STT4_2015_leoframes.py while Hannah is\nrunning pipe_STT4-NS_2015_leoframes.py (the only difference being some\nchanging some parameters we are trying to estimate). To run the pipeline\nwe'd do something like\n\npython /home/christopher.berry/code/lscsoft/pipe_STT4_2015_leoframes.py -s\nlalinferencenest -f 1 -l 10 -p\n/home/christopher.berry/lscsoft/lalinference_paper/bin/ --path\n/home/christopher.berry/data/2015_injset_131210/ -r\n/home/christopher.berry/data/2015_spin/ --condor-submit\nIf we just unpack that, you'll see that the python script takes various\noptions, which schematically are\n\npython /home/christopher.berry/code/lscsoft/pipe_STT4_2015_leoframes.py -s\n[name of LALInference code to run] -f [first job] -l [last job] -p [path to\nbinaries] --path [path to input data] -r [path to output] --condor-submit\n\nHence the example I gave will start ten instances of LALInference Nest, one\nfor each run 1 to 10. (There are 250 events in total in our input set. If\nyou want to check which numbers correspond to jobs on hold, you can check\nthe Out, UserLog, Err, etc. fields of condor_q -l. Picking three at random,\n7, 32 and 67 are on hold.) The installation of LALInference we are using\ncan be sourced by\n\nsource /home/christopher.berry/lscsoft/lalinference_paper/etc/lscsoftrc\n\nThe paths to the binaries is above, and the source is in\n/home/christopher.berry/code/lscsoft/lalsuite/ I hope that is sufficient\ninformation about things. I think I've set permissions correctly on\neverything, but just let me know if not.\n</pre></div>\n\n\n<p>Hannah Middleton writes:\n\n</p><p></p><div class=\"verbatim\">\n<pre>Yes all my stuff should be similar to Christopher's apart from the install\nof lal and the output directory:\n\npython\n/home/hannah.middleton/SkyLocMDCScripts/pipe_STT4-NS_2015_leoframes.py -s\nlalinferencenest -f [first job] -l [last job] -p\n/home/hannah.middleton/lscsoft/lalinf_paper_branch/bin/ --path\n/home/christopher.berry/data/2015_injset_131210/ -r\n/home/hannah.middleton/2015_NonSpinning/ --condor-submit\n\nA couple of examples of jobs which I have on hold are 103, 104, 107 (running\non pcdev1) and 200,  235 (on pcdev3) - think think the ones on pcdev3 are\nusing a slightly later version of the lalinference_paper branch than above\nwhich is at /home/hannah.middleton/lscsoft/lalinf_paper_new/, if that's any\nhelp.\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\nLIGO will re-report this issue if it re-occurs after they upgrade to 8.2.x.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "incident", "last_change": "2014-Jul-30 13:20", "status": "defer", "created": "2014-Jun-23 10:19", "fixed_version": "2014-Jun-23 10:19", "broken_version": "", "priority": "5", "subsystem": "Std", "assigned_to": "tlmiller", "derived_from": "", "creator": "tlmiller", "rust": "", "customer_group": "ligo", "visibility": "public", "notify": "tlmiller@cs.wisc.edu,pcouvare@caltech.edu", "due_date": ""}