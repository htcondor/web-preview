{"id": 5412, "title": "Ticket #5412: HTCondor View: rolling file name format", "description": "<blockquote>\n<span class=\"section\"><h2>Requirements </h2></span>\n\n<p>The HTCondor View client needs to be able to identify which files available on the HTCondor View server it must load to display a given date range's worth of data. The client should do so without asking the server for dynamic information.  We cannot assume that the server will provide any sort of automatic, parseble directory listing.\n\n</p><p>The files will be in multiple sampling resolutions, which more dense sampling kept in files covering smaller intervals.  The number of old files will vary based on the interval.\n\n</p><p><span class=\"section\"></span></p><h2>Server Specifications</h2>\n\n<p><span class=\"subsection\"></span></p><h3>Summary </h3>\n\n<p>End up with a bunch of files like:\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\">machine.oldest.json\n\nmachine.monthly.2015-11.json\nmachine.monthly.2015-10.json\nmachine.monthly.2015-09.json\n\nmachine.weekly.2015-W48.json\nmachine.weekly.2015-W47.json\n\nmachine.daily.2015-11-23.json\nmachine.daily.2015-11-22.json\n\nsubmitter.oldest.json\n\nsubmitter.monthly.2015-11.json\nsubmitter.monthly.2015-10.json\nsubmitter.monthly.2015-09.json\n\nsubmitter.weekly.2015-W48.json\nsubmitter.weekly.2015-W47.json\n\nsubmitter.daily.2015-11-23.json\nsubmitter.daily.2015-11-22.json\n</pre></div>\n\n\n<p>* .daily. *, * .weekly. *, and * .monthly. * are JSON files with data covering the specified period.\n\n</p><p>* .oldest are JSON files identifying the oldest data available for each type of data. For example:\n</p><div class=\"code\">\n<pre class=\"code\">{\n\"monthly\": \"2015-09\",\n\"weekly\": \"2015-W47\",\n\"daily\": \"2015-11-22\"\n}\n</pre></div>\n\n\n<p>All dates and times are in UTC.\n\n</p><p><span class=\"subsection\"></span></p><h3>Details </h3>\n\n<p>The data files are JSONish, notably missing the framing \"[]\" that an array would normally require and allowing an extra \",\" after the last entry.  The \"[]\" and \",\" are allowed, although if the framing \"[]\" is present, the extraneous \",\" after the last record is <em>not</em>.  Otherwise data is in any format Afterquery understands.\n\n</p><p>A set of files will be kept for each TYPE of data. Types might include \"submitters\" and \"machines.\"\n\n</p><p>For each TYPE, there will be files for several intervals: daily, weekly, and monthly.\n\n</p><p>For each TYPE and interval there will be a file for each period. Intervals will start at midnight. Weekly intervals start on Monday (matching ISO 8601). Monthly intervals start on the first of the month.  File may be missing because the server was down for that period, or no records have yet been written to the current period.\n\n</p><p>All dates and times are in UTC.\n\n</p><p>For weekly files, the year rolls over on the Monday of the first week to include a Thursday in the new year.  (Or put another way: the week that includes January 4th.) This means the \"year\" can be ahead or behind the year as generally understood.  For example Sunday, January 3rd, 2016 is 2015-W53 while Monday, January 4th, 2016 is 2016-W01.  Monday, December 31st, 2018 is 2019-W01.  If you're using strftime %G may get you the year you want.\n\n</p><p>The file name will consist of the TYPE (eg \"submitters\"), the period description (\"monthly\"), and the shortest ISO 8601 data that will uniquely identify the start of the period. Unneeded fields in the data can be dropped.\n\n</p><p></p><ul>\n<li>Monthly: TYPE.monthly.2015-11.json - strftime(\"%Y-%m\")\n</li><li>Weekly: TYPE.weekly.2015-W48.json - strftime(\"%G-W%V\")\n</li><li>Daily: TYPE.daily.2015-11-23.json - strftime(\"%Y-%m-%d\")\n</li><li>Hourly: TYPE.hourly.2015-11-23T15.json (This is an example. Hourly logs are not currently planned.)\n</li></ul>\n\n<p>Old files will be deleted on a regular basis.  While likely user configurable in the future, as a starting point:\n\n</p><p></p><ul>\n<li>Daily: Keep 2 files, sample every 5 minutes\n</li><li>Weekly: Keep 2 files, sample every hour\n</li><li>Monthly: Keep 12 files, sample every 2 hours\n</li></ul>\n\n<p>The server will also maintain an additional file with the TYPE and \".oldest.\"  It contains information on the oldest data available for each interval for that type.  It is a JSON list of Objects. Each object has an \"interval\" (eg \"monthly\") and \"oldest\" (eg \"2014-12\")\n\n</p><p>When the server starts up, it will fill in this file if it's missing. When the server deletes old data, it will replace this file with updated information. It is acceptable to set an oldest date that does not yet exist; it is likely on initial server startup.\n\n</p><p>Example TYPE.oldest.json file:\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\">{\n\"monthly\": \"2015-09\",\n\"weekly\": \"2015-W47\",\n\"daily\": \"2015-11-22\",\n\"hourly\": \"2015-11-22T15\"\n}\n</pre></div>\n\n\n<p><span class=\"section\"></span></p><h2>File Data</h2>\n\n<p>The dated JSON files contain data in any form that Afterquery can parse. However, every record <em>must</em> have a \"Date\" field which contains a UTC time and date stamp in a form Afterquery can parse.  (Non-UTC times are acceptable so long as they contain time zone information in a way that Afterquery can correctly interpret.)\n\n</p><p><span class=\"section\"></span></p><h2>Client Notes</h2>\n\n<p>The most common use case is \"for a given interval, give me the two most recent files\". We need two because the most recent file will only contain <em>up to</em> a given interval's worth of data. Two files ensure we receive <em>at least</em>  an interval's worth of data. This is being treated as a special case of the more general case.\n\n</p><p>The more general case is \"Get me data between these two timestamps. All data must use the same interval. If possible no more than two files will be loaded. Given those constraints, select the highest resolution possible.\"  The client will use the\n\n</p><p>In both cases the client is almost guaranteed to end up with more data than requested.  The client will filter it out. The client will <em>not</em> just display all of the data; doing so would leave to automatically-updating graphs slowly expanding the period covered, then suddenly snapping back to the minimum.  Strictly limiting the range will provide smooth animations.\n\n</p><p><span class=\"section\"></span></p><h2>Rationale </h2>\n\n<p>The files could have ended with \".0\" \".1\" and so on, and be rotated. Files with time/date stamps in the name were chose so that:\n\n</p><p></p><ol>\n<li>Easy for the client to calculate which files it should read.\n</li><li>A server which is down for an entire period doesn't need to stub in an empty rollover file to ensure the client's calculations match.\n</li><li>Eliminates race conditions when the client is requesting files while the server is rolling them over.\n</li></ol>\n\n<p>I considered one .oldest file per TYPE and interval (\"TYPE.monthly.oldest\" \"TYPE.weekly.oldest\").  Rejected as requiring additional unnecessary file writes and HTTP requests. In particular, the client will often need to check multiple oldest entries to decide which files to load. The file is small enough that that overhead will drown out the tiny file savings.\n\n</p><p>Dates are all in UTC because the client has no idea what time zone the server is in.  It's more straightforward for everyone to work in UTC than for the server to publish time zone information and the client to convert into it (with bonus points for dealing with daylight savings).</p></blockquote>", "remarks": "<blockquote>\n</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2015-Dec-09 17:35", "status": "new", "created": "2015-Nov-23 15:43", "fixed_version": "2015-Nov-23 15:43", "broken_version": "", "priority": "4", "subsystem": "", "assigned_to": "", "derived_from": "#5351", "creator": "adesmet", "rust": "", "customer_group": "other", "visibility": "public", "notify": "", "due_date": ""}