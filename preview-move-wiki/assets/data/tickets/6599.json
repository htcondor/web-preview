{"id": 6599, "title": "Ticket #6599: remove the need for most wrapper scripts", "description": "<blockquote>\n<em>It is our belief in most cases, the use of job wrapper scripts by users or administrators is an indication that HTCondor is lacking in necessary features.  This ticket is an examination of some specific wrapper scripts in use with the 8.6 stable release with analysis of what features should be added to make these scripts unnecessary</em>\n\n<p>Wrappers come in 2 forms\n</p><ol>\n<li>Administrator defined wrappers (aka <code>USER_JOB_WRAPPER</code>)\n</li><li>User defined wrappers - a submit file where the executable is a script that wraps the real job.\n</li></ol>\n\n<p><span class=\"section\"></span></p><h2>Administrator defined wrappers</h2>\nOn the STARTD, the <code>USER_JOB_WRAPPER</code> configuration knob can be set to provide a wrapper script for all jobs that run on that node.  These are undesirable because they don't compose - only one wrapper is allowed for all jobs, so it must handle <strong>all</strong> forms of wrapping.\n\n<p>In this category we have two examples\n</p><ol>\n<li>singularity-job-wrapper.sh - a wrapper for singularity jobs used by OSG\n</li><li>condor-docker - a wrapper for docker jobs used by Fermi\n</li></ol>\n\n<p><span class=\"subsubsection\"></span></p><h4>singularity-job-wrapper </h4>\nIn pseudo-code this wrapper does the following:\n\n<p></p><pre>    if the job has a SingularityImage attribute AND the STARTD supports singularity\n        add \"-bind /cvmfs\" to singularity args\n        if the slot has GPUs\n           add \"-bind &lt;nvidia drivers/libs&gt;\" to singularity args\n        set home and pwd for singularity job to /srv\n        exec singularity using SingularityImage and input args\n    else\n        exec the job\n</pre>\n\n<p>There is also code to modify environment variables and paths in the arguments <span class=\"comment\">[[anonymous: to adjust for the existence of the wrapper script itself?]]</span>\n\n</p><p><strong>recommendation</strong>\nNone - this wrapper script does not appear to do anything we cannot do with HTCondor's native Singularity support, but it does enable the use of Singularity jobs on versions of HTCondor that have no native Singularity support.\n\n</p><p><span class=\"subsubsection\"></span></p><h4>docker-wrapper </h4>\nin pseudo-code the docker wrapper does\n\n<p></p><pre>   add arg to set the hostname of the container to a well known, unique value\n   add args to disable swapping\n   add environment variables from FERMIHTC_DOCKER_ENV config variable\n   if the docker job is using a trusted docker image\n      enable --cap--add items from FERMIHTC_DOCKER_CAPABILITIES config variable\n   If pull configured\n      pull the docker image\n   run the docker job with modifed args\n</pre>\n\n<p><strong>recommendation</strong>\n</p><ul>\n<li>add support for --cap-add for trusted docker images\n</li><li>add support for STARTD_JOB_TRANSFORMS in order to customize the environment.\n</li></ul>\n\n<p><span class=\"section\"></span></p><h2>User defined wrappers</h2>\nWe consider the user to have written a wrapper script when the <code>executable</code> statement in the submit file is a script but what the user thinks of as their job is a different executable or script. For instance, most R jobs in CHTC are an R script, with a bash script wrapper.\n\n<p>In this sort of job, the wrapper script is really a setup script, preparing the environment for the job itself.  We have many examples, but they all boil down to one or more of these basic operations\n\n</p><p></p><ol>\n<li>download an executable or runtime\n</li><li>unpack a tarball or zip file from file transfer or from step 1\n</li><li>adjust the environment to be correct relative to the current working directory\n</li><li>validate the results and report a job failure if validation fails\n</li><li>delete extraneous files after the job runs and before output transfer\n</li><li>tar/zip the results\n</li></ol>\n\n<p><strong>recommendation</strong>\n</p><ul>\n<li>add tar/zip packing and unpacking to file transfer\n</li><li>add file transfer blacklist\n</li><li>make sandbox directory path available to $$() expansion OR add a mechanism to modify the final environment in the starter before launching the job.</li></ul>\n</blockquote>", "remarks": "<blockquote>\n<em>2018-Mar-13 14:45:55 by johnkn:</em> <br/>\n\n<span class=\"subsection\"><h3>Feature comparison Docker vs. Singularity</h3></span>\n\n<p><table border=\"1\" cellspacing=\"0\">\n<tbody><tr>\n<td>\nFeature</td>\n<td>\nDocker</td>\n<td>\nSingularity</td>\n<td>\nNotes</td>\n</tr>\n\n<tr>\n<td>\nSpecify image</td>\n<td>\n <code>job.DockerImage</code> </td>\n<td>\n config <code>SINGULARITY_IMAGE_EXPR</code>. default is <code>job.SingularityImage</code> </td>\n<td>\n singularity wrapper assumages images are in cvmfs </td>\n</tr>\n\n<tr>\n<td>\nImage whitelist</td>\n<td>\nno</td>\n<td>\nvia <code>SINGULARITY_IMAGE_EXPR</code> expression</td>\n<td>\n </td>\n</tr>\n\n<tr>\n<td>\nWrap a job in a container</td>\n<td>\nno</td>\n<td>\nvia <code>SINGULARITY_JOB</code> config</td>\n<td>\nstarter can convert any vanilla job to a singularity job</td>\n</tr>\n\n<tr>\n<td>\n<code>MOUNT_UNDER_SCRATCH</code></td>\n<td>\nyes</td>\n<td>\nyes</td>\n<td>\ndocker allows <code>MOUNT_UNDER_SCRATCH</code> to be an expression against the job </td>\n</tr>\n\n<tr>\n<td>\nBindmounts</td>\n<td>\n config <code>DOCKER_MOUNT_VOLUMES</code>, <code>DOCKER_VOLUME_DIR_xxx</code>, and optionally <code>DOCKER_VOLUME_DIR_xxx_MOUNT_IF</code></td>\n<td>\nconfig <code>SINGULARITY_BIND_EXPR</code> is expr returning a stringlist. default is <code>job.SingularityBind</code></td>\n<td>\n singularity wrapper does conditional bindmount of nvidia drivers if assigned Gpus </td>\n</tr>\n\n<tr>\n<td>\n chirp </td>\n<td>\n yes </td>\n<td>\n yes </td>\n<td>\n </td>\n</tr>\n\n<tr>\n<td>\n <code>STARTER_JOB_ENVIRONMENT</code> </td>\n<td>\n yes </td>\n<td>\n yes </td>\n<td>\n docker-wrapper sets GLIDEIN_ToDie and GLIDEIN_Site </td>\n</tr>\n\n<tr>\n<td>\n Capabilities </td>\n<td>\n config <code>DOCKER_DROP_ALL_CAPABILITIES</code> </td>\n<td>\n n/a </td>\n<td>\n<code>DAC_OVERRIDE</code>, <code>SETUID</code>, <code>SETGID</code>, <code>SYS_ADMIN</code>, <code>SYS_CHROOT</code> and <code>SYS_PTRACE</code> needed to run singularity within docker</td>\n</tr>\n\n<tr>\n<td>\n Gpu support </td>\n<td>\n<pre>\n  via nvida docker wrapper </pre>\n</td>\n<td>\n via <code>SINGULARITY_BIND_EXPR</code> </td>\n<td>\n </td>\n</tr>\n\n<tr>\n<td>\n Nesting </td>\n<td>\n no </td>\n<td>\n no </td>\n<td>\n singularity can be run inside if high capability docker containers </td>\n</tr>\n</tbody></table></p></blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "enhance", "last_change": "2020-Nov-09 10:52", "status": "new", "created": "2018-Mar-08 16:52", "fixed_version": "2018-Mar-08 16:52", "broken_version": "", "priority": "3", "subsystem": "Daemons", "assigned_to": "johnkn", "derived_from": "", "creator": "johnkn", "rust": "", "customer_group": "other", "visibility": "public", "notify": "", "due_date": ""}