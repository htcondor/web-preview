{"id": 309, "title": "Ticket #309: HAD replication daemon can only replicate a single file", "description": "<blockquote>\nCurrently, the HAD replication daemon is hard-coded to replicate a single file.  For hadoop, it may be necessary for it to handle a list of files.\n\n<p>Timeline:\n</p><ol>\n<li>Complete: 8 Jan 2010</li></ol>\n</blockquote>", "remarks": "<blockquote>\n<em>2009-May-28 11:58:47 by nleroy:</em> <br/>\n\nI was led to believe that this would be a pretty simple update -- I think that there were some communications problems that led me to that belief.\n\n<p>This will going to be a bigger job than I had previously anticipated.  :(\n\n</p><p></p><hr/>\n<em>2009-Nov-18 10:45:29 by nleroy:</em> <br/>\n\n<span class=\"section\"><h2>Replicating HDFS state files</h2></span>\n\n<p></p><ol>\n<li>HDFS can produce files that reflect it's current state\n<ol>\n<li>1 file is the state at the most recent rebuild\n</li><li>1 file is a append-only log file; this file can grow quite large\n</li></ol>\n\n<p></p></li><li>Current proposal\n<ol>\n<li>Replicator would handle a set of files\n<ol>\n<li>Track version of the entire set, not individual files\n</li><li>Largest mtime of all of the files would be used as the mtime of the entire set\n</li></ol>\n</li><li>Give the replicator the ability to track the size of a file, and to push additions to append-only files\n</li></ol>\n\n<p></p></li><li>Problems\n<ol>\n<li>This model doesn't handle multiple peers.  Consider the following:\n<ul>\n<li>Define peers: A, B, C; A is the master\n</li><li>Define files: \"state\", \"log\"; \"log\" is append-only\n</li><li>A initially pushes \"state\" and \"log\" to B and C\n</li><li>A pushes additions to \"log\" to B and C (zero or more times)\n</li><li>Peer C goes down\n</li><li>A pushes additions to \"log\" to B, but not C (one or more times)\n</li><li>Peer C comes back up\n</li><li>A pushes additions to \"log\" to B and C\n<ul>\n<li>\"log\" on C is now corrupt -- it does not contain the additions pushed while C was down\n</li></ul>\n</li></ul>\n</li></ol>\n</li></ol>\n\n<p></p><hr/>\n<em>2009-Nov-18 11:08:20 by nleroy:</em> <br/>\n\n<span class=\"section\"><h2>Replicating HDFS state files solution</h2></span>\n\n<p></p><ol>\n<li>Replicator daemon reverts back to similar to that of 7.4.x, but:\n<ul>\n<li>Knows of file sets\n</li><li>File set mtime defined by the most recent mtime\n</li><li>File name + ctime included in decision of when to move file set, from which machine, etc.\n</li><li>Communicate with other replicator(s) by sending <span class=\"quote\">ClassAd</span>s\n</li></ul>\n\n<p></p></li><li>Transferer daemon gains a lot of intelligence:\n<ul>\n<li>Knows about the list of files to replicate, which are append-only, etc.\n</li><li>Communicate with each other via <span class=\"quote\">ClassAd</span>s\n</li></ul>\n\n<p></p></li><li>Transferer Protocol:\n<ol>\n<li>Sender sends complete state via <span class=\"quote\">ClassAd</span>\n</li><li>For each file that that requires transfer:\n<ol>\n<li>Receiver sends \"send file request\" via <span class=\"quote\">ClassAd</span>\n<ul>\n<li>file path (relative to base)\n</li><li>beginning offset to send (0 == entire file)\n</li></ul>\n</li><li>Sender sends \"pushing file\" command via <span class=\"quote\">ClassAd</span> or NAK\n<ul>\n<li>file path (should match request)\n</li><li>file meta data (currently: ctime)\n</li><li>beginning offset (should match request)\n</li><li>number of bytes to send\n</li></ul>\n</li><li>Data transfer\n</li><li>After transfer complete, receiver sets file meta data to match sender's\n</li></ol>\n</li></ol>\n</li></ol>\n\n<p></p><hr/>\n<em>2010-Oct-06 23:44:42 by ilikhan:</em> <br/>\n\nWith the new version of Hadoop (0.21.0) we do not  need HAD replication daemon to replicate HDFS state files. We can configure a machine to be Backup Node to maintain an in-memory up-to-date copy of the file system namespace that is always synchronized with the active <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=NameNode\" title=\"Name Node\">NameNode</a></span> state. See <a class=\"external\" href=\"http://hadoop.apache.org/hdfs/docs/r0.21.0/hdfs_user_guide.html#Secondary+NameNode\">http://hadoop.apache.org/hdfs/docs/r0.21.0/hdfs_user_guide.html#Secondary+NameNode</a>\n\n<p>So, should we cancel this task?\n</p><hr/>\n<em>2010-Oct-20 15:59:08 by jfrey:</em> <br/>\n\nBulk change of target version from v070504 to v070505 using ./ticket-target-mover.\n<hr/>\n<em>2011-Jan-27 14:21:33 by danb:</em> <br/>\n\nBulk change of target version from v070505 to v070506 using ./ticket-target-mover.\n<hr/>\n<em>2011-Feb-01 14:49:30 by tannenba:</em> <br/>\n\nBulk change of target version from v070506 to NULL using ./ticket-target-mover.\n\n<p></p><hr/>\n<em>2011-Mar-30 19:47:38 by nleroy:</em> <br/>\n\nDue to updates to HDFS, there is no longer a driver for this work.  The work is 90% complete, sitting on the <code>V7_5-had_replication_fileset-branch</code>.  It's pushed to the main repo.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Feb-05 12:27</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=17177\">[17177]</a></span>: Added the ability to send/get the end of a file to CEDAR (<span class=\"ticket\"><a class=\"abandoned\" href=\"/tickets?ticket=309\" onclick=\"get_ticket_and_populate_wrapper('309'); return false;\" title=\"HAD replication daemon can only replicate a single file\">#309</a></span>)  (By Nick <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LeRoy\" title=\"Le Roy\">LeRoy</a></span> )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Jan-19 16:35</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=17087\">[17087]</a></span>: Rework of the HAD replicator to support multiple files (<span class=\"ticket\"><a class=\"abandoned\" href=\"/tickets?ticket=309\" onclick=\"get_ticket_and_populate_wrapper('309'); return false;\" title=\"HAD replication daemon can only replicate a single file\">#309</a></span>)  (By Nick <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LeRoy\" title=\"Le Roy\">LeRoy</a></span> )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Jan-19 16:22</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=17086\">[17086]</a></span>: Added the ability to send/get the end of a file to CEDAR (<span class=\"ticket\"><a class=\"abandoned\" href=\"/tickets?ticket=309\" onclick=\"get_ticket_and_populate_wrapper('309'); return false;\" title=\"HAD replication daemon can only replicate a single file\">#309</a></span>)  (By Nick <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LeRoy\" title=\"Le Roy\">LeRoy</a></span> )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2011-Oct-19 08:25", "status": "abandoned", "created": "2009-Mar-09 13:58", "fixed_version": "2009-Mar-09 13:58", "broken_version": "", "priority": "2", "subsystem": "Daemons", "assigned_to": "nleroy", "derived_from": "#245", "creator": "nleroy", "rust": "", "customer_group": "other", "visibility": "public", "notify": "matt@cs.wisc.edu", "due_date": "20100118"}