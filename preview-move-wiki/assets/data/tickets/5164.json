{"id": 5164, "title": "Ticket #5164: Bulk submits for condor_dagman", "description": "<blockquote>\nWhen fully loaded, we're seeing pretty huge penalties for our dagman-based workflows versus our non-dagman workflows.  Looking at a strace of the schedd, I think one big contribution is the fact dagman submits a cluster-at-a-time while all our other submission methods do bulk submits (multiple procs; 10-100).\n\n<p>Our schedds see about 10 condor_submit processes in parallel at any given time and 200-300 condor_dagman processes.  We are bottlenecked on accept() new sockets, giving further credence to the idea that a bulk condor_submit would be helpful.\n\n</p><p>Since we want to convert condor_submit into a library anyway for the 8.5 series, I wonder if we could change condor_submit / condor_dagman to do something along the line of:\n\n</p><p></p><div class=\"verbatim\">\n<pre>condor_submit file1 file2 file3\n</pre></div>\n\n\n<p>where each fileX is a separate submit file and creates a separate cluster.</p></blockquote>", "remarks": "<blockquote>\n<em>2015-Jul-28 14:33:14 by bbockelm:</em> <br/>\n\nUnassigning from myself as this is a huge piece of work - just wanted to record the need and use this as a conversation starter.\n\n<p></p><hr/>\n<em>2015-Jul-29 10:59:16 by wenger:</em> <br/>\n\nFrom the DAGMan point of view, there are several complications with this:\n<ol>\n<li>Often various nodes that are submitted in the same cycle don't have the same set of condor_submit arguments (e.g., VARS, parent node names, etc.).\n</li><li>DAGMan currently parses the output of condor_submit, so we'd have to make sure the multi-submit condor_submit produced output containing all of the information DAGMan needs, and DAGMan would have to be changed to parse that output.\n</li></ol>\n\n<p></p><hr/>\n<em>2015-Jul-29 11:05:00 by bbockelm:</em> <br/>\n\nAnother possible approach would be to pre-create a schedd socket and let condor_submit inherit that.\n\n<p>That way, each condor_submit is completely independent (and unchanged) but the security session and socket are reused.  The schedd would see the benefit of bulk submits, but the client side would look \"mostly\" the same.\n\n</p><p></p><hr/>\n<em>2015-Aug-09 11:31:16 by bbockelm:</em> <br/>\n\nA third, even simpler idea (but with less impact) is to automatically disable the reschedule for condor_submit and perform a condor_reschedule at the end of the cycle when there was at least one successful submit.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2015-Aug-09 11:31", "status": "new", "created": "2015-Jul-17 09:07", "fixed_version": "2015-Jul-17 09:07", "broken_version": "", "priority": "5", "subsystem": "Dag", "assigned_to": "", "derived_from": "#5162", "creator": "bbockelm", "rust": "", "customer_group": "cms", "visibility": "public", "notify": "wenger@cs.wisc.edu, bbockelm@cse.unl.edu", "due_date": ""}