{"id": 462, "title": "Ticket #462: upon removal, condor_dagman leaves orphaned jobs", "description": "<blockquote>\nwhen a user runs condor_rm on a dagman job, dagman removes all it's child jobs (which it should).  it does this by invoking 'condor_rm -constraint'.  however, it is possible for dagman to exit and then be removed from the job queue while child jobs are still in the 'X' state.  dagman should NEVER leave jobs behind in any state.\n\n<p>the reason this is bad is because it is possible for jobs to go from 'X' state to 'H'eld if the removal fails (especially grid universe jobs), thus leaving the orphan job in the queue with no dagman overseeing it.\n\n</p><p>i was able to reproduce this by submitting a dag with 1000 vanilla sleep jobs.  run condor_rm on the dag, and then run condor_q in a tight loop and capture the output.  you will (maybe) see that dagman has left the queue while child jobs remain in 'X' state.  i was able to do this more than once, so it's fairly reproducible.  see below.\n\n</p><p>dagman should not exit until all jobs are actually gone.  i believe it should do this by watching the job logs and verifying that the remove events (or complete events, since there may be a race here) are written for all jobs before exiting.\n\n</p><p>a separate but related issue is when the remove events actually get written -- when the job goes TO 'X' state or when it actually leaves the queue, but i'm making a separate ticket for that.  in any case, waiting for the remove events to be written will help ensure that orphaned jobs are not left behind.\n\n</p><p></p><div class=\"verbatim\">\n<pre>% condor_rm 25057.0 ; condor_q\n\nCluster 25057 has been marked for removal.\n\n\n-- Submitter: newbio.cs.wisc.edu : &lt;128.105.147.100:40591&gt; : newbio.cs.wisc.edu\n ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD\n25057.0   zmiller         5/7  15:15   0+00:00:00 X  0   4.6  condor_dagman\n25058.0   zmiller         5/7  15:15   0+00:01:11 R  0   1.7  sleep 600\n25059.0   zmiller         5/7  15:15   0+00:01:24 R  0   1.7  sleep 600\n25060.0   zmiller         5/7  15:15   0+00:01:10 R  0   1.7  sleep 600\n25061.0   zmiller         5/7  15:15   0+00:01:05 I  0   1.7  sleep 600\n25062.0   zmiller         5/7  15:15   0+00:01:14 I  0   1.7  sleep 600\n25063.0   zmiller         5/7  15:15   0+00:00:47 R  0   1.7  sleep 600\n25064.0   zmiller         5/7  15:15   0+00:00:48 R  0   1.7  sleep 600\n25065.0   zmiller         5/7  15:16   0+00:00:41 R  0   1.7  sleep 600\n25066.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25067.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25068.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25069.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25070.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25071.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25072.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25073.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25074.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25075.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25076.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25077.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25078.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25079.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25080.0   zmiller         5/7  15:16   0+00:00:00 I  0   0.0  sleep 600\n25081.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25082.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25083.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25084.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25085.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25086.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25087.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25088.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25089.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25090.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25091.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n25092.0   zmiller         5/7  15:17   0+00:00:00 I  0   0.0  sleep 600\n\n35 jobs; 29 idle, 6 running, 0 held\n\n% condor_q\n\n-- Submitter: newbio.cs.wisc.edu : &lt;128.105.147.100:40591&gt; : newbio.cs.wisc.edu\n ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD\n25057.0   zmiller         5/7  15:15   0+00:02:14 X  0   4.6  condor_dagman\n25058.0   zmiller         5/7  15:15   0+00:01:10 X  0   1.7  sleep 600\n25059.0   zmiller         5/7  15:15   0+00:01:23 X  0   1.7  sleep 600\n25060.0   zmiller         5/7  15:15   0+00:01:10 X  0   1.7  sleep 600\n25061.0   zmiller         5/7  15:15   0+00:01:05 X  0   1.7  sleep 600\n25062.0   zmiller         5/7  15:15   0+00:01:14 X  0   1.7  sleep 600\n25063.0   zmiller         5/7  15:15   0+00:00:48 X  0   1.7  sleep 600\n25066.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25067.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25068.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25069.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25070.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25071.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25073.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25074.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25075.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25076.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25077.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25078.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25079.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25080.0   zmiller         5/7  15:16   0+00:00:00 X  0   0.0  sleep 600\n25081.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25082.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25083.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25084.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25085.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25086.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25087.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25088.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25089.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25090.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25091.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n25092.0   zmiller         5/7  15:17   0+00:00:00 X  0   0.0  sleep 600\n\n0 jobs; 0 idle, 0 running, 0 held\n\n% condor_q\n\n\n-- Submitter: newbio.cs.wisc.edu : &lt;128.105.147.100:40591&gt; : newbio.cs.wisc.edu\n ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD\n25059.0   zmiller         5/7  15:15   0+00:01:23 X  0   1.7  sleep 600\n25060.0   zmiller         5/7  15:15   0+00:01:10 X  0   1.7  sleep 600\n\n0 jobs; 0 idle, 0 running, 0 held\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2009-May-12 17:33:04 by wenger:</em> <br/>\n\nWe probably need to have configuration to allow users to preserve the old behavior -- I think there are times when people want DAGMan to just make a decent attempt at removing its children, but not use up resources making sure.</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "defect", "last_change": "2010-Jan-31 13:47", "status": "new", "created": "2009-May-07 16:09", "fixed_version": "2009-May-07 16:09", "broken_version": "v070201", "priority": "4", "subsystem": "Dag", "assigned_to": "wenger", "derived_from": "", "creator": "zmiller", "rust": "", "customer_group": "fermi", "visibility": "public", "notify": "zmiller@cs.wisc.edu", "due_date": ""}