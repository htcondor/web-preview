{"id": 6085, "title": "Ticket #6085: Missed shadow updates causes a death spiral", "description": "<blockquote>\nWe have a Schedd that is killing of shadows at a rate of about 1-5Hz; seems mostly due to missing keepalives.  Randomly killing shadows results in a lot of chaos through the system (including the issue fixed in 8.4.11 about disconnecting glexec-based jobs) that could otherwise be avoided by processing the keepalive.\n\n<p>I have verified this is simply a too-busy schedd: no obvious blocking is going on, the UDP buffer (from /proc/net/udp) is indeed at the limit of 128KB.\n\n</p><p>Can we better detect UDP drops or standing buffers?  Can we record killed shadow processes as a metric?  Could we switch to using a unix socket as the command socket?  The unix socket would report failures to enqueue data back to the client.\n\n</p><p>It seems that one keepalive is processed per duty cycle, despite the fact the keepalive is \"light\" to process and expensive when missed.  Todd suggested it would be plausible to process multiple of these in a cycle.\n\n</p><p>In the end, we had to just crank up SHADOW_NOT_RESPONDING_TIMEOUT to a value where the update rate is below what the schedd can handle.</p></blockquote>", "remarks": "<blockquote>\n<em>2017-Mar-08 09:59:12 by tannenba:</em> <br/>\n\nDesign document forthcoming, but ultimately will be going with a small shared memory segment between child and parent.  This way, no keep alives will be dropped, even under extreme loads or blocking behavior.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2017-Mar-13 11:41</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=50303\">[50303]</a></span>: Improve efficiency handling daemon keep alive messages. <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=6085\" onclick=\"get_ticket_and_populate_wrapper('6085'); return false;\" title=\"Missed shadow updates causes a death spiral\">#6085</a></span> Previous to this commit, there was a timer associated with every child process, and every keep alive message reset the timer associated with that child. A reset of a timer walks a linked list of all timers twice - once to find it (no index\u00a0[...]\n (By Todd Tannenbaum )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2017-Mar-09 14:08</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=50294\">[50294]</a></span>: Consolidate code for daemon keepalives into its own class. <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=6085\" onclick=\"get_ticket_and_populate_wrapper('6085'); return false;\" title=\"Missed shadow updates causes a death spiral\">#6085</a></span> Note this commit does not make any logic changes or enhancements to the keepalive code; it simply cut-n-pastes code out of <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DaemonCore\" title=\"Daemon Core\">DaemonCore</a></span> and into a seperate <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DaemonKeepAlive\" title=\"Daemon Keep Alive\">DaemonKeepAlive</a></span> friend class (and source file) so it becomes easier to make changes.\u00a0[...]\n (By Todd Tannenbaum )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2018-Oct-19 14:15", "status": "active", "created": "2017-Jan-10 15:20", "fixed_version": "2017-Jan-10 15:20", "broken_version": "", "priority": "3", "subsystem": "Daemons", "assigned_to": "tannenba", "derived_from": "", "creator": "bbockelm", "rust": "", "customer_group": "cms", "visibility": "public", "notify": "bbockelm@cse.unl.edu", "due_date": ""}