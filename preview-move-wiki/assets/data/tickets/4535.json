{"id": 4535, "title": "Ticket #4535: Reject DAGs that try to write to read-only file systems", "description": "<blockquote>\nOn Tue, 12 Aug 2014, Tom Downes wrote:\n\n<p>I'm receptive to the idea that you can only do so much to stop stupid\nbut...\n\n</p><p>I have 2 users who were running DAGs that were attempting to write to\na read-only filesystem. I think these DAGs are bonked for their own\nspecial-snowflake reasons and it so happens that when they were first\nsubmitted long ago it was a rw filesystem. It got filled up along the\nway, brought down the cluster and I decided to make it read-only;\nthese users did not change their jobs accordingly. But, at some point,\nthese DAGs probably started up OK and successfully submitted jobs.\n\n</p><p>After upgrading to 8.2.2 today and rebooting to get a kernel patch\ninstalled, I found that after restarting the schedd, these\ncondor_dagmans would get stuck in idle and condor_q was unresponsive\nto the point where I had to turn the tool multiplier up to 100 and\nrun, e.g..\n\n</p><p></p><pre>  condor_rm -constraint 'JobUniverse == 7' user\n</pre>\n\n<p>It did not go unnoticed that these tools now allow translate a\nusername argument into the appropriate constraint, thanks.\n\n</p><p>strace -p pid_of_schedd showed a lot of hits involving the read-only\nfilesystem and an error  like -1 O_RDONLY (my strace output is lost to\nsands of time). It moved on from each error quickly but would move\nright on to another instance of the error (in one case a user had ~15\nDAGs all making the same mistake).\n\n</p><p>So, it would be nice if condor_schedd could detect this problem and\nreject a DAG. I'm not sure if it was a DAG job trying to write to the\nfilesystem or the condor_dagman itself but the fact that the\nJobUniverse=7 jobs were idling suggests it was the condor_dagman.\n\n</p><p></p><hr/>\nOkay, I'll make a gittrac ticket for this.  We'll have to do some thinking\nabout how things should work, and where the detection should happen.  For\nexample, if the problem is that the workflow log is on a read-only\nfilesystem, DAGMan itself could detect that before submitting any jobs.\nIf the dagman.out file is on a read-only filesystem, I think that would have\nto get detected in daemoncore.\n\n<p>Kent</p></blockquote>", "remarks": "<blockquote>\n<em>2015-Sep-22 11:51:34 by tpdownes:</em> <br/>\n\nIn-person discussion Kent+Tom. We both think it's worthwhile to pursue ability of DAGMan to test writability of nodes.log file prior to submitting jobs because DAGMan simply won't know jobs are completing unless this file exists.\n\n<p>Targeting 8.5 series so prioritize at 3.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2016-Apr-13 13:06", "status": "defer", "created": "2014-Aug-14 10:48", "fixed_version": "2014-Aug-14 10:48", "broken_version": "v030300", "priority": "5", "subsystem": "Dag", "assigned_to": "", "derived_from": "", "creator": "wenger", "rust": "", "customer_group": "ligo", "visibility": "public", "notify": "wenger@cs.wisc.edu, zmiller@cs.wisc.edu, tpdownes@gravity.phys.uwm.edu,pcouvare@caltech.edu", "due_date": ""}