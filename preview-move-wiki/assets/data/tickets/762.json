{"id": 762, "title": "Ticket #762: Need documentation for condor_hdfs", "description": "<blockquote>\nWe need a general section describing what condor_hdfs does, what hdfs does, why condor_hdfs is more than just running hdfs alongside Condor, and how to install/configure condor_hdfs (including all configure knobs - for each knob there should be a description and a documented default).\n\n<p>Faisel, please write-up a first pass at this documentation.  You can either coordinate directly w/ Karen and place it directly into the Condor Manual, or you could write it up on the wiki and ask Karen to move it into the Manual.</p></blockquote>", "remarks": "<blockquote>\n<em>2009-Nov-18 17:46:13 by faisal:</em> <br/>\n\nSee attachment for documentation. Please let me know any modifications required.\n\n<p></p><hr/>\n<em>2009-Nov-19 10:08:35 by tannenba:</em> <br/>\n\nOk, all the config knobs are there (good), but this document is a bit sparse on background, motivation, explanation, etc.  I just gave the lowdown on all this to Karen, and she will take a stab at beefing this up.\n\n<p></p><hr/>\n<em>2009-Nov-24 11:38:10 by smoler:</em> <br/>\n\nTodd asked me to get my questions into the ticket. So, here are questions that need answers:\n\n<p>1.  Please better specify the syntax for a host and port number (as in the configuration variable HDFS_NAMENODE).  Is it a sinful string, or perhaps something different?\n\n</p><p>Sinful string would be &lt;a.b.c.d:port&gt;\n\n</p><p>2. What will be Condor's default value, if configuration variable HDFS_LOG4J is not specified?\n\n</p><p>3. The description given for the 2 configuration variables\nHDFS_ALLOW and HDFS_DENY need clarification for me to be able\nto place them in the manual.\n\n</p><p>The Word document says they are host based, and then refers to the descriptions of non-host-based variable definitions as overriding values.  Additional grammar errors in the description makes it worse than difficult for me to figure out what these variables do.  In the warn(ing) listed, I think that the prose suggests that setting either one of these causes values for both READ and WRITE to be defined. Is that right?\n\n</p><p>The other part of the warn(ing) suggests that this doesn't work if Condor is not invoking Hadoop jar files incorporated into the Condor release.  Does ANYTHING work in this case?\n\n</p><p>4. Attached Word document defines config knob HDFS_NAMENODE_WEB, while the table that maps Condor knobs to HDFS XML variable names defines HDFS_DATANODE_WEB.  Which is it?  If the answer happens to be both, then the\ndefinition of one is missing and the mapping of the other is missing.\n\n</p><p></p><hr/>\n<em>2009-Nov-25 10:07:01 by tannenba:</em> <br/>\n\nKaren, re question number 4 above, there is both <code>HDFS_DATANODE_WEB</code> and <code>HDFS_NAMENODE_WEB</code>.  Both should be of the format <code>x.x.x.x:0</code>.  I <em>think</em> only <code>HDFS_NAMENODE_WEB</code> must be defined, as <code>HDFS_DATANODE_WEB</code> will default to a reasonable value for must folks of 0.0.0.0:0 which means bind to the default interface on a dynamic port.\n\n<p>As for mappings to the hdfs xml config file, <code>HDFS_DATANODE_WEB</code> maps to <code>dfs.datanode.http.address</code>, and <code>HDFS_NAMENODE_WEB</code> maps to <code>dfs.http.address</code>.\n\n</p><p>You also find <a class=\"external\" href=\"http://hadoop.apache.org/common/docs/current/hdfs-default.html\">this link</a> helpful.\n\n</p><p></p><hr/>\n<em>2009-Nov-25 14:17:57 by faisal:</em> <br/>\n\nThanks for these questions:  I tried to give more description of how access filters in HDFS are implemented. Please let me know if they make more sense then before.\n\n<p>HDFS_ALLOW and HDFS_DENY are used to regulate access to HDFS cluster. Here is more detail on how the access control works in HDFS.\n\n</p><p> HDFS provides very minimal access control mechanism (if at all). Specifically it lacks any regular expression based host or IP  access filters which otherwise are used through-out  Condor. I added a way to regulate access to HDFS cluster using a similar mechanism as we have for Condor.\n\n</p><p> On startup HDFS daemon (<span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DaemonCore\" title=\"Daemon Core\">DaemonCore</a></span> daemon) looks for HDFS_ALLOW and HDFS_DENY in Condor's configuration files.  If these knobs exist, their values are used to filter access. Otherwise allow and dney access is configured using Condor's existing knobs for access control. Below is this mapping:\n\n</p><p>if HDFS_ALLOW is missing: Allow filter will be configured using union of values from these knobs:\n\n</p><p>a) ALLOW_READ\n\n</p><p>b) ALLOW_DENY\n\n</p><p>c) HOSTALLOW_READ\n\n</p><p>d) HOSTALLOW_DENY\n\n</p><p>Similarly, if HDFS_DENY is missing: Deny filter will be configured using union of values from these knobs\n\n</p><p>a) DENY_READ\n\n</p><p>b) DENY_WRITE\n\n</p><p>c) HOSTDENY_READ\n\n</p><p>d) HOSTDENY_WRITE\n\n</p><p>The mappings from Condor's access filter and HDFS access filter is not one-to-one. There are two major differences.\n\n</p><p>First, In HDFS we don't make any distinction between read access or write access. It is either allow a host/IP or This explain why mappings involving allow and deny filters considers both read and write combinations of corresponding configuration in Condor.\n\n</p><p>Second major difference is that Condor's configuration for above filters also includes user and host combination e.g user@*.cs.wisc.edu. When copying over values HDFS simply ignores any entry that specify a user-host combination.\n\n</p><p>As these above filters are an additional feature by us, they will not work if someone tries to use version of Hadoop software not shipped by us. In that case these mappings from Condors configuration file to Hadoop's XML files will simply be ignored. Of course there won't be any access control in that case as well.\n\n</p><p></p><hr/>\n<em>2009-Nov-25 14:19:40 by faisal:</em> <br/>\n\nFew other things you asked. Pelease let me know if these need more detail as well. Thanks a lot!\n\n<p>The default value of HDFS_LOG4J is INFO.\n\n</p><p>The required value for HDFS_NAME node is a sinful string (a.b.c.d:port).\n\n</p><p></p><hr/>\n<em>2009-Nov-30 14:11:41 by smoler:</em> <br/>\n\nIn the Word document, the table gives a mapping of the configuration variable <code>HDFS_REPLICATION</code>, but no configuration variable of this name is defined.  So, if it is a Condor configuration variable, we need a definition of what it does,\nas well as a default value.\n\n<p></p><hr/>\n<em>2009-Dec-10 12:01:41 by faisal:</em> <br/>\n\nHDFS_REPLICATION:\n\n<p>HDFS replicates blocks for each files for fault tolerance. This configuration knobs can be used to configure the replication factor for these blocks. We don't perform any extra steps for this knob in Condor just pass it to dfs.replication in HDFS configuration files.\n\n</p><p></p><hr/>\n<em>2009-Dec-11 13:39:35 by smoler:</em> <br/>\n\nInfo from an e-mail, interpreted by Karen:\n\n<p>HDFS_REPLICATION is a Condor configuration variable.\n\n</p><p>It is optional, and no default value is passed on to the HDFS configuration if it is not set. HDFS has its own default value of 3 that it uses, which is why setting it in a Condor configuration is optional, with no default.\n\n</p><p>If set, it is an integer, and represents the replication factor used by HDFS.\n\n</p><p>If set, it maps to the HDFS configuration variable dfs.replication</p></blockquote>", "derived_tickets": "", "attachments": "<blockquote>\n<ul>\n<li><a href=\"attach_get/124/HDFS_Doc_v2.doc\">HDFS_Doc_v2.doc</a>\n47104 bytes added by faisal on 2009-Nov-18 23:45:32 UTC.\n<br/>\nDocumentation for current version of HDFS daemon.<br/>\n</li></ul>\n</blockquote>", "check_ins": "", "type": "doc", "last_change": "2010-Jan-31 13:15", "status": "resolved", "created": "2009-Sep-23 08:58", "fixed_version": "2009-Sep-23 08:58", "broken_version": "", "priority": "2", "subsystem": "Daemons", "assigned_to": "smoler", "derived_from": "", "creator": "nleroy", "rust": "", "customer_group": "other", "visibility": "public", "notify": "smoler@cs.wisc.edu,faisal@cs.wisc.edu", "due_date": ""}