{"id": 3606, "title": "Ticket #3606: Batch VM requests.", "description": "<blockquote>\nTony Tiradani writes:\n\n<p></p><div class=\"blockquote\">\n<table width=\"95%\"><tbody><tr><td>\u00a0</td><td>\n  \nCould we add the ability to request N number of VMs in one request for the\nEC2 universe?  Currently, if I want 100 VMs, HTCondor will iterate through\nand make 100 requests.  Additionally, if I understand things correctly, it\nwill then perform 100 EC2DescribeInstances calls.  If HTCondor will make one\ncall for 100 VMs, then only make one EC2DescribeInstances call, this will\ndramatically reduce the load on OpenStack Cloud controllers.\n</td></tr></tbody></table></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2013-May-02 09:14:15 by tlmiller:</em> <br/>\n\nThe 100 status requests occur because we still ask about a job individually when its state changes.  There are two potential work-arounds: first, set the state of the job when we create it to its initial state ('pending', IIRC; possibly 'pending evaluation' for Spot); or second, adjusting the batch update code so that we can obtain and distribute all the information we would obtain via our single-instance query, thereby obviating the need for single-intance queries (and removing them entirely, rather than avoiding making them).\n\n<p></p><hr/>\n<em>2013-May-02 09:32:58 by tlmiller:</em> <br/>\n\nI need to investigate how multiple-instance requests interact with idempotence and recovery, especially since requesting 100 VMs may get you any number of them, up to 100.  (If we crash after sending a multiple-instance request but before cramming the instance IDs into the queue, how do we know how many there are supposed to be?)\n\n<p>Also, to preserve our usual semantics, we may end up needing to implement this an optimization within the EC2 GAHP and/or the grid manager (e.g., one submit per cluster); recognizing this opportunity is its own problem.  (Also, if we require a minimum of 100 VMs as well as a maximum, the queue won't be behaving properly if fewer than that are available.)\n\n</p><p></p><hr/>\n<em>2014-Feb-18 11:25:18 by tlmiller:</em> <br/>\n\nOne implementation possibility is to handle client token creation and RunInstances() batching in the resource.  Thus:\n\n<p>- Instead of unconditionally generating a new client token, each job object asks its resource for a client token, passing the same set of arguments along that it would to the GAHP to run its instance.\n\n</p><p>- We treat this call as if it were a GAHP client call -- we come back some time later and call it again to find out if the resource has generated a client token for us.\n\n</p><p>- The resource pauses for a few seconds to wait for identical instance requests to enter the queue and ask for a client token.  Identical requests all get the same client token, and the resource records how many did.  Once every job has called back (and reduced the outstanding total to 0), the resource will issue a batched command with the appropriate number.\n\n</p><p>- Jobs which get a client token back will then block in GM_START, waiting for a batch status update.  Otherwise, they will create their own client token (in the appropriate state) and proceed normally.\n\n</p><p>- When RunInstances() returns, the resource will hand out instance IDs in an arbitrary order.  If it didn't get enough, it will assign NULL instance IDs.  If a job blocked in GM_START gets a NULL instance ID, it returns to GM_SAVE_CLIENT_TOKEN.  This allows for a second batch request to be issued; it may instead be preferable to set a flag which forces it to generate a new client token immediately (or block in GM_SAVE_CLIENT_TOKEN instead of GM_START, although that has odd semantics).\n\n</p><p>- Recovery is the tricky problem here.  We will have n jobs sharing a single client token, some j of which will not have instance IDs, some k of which will not be getting instance IDs.  However, I think the same process as the previous point will suffice: jobs with instance IDs will retain them, and some j arbitrary job in the set will get instance IDs, and the other k will issue new requests.  Because the VMs are identical and we have no other information about them, it's OK for the job ID to \"change\" during recovery, because we don't remember anything about it.\n\n</p><p></p><hr/>\n<em>2016-May-26 14:37:51 by tlmiller:</em> <br/>\n\nSee ticket <span class=\"ticket\"><a class=\"abandoned\" href=\"/wiki-archive/tickets/?ticket=5691\" onclick=\"get_ticket_and_populate_wrapper('5691'); return false;\" title=\"Expose condor_annex's mechanism(s) for bulk VM requests.\">#5691</a></span>.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2016-May-26 14:38", "status": "abandoned", "created": "2013-May-02 09:10", "fixed_version": "2013-May-02 09:10", "broken_version": "", "priority": "4", "subsystem": "Grid", "assigned_to": "tlmiller", "derived_from": "", "creator": "tlmiller", "rust": "", "customer_group": "fermi", "visibility": "public", "notify": "tiradani@fnal.gov, tstclair@redhat.com", "due_date": ""}