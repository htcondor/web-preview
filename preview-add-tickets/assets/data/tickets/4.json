{"id": 4, "title": "Ticket #4: Integrate Condor with the Hadoop File System", "description": "<blockquote>\nWe want to explore integration of the Hadoop File System (HDFS) into Condor.\n\n<p>The main person doing the work is <a class=\"external\" href=\"mailto:faisal@cs.wisc.edu\">Faisal Khan</a>, a grad student at UW.\n\n</p><p>In brief, we want to:\n</p><ol>\n<li>Run HDFS services as Condor daemons under the Condor Master.\n</li><li>Install HDFS across the CHTC cluster at UW.\n</li><li>Gain experience: Test the performance and fault tolerance of HDFS (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=124\" onclick=\"get_ticket_and_populate_wrapper('124'); return false;\" title=\"Perform some HDFS testing\">#124</a></span>).  What happens when the block space is filled up?  What is the performance of using HDFS via the JNI interface? Is a new JVM spawned for every JNI session?\n</li><li>Explore ways in which running an integrated HDFS + Condor together can be more powerful than running HDFS and Condor separately. (e.g. <span class=\"ticket\"><a class=\"new\" href=\"/tickets?ticket=245\" onclick=\"get_ticket_and_populate_wrapper('245'); return false;\" title=\"Failover of HDFS file server node\">#245</a></span>)\n</li><li>Once Condor File Transfer plugins are working (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=241\" onclick=\"get_ticket_and_populate_wrapper('241'); return false;\" title=\"File Transfer plugins\">#241</a></span>), write a HDFS plugin for the file transfer object</li></ol>\n</blockquote>", "remarks": "<blockquote>\n<em>2009-Mar-31 13:28:48 by dhruba:</em> <br/>\n\n1. is there a condor UI page that can be integrated with the HDFS UI?\n\n<p>2. HDFS has APIs to expose the names of machines that have a replica of blocks in a hdfs file. Can this be exposed through any Condor resource advertisement API? (or something similar to the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=FileTrasferPlugin\" title=\"File Trasfer Plugin\">FileTrasferPlugin</a></span> that exposes various properties associated with the File URI)\n</p><hr/>\n<em>2010-Oct-20 15:59:08 by jfrey:</em> <br/>\n\nBulk change of target version from v070504 to v070505 using ./ticket-target-mover.\n<hr/>\n<em>2011-Jan-27 14:21:33 by danb:</em> <br/>\n\nBulk change of target version from v070505 to v070506 using ./ticket-target-mover.\n<hr/>\n<em>2011-Feb-01 14:49:30 by tannenba:</em> <br/>\n\nBulk change of target version from v070506 to NULL using ./ticket-target-mover.</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=7\" onclick=\"get_ticket_and_populate_wrapper('7'); return false;\" title=\"Run HDFS services as Condor daemons\">#7</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nRun HDFS services as Condor daemons</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=124\" onclick=\"get_ticket_and_populate_wrapper('124'); return false;\" title=\"Perform some HDFS testing\">#124</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nPerform some HDFS testing</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/tickets?ticket=245\" onclick=\"get_ticket_and_populate_wrapper('245'); return false;\" title=\"Failover of HDFS file server node\">#245</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nFailover of HDFS file server node</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nCondor HDFS daemons should publish info to the collector</td></tr>\n</tbody></table>", "attachments": "", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2021-Apr-06 11:39</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=62874\">[62874]</a></span>: Merged <span class=\"chng\"><a href=\"chngview?cn=62873\">[62873]</a></span>, Merge pull request <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span> from jasoncpatton/remove-json-token Add option to local credmon to (not) write access tokens as JSON (HTCONDOR-367) Committer: <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=GitHub\" title=\"Git Hub\">GitHub</a></span>  (By Derek Weitzel )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-09 20:12</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=46489\">[46489]</a></span>: Merged <span class=\"chng\"><a href=\"chngview?cn=46483\">[46483]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=46484\">[46484]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=46485\">[46485]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=46486\">[46486]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=46487\">[46487]</a></span>, <span class=\"chng\"><a href=\"chngview?cn=46488\">[46488]</a></span>, Merge pull request <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span> from zhangzhehust/network_namespaces Unittest for Lark Code &amp; Implementation of invoking network policy script using Hook mechanism (By Brian Bockelman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-19 17:02</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15408\">[15408]</a></span>: Added recursive copy target for installing hadoop jars under libexec. (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-19 15:26</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15402\">[15402]</a></span>: Added an extra statement to remove previously installed hdfs folder under exteranls_install_dir (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-19 15:19</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15401\">[15401]</a></span>: Added hadoop software as an external. (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-14 12:25</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15347\">[15347]</a></span>: Log files created by log4j of HDFS goes under a subdir under log folder. (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) This avoids exposing of log directory.  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-14 12:04</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15345\">[15345]</a></span>: Added example configuration file for HDFS daemon. Removed an old README file. (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-11 16:02</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15301\">[15301]</a></span>: Merge of hadoop code from V7_hadoop-branch including Visual Studios project file for condor_hdfs (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-11 13:21</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15297\">[15297]</a></span>: Added a param to specify hadoop's log4j debug string (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jul-24 12:57</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15152\">[15152]</a></span>: Fix: Pipe redirection passed to Create_Process had missing entries for stderr/stdin. (related <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jul-16 13:01</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15105\">[15105]</a></span>: Use libexec as default location for hadoop jar file. Use condor's log dir for site.xml file (related <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jul-08 11:10</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=15037\">[15037]</a></span>: Added ability to run secondary namenode (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>). May be helpful in doing (<span class=\"ticket\"><a class=\"new\" href=\"/tickets?ticket=245\" onclick=\"get_ticket_and_populate_wrapper('245'); return false;\" title=\"Failover of HDFS file server node\">#245</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jun-03 14:35</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14828\">[14828]</a></span>: Handle data types when publishing <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>) in hdfs daemon (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 19:41</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14755\">[14755]</a></span>: Merged <span class=\"chng\"><a href=\"chngview?cn=14754\">[14754]</a></span>, Merge branch (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) Merge branch 'V7_3-hadoop-branch'  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 19:39</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14754\">[14754]</a></span>: (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) Cleanly handled termination code from hadoop process. A basic substrate to publish <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> from Hadoop (<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>). This commit also handles upgrading hadoop jar files to a newer version.  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Mar-20 13:45</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14270\">[14270]</a></span>: Merged <span class=\"chng\"><a href=\"chngview?cn=14216\">[14216]</a></span>, Merge branch 'V7_3-hadoop-branch' (<span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Mar-11 15:26</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=14216\">[14216]</a></span>: Initial revision of hadoop file system daemon (see <span class=\"ticket\"><a class=\"active\" href=\"/tickets?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>). Code reviewed by Greg Quinn.  (By faisal )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2012-Oct-16 13:10", "status": "active", "created": "2009-Jan-13 13:39", "fixed_version": "2009-Jan-13 13:39", "broken_version": "", "priority": "3", "subsystem": "Unknown", "assigned_to": "ilikhan", "derived_from": "", "creator": "gthain", "rust": "", "customer_group": "other", "visibility": "public", "notify": "gthain@cs.wisc.edu,tannenba@cs.wisc.edu", "due_date": "PARENT"}