{"id": 2392, "title": "Ticket #2392: Changes to shadow log file initialization routines have broken SOAP", "description": "<blockquote>\nPrior to 7.6.x it was commonplace for us to set:\n\n<p>QUEUE_ALL_USERS_TRUSTED = True\n\n</p><p>On our SOAP-enabled schedulers and then submit jobs  with \"Owner = <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=AnyOwnerWeLikeEvenIfItDoesNotExist\" title=\"Any Owner We Like Even If It Does Not Exist\">AnyOwnerWeLikeEvenIfItDoesNotExist</a></span>\" through the SOAP API. The jobs were also set to not run as owner on the execute nodes. The execute nodes are set up to run as logged-in domain users.\n\n</p><p>On Window we would have the scheduler daemons running as a domain account, on Linux it would be context-switched to a local account on the machine. Condor would simple initialize the log files for the job under the spool/ directory as the user the schedd and shadow processes were running as.\n\n</p><p>This worked great.\n\n</p><p>Starting with 7.6.2 this setup now fails. Condor keeps trying to initialize the log files as the user found in the Owner attribute on the job. Subsequently shadow start fails because this owner never exists on the local machine. I see in the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ShadowLog\" title=\"Shadow Log\">ShadowLog</a></span>:\n\n</p><p>08/15/11 16:10:48 Initializing a VANILLA shadow for job 1736.9\n08/15/11 16:10:48 (1736.9) (530): passwd_cache::cache_uid(): getpwnam(\"Daily\") failed: user not found\n08/15/11 16:10:48 (1736.9) (530): Daily not in passwd file\n08/15/11 16:10:48 (1736.9) (530): init_user_ids() failed as user Daily\n08/15/11 16:10:48 (1736.9) (530): set_user_egid() called when <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=UserIds\" title=\"User Ids\">UserIds</a></span> not inited!\n08/15/11 16:10:48 (1736.9) (530): set_user_euid() called when <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=UserIds\" title=\"User Ids\">UserIds</a></span> not inited!\n08/15/11 16:10:48 (1736.9) (530): passwd_cache::cache_uid(): getpwnam(\"Daily\") failed: user not found\n08/15/11 16:10:48 (1736.9) (530): Daily not in passwd file\n08/15/11 16:10:48 (1736.9) (530): WriteUserLog::initialize: init_user_ids() failed!\n08/15/11 16:10:48 (1736.9) (530): Failed to initialize user log to /opt/condor/local/spool/1/1736/9/cluster1736.proc9.subproc0/5585-9.log\n08/15/11 16:10:48 (1736.9) (530): Job 1736.9 going into Hold state (code 22,0): Failed to initialize user log to /opt/condor/local/spool/1/1736/9/cluster1736.proc9.subproc0/5585-9.log\n08/15/11 16:10:48 (1736.9) (530): RemoteResource::killStarter(): DCStartd object NULL!\n\n</p><p>This is true for both Windows and Linux schedulers.\n\n</p><p>In order to make things work I have at least have local accounts on the schedulers that match the names found in any Owner attribute in jobs submitted.\n\n</p><p>While I realize this is the slightly more secure way to go, it's a major hassel and big deviation from the behaviour in pre-7.6.x. I say slightly because really it's just an inconvenience. I can still queue as any user I want with QUEUE_ALL_USERS_TRUSTED. That I now need to use a user who exists on the machine is only a minor upgrade in security to this very open, but incredibly necessary when using SOAP, hole.\n\n</p><p>Ideally I'd like pre-7.6.x behaviour back.\n\n</p><p>If that can't happen can we work out some way to disable this context switching in the shadow so the spawned sub-processes just run and read/write those log files in the spool directory as the user they happen to be running as on startup.\n\n</p><p>It looks like things are failing specifically because init_user_ids() returns false on account of the user the shadow is running as, on both Linux and Windows, does not have the ability to context switch (makes sense, it's not root).</p></blockquote>", "remarks": "<blockquote>\n<em>2011-Aug-23 13:01:58 by ichesal:</em> <br/>\n\n<hr/>\nI tried this with 7.6.1 on Windows, adding a local account to the machine that matched the Owner in the job, and it didn't help. Still the Shadow dies with an unhandled exception. There is most definitely an mrm-prod account on the local machine and it's in the Administrators group.\n\n<p></p><div class=\"code\">\n<pre class=\"code\">08/23/11 12:52:51 Locale: English_United States.1252\n08/23/11 12:52:51 Setting maximum accepts per cycle 4.\n08/23/11 12:52:51 ******************************************************\n08/23/11 12:52:51 ** condor_shadow (CONDOR_SHADOW) STARTING UP\n08/23/11 12:52:51 ** e:\\condor\\7.6.1\\bin\\condor_shadow.exe\n08/23/11 12:52:51 ** SubsystemInfo: name=SHADOW type=SHADOW(6)\nclass=DAEMON(1)\n08/23/11 12:52:51 ** Configuration: subsystem:SHADOW local:&lt;NONE&gt;\nclass:DAEMON\n08/23/11 12:52:51 ** $CondorVersion: 7.6.1 May 31 2011 BuildID: 339001 $\n08/23/11 12:52:51 ** $CondorPlatform: x86_winnt_5.1 $\n08/23/11 12:52:51 ** PID = 167332\n08/23/11 12:52:51 ** Log last touched time unavailable (No such file or\ndirectory)\n08/23/11 12:52:51 ******************************************************\n08/23/11 12:52:51 Using config source: E:\\condor\\7.6.1\\condor_config\n08/23/11 12:52:51 Using local config sources:\n08/23/11 12:52:51 e:\\condor\\7.6.1/condor_config.local\n08/23/11 12:52:51 e:\\condor\\7.6.1/bin\\cycle_cache_config.exe\ne:\\condor\\7.6.1\\cached_config 30 30\nhttp://cycleserver:8080/condor/assigned_template/AMPWMOS15.annuity.aigrs\n.net |\n08/23/11 12:52:51 Not using shared port because USE_SHARED_PORT=false\n08/23/11 12:52:51 DaemonCore: command socket at &lt;10.78.192.37:58046&gt;\n08/23/11 12:52:51 DaemonCore: private command socket at\n&lt;10.78.192.37:58046&gt;\n08/23/11 12:52:51 Setting maximum accepts per cycle 4.\n08/23/11 12:52:51 Will use TCP to update collector\nampwwhmos07.annuity.aigrs.net &lt;10.78.193.194:9618&gt;\n08/23/11 12:52:51 Not using shared port because USE_SHARED_PORT=false\n08/23/11 12:52:51 Spool format version requires &gt;= 1 (I support version\n1)\n08/23/11 12:52:51 Spool format version is 1 (I require version &gt;= 1)\n08/23/11 12:52:51 Reading job ClassAd from STDIN\n08/23/11 12:52:51 Initializing a VANILLA shadow for job 1.16\n08/23/11 12:52:51 (1.16) (167332): init_user_ids: want user\n'mrm-prod@AMPWMOS15', current is '(null)@(null)'\n08/23/11 12:52:51 (1.16) (167332): init_user_ids: failed because user\nswitching is disabled\n08/23/11 12:52:51 (1.16) (167332): WriteUserLog::initialize:\ninit_user_ids() failed!\n08/23/11 12:52:51 (1.16) (167332): Failed to initialize user log to\ne:\\condor\\7.6.1/spool\\1\\16\\cluster1.proc16.subproc0/5666-16.log\n08/23/11 12:52:51 (1.16) (167332): Job 1.16 going into Hold state (code\n22,0): Failed to initialize user log to\ne:\\condor\\7.6.1/spool\\1\\16\\cluster1.proc16.subproc0/5666-16.log\n08/23/11 12:52:51 (1.16) (167332): RemoteResource::killStarter():\nDCStartd object NULL!\n08/23/11 12:52:51 (1.16) (167332): Intercepting an unhandled exception.\n08/23/11 12:52:51 (1.16) (167332): Dropping a core file.\n</pre></div>\n\n\n<p>The daemons were running as a domain account, also with Administrator privileges.\n\n</p><p></p><hr/>\n<em>2011-Aug-25 10:58:05 by ichesal:</em> <br/>\n\nHere's the contents of the core file that's mentioned in that log output above:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">\n//=====================================================\nPID: 260784\nException code: C0000005 ACCESS_VIOLATION\nFault address:  00BB2DAC 01:00001DAC e:\\condor\\7.6.1\\bin\\condor_shadow.exe\n\nRegisters:\nEAX:00000001\nEBX:00000000\nECX:00000000\nEDX:000000B8\nESI:021A2F70\nEDI:0216EA30\nCS:EIP:0023:00BB2DAC\nSS:ESP:002B:00B3F974  EBP:00000016\nDS:002B  ES:002B  FS:0053  GS:002B\nFlags:00010206\n\nCall stack:\nAddress   Frame\n00BB2DAC  00B3F9A0  BaseShadow::updateJobInQueue (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:1184)\n00BB3545  00B3F9B8  BaseShadow::holdJob (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:422)\n00BB3A4B  00B3FA14  BaseShadow::initUserLog (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:835)\n00BB534D  00B3FAA0  BaseShadow::baseInit (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:162)\n00BC7888  00B3FAB4  UniShadow::init (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow.cpp:108)\n00BC8558  00B3FAE4  initShadow (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow_v61_main.cpp:273)\n00BC86D5  00B3FB1C  startShadow (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow_v61_main.cpp:295)\n00BC8911  00B3FB24  main_init (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow_v61_main.cpp:382)\n00BE2F68  00B3FBBC  dc_main (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_daemon_core.v6\\daemon_core_main.cpp:2377)\n00BE30AF  00B3FBD4  main (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_daemon_core.v6\\daemon_core_main.cpp:2443)\n00CB54D9  00B3FC18  __tmainCRTStartup (f:\\dd\\vctools\\crt_bld\\self_x86\\crt\\src\\crtexe.c:582)\n76F0F13C  00B3FC24  BaseThreadInitThunk+E\n777AD80D  00B3FC64  RtlCreateUserProcess+8C\n777ADA1F  00B3FC7C  RtlCreateProcessParameters+4E\n\n//=====================================================\n{/endcode}\n\n----\n_2011-Aug-25 10:59:01 by ichesal:_ {linebreak}\n(Yes, I suck at remembering wiki syntax...in my defence there are too many wiki syntaxes to remember these days...)\n\nHere it is again:\n\n{code}\n//=====================================================\nPID: 260784\nException code: C0000005 ACCESS_VIOLATION\nFault address:  00BB2DAC 01:00001DAC e:\\condor\\7.6.1\\bin\\condor_shadow.exe\n\nRegisters:\nEAX:00000001\nEBX:00000000\nECX:00000000\nEDX:000000B8\nESI:021A2F70\nEDI:0216EA30\nCS:EIP:0023:00BB2DAC\nSS:ESP:002B:00B3F974  EBP:00000016\nDS:002B  ES:002B  FS:0053  GS:002B\nFlags:00010206\n\nCall stack:\nAddress   Frame\n00BB2DAC  00B3F9A0  BaseShadow::updateJobInQueue (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:1184)\n00BB3545  00B3F9B8  BaseShadow::holdJob (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:422)\n00BB3A4B  00B3FA14  BaseShadow::initUserLog (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:835)\n00BB534D  00B3FAA0  BaseShadow::baseInit (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\baseshadow.cpp:162)\n00BC7888  00B3FAB4  UniShadow::init (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow.cpp:108)\n00BC8558  00B3FAE4  initShadow (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow_v61_main.cpp:273)\n00BC86D5  00B3FB1C  startShadow (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow_v61_main.cpp:295)\n00BC8911  00B3FB24  main_init (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_shadow.v6.1\\shadow_v61_main.cpp:382)\n00BE2F68  00B3FBBC  dc_main (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_daemon_core.v6\\daemon_core_main.cpp:2377)\n00BE30AF  00B3FBD4  main (c:\\condor\\execute\\dir_3900\\userdir\\src\\condor_daemon_core.v6\\daemon_core_main.cpp:2443)\n00CB54D9  00B3FC18  __tmainCRTStartup (f:\\dd\\vctools\\crt_bld\\self_x86\\crt\\src\\crtexe.c:582)\n76F0F13C  00B3FC24  BaseThreadInitThunk+E\n777AD80D  00B3FC64  RtlCreateUserProcess+8C\n777ADA1F  00B3FC7C  RtlCreateProcessParameters+4E\n\n//=====================================================\n\n</pre></div>\n\n\n<p></p><hr/>\n<em>2012-Jan-09 14:40:58 by ichesal:</em> <br/>\n\nJust looking through the 7.6.x release notes now and it looks like this may be fixed with the changes for <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2004\" onclick=\"get_ticket_and_populate_wrapper('2004'); return false;\" title=\"condor_submit -remote for unknown user\">#2004</a></span> released in 7.6.4. Haven't tried it yet, but it looks semantically identical to the SOAP submission.\n\n<p></p><hr/>\n<em>2012-Mar-16 12:11:34 by ichesal:</em> <br/>\n\nI just tried the changes from <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2004\" onclick=\"get_ticket_and_populate_wrapper('2004'); return false;\" title=\"condor_submit -remote for unknown user\">#2004</a></span> and no, this doesn't fix the issues with jobs submitted via the SOAP interface in 7.6.6.\n\n<p></p><hr/>\n<em>2012-Mar-16 12:49:50 by matt:</em> <br/>\n\nHave you tried using <span class=\"wiki\"><a href=\"wiki?p=CondorAviary\" title=\"Condor Aviary\">CondorAviary</a></span>?\n\n<p></p><hr/>\n<em>2012-Jul-11 15:57:48 by tannenba:</em> <br/>\n\nIan is able to work around this problem. If they submit all jobs as the same user that Condor is running as on the instance it works. This is what the SOAP regression tests are doing. If Owner != account Condor is running as it fails for Ian.\n\n<p></p><hr/>\n<em>2012-Aug-28 17:09:41 by tannenba:</em> <br/>\n\nResolving. Got an email from Ian stating that indeed if the daemons are running as root/localsystem as designed then everything works ok.</blockquote>", "derived_tickets": "", "attachments": "<blockquote>\n<ul>\n<li><a href=\"attach_get/443/ShadowLog.530.log\">ShadowLog.530.log</a>\n24623 bytes added by ichesal on 2011-Aug-15 22:02:45 UTC.\n<br/>\nComplete <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ShadowLog\" title=\"Shadow Log\">ShadowLog</a></span> file for the failed startup in 7.6.2. Happens to be for a Linux scheduler but it's the same error on Windows.<br/>\n</li></ul>\n</blockquote>", "check_ins": "", "type": "incident", "last_change": "2012-Sep-18 07:34", "status": "abandoned", "created": "2011-Aug-15 16:48", "fixed_version": "2011-Aug-15 16:48", "broken_version": "v070602", "priority": "2", "subsystem": "Daemons", "assigned_to": "tannenba", "derived_from": "", "creator": "ichesal", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tstclair@redhat.com tannenba@cs.wisc.edu", "due_date": ""}