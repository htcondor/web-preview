{"id": 6366, "title": "Ticket #6366: corrupt job_queue.log entries", "description": "<blockquote>\nIn the process of tracking down another bug, the schedd on submit-4 repeated crashed with an invalid job_queue.log.  The entries in question:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">103 4416990.0 LastRejMatchTime 1501776513\n16654.0 LastRejMatchTime 1501776512\n103 4416686.0 LastRejMatchReason \"no match found \"\n103 4416686.0 LastRejMatchTime 1501776512\n103 4416724.0 LastRejMatchReason \"no match found \"\n103 4416724.0 LastRejMatchTime 1501776513\n103 4416769.0 LastRejMatchReason \"no match found \"\n103 4416769.0 LastRejMatchTime 1501776513\n103 4416928.0 LastRejMatchReason \"no match found \"\n103 4416928.0 LastRejMatchTime 1501776513\n103 4416929.0 LastRejMatchReason \"no match found \"\n103 4416929.0 LastRejMatchTime 1501776513\n103 4416948.0 LastRejMatchReason \"no match found \"\n103 4416948.0 LastRejMatchTime 1501776513\n16654.0 LastRejMatchTime 1501776512\n103 4416686.0 LastRejMatchReason \"no match found \"\n103 4416686.0 LastRejMatchTime 1501776512\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2017-Aug-08 11:47:15 by jfrey:</em> <br/>\n\nThe job_queue.log contained 16 invalid lines, written over the course of 12 minutes. All of the lines appear to be incomplete entries that are missing a variable number of their initial characters.\n\n<p></p><hr/>\n<em>2017-Aug-08 11:55:32 by jfrey:</em> <br/>\n\nWhen the schedd first opens the job_queue.log file (<code>LoadClassAdLog()</code>), it does not use O_APPEND. When the schedd opens a new file for truncation (<code>TruncateClassAdLog()</code>), it does use O_APPEND. If the file is \"clean\" when initially read in (i.e. no transactions and no incomplete entries), the schedd will use the non-append file descriptor for further writes. If the file isn't \"clean\", then it immediately does a truncation (resulting in a file descriptor in append mode).\n\n<p>The corruption we're seeing could be explained by a forked child process writing to the log file in non-append mode. Always opening the file in append mode would help prevent this, but we should also understand how the extra writes are happening.\n\n</p><p></p><hr/>\n<em>2017-Aug-10 12:55:08 by jfrey:</em> <br/>\n\nThe log corruption appears to be caused by valgrind. I wrote a simple program that called fopen(), fprintf(), and _exit(). When I run it normally, the file is empty. When I run it under valgrind, the file contains the text from my fprintf().\n\n<p>The corruption always occurs around updates of <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRejMatchTime\" title=\"Last Rej Match Time\">LastRejMatchTime</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRejMatchReason\" title=\"Last Rej Match Reason\">LastRejMatchReason</a></span>, which are done non-durable, which means they aren't fflush()d. The corrupted job_queue.log was generated while the schedd was run under valgrind (while Greg investigated a crash).\nThroughout the file, groups of updates to <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRejMatchTime\" title=\"Last Rej Match Time\">LastRejMatchTime</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRejMatchReason\" title=\"Last Rej Match Reason\">LastRejMatchReason</a></span> are duplicated, sometimes jumping backward in time (duplicating entries from a second ago).\n\n</p><p>I believe whenever the schedd forked a child helper process when ad updates were buffered by stdio, valgrind caused those updates to be flushed when the child process exited.</p></blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "incident", "last_change": "2017-Dec-08 16:14", "status": "abandoned", "created": "2017-Aug-07 11:00", "fixed_version": "2017-Aug-07 11:00", "broken_version": "v080702", "priority": "3", "subsystem": "", "assigned_to": "jfrey", "derived_from": "", "creator": "gthain", "rust": "", "customer_group": "chtc", "visibility": "public", "notify": "", "due_date": ""}