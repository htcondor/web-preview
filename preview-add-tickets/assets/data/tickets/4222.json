{"id": 4222, "title": "Ticket #4222: Networking and HTC challenges", "description": "<blockquote>\nThis is research/brainstorming for a talk, and it probably not of interest.\n\n<p>What are network related issues you need to think about with HTC?\n\n</p><p>\"Intermediary\" - Anyone between the client and the server.  Could the operating systems on either side, the network cards on either side, routers, switches, NATs, and more.\n\n</p><p>\"server\" - The side listening for an inbound TCP connection or UDP packet.  A given process might be both a server and a client.\n\n</p><p>\"client\" - The side initiating a TCP connection or sending a UDP packet.  A given process might be both a server and a client.\n\n</p><p>FINITE RESOURCES\n\n</p><p></p><ul>\n<li>Bandwidth - Can you transmit required data quickly enough to meet your needs?  You might be constrained by the physical links as well as any intermediaries.  For example, many firewalls process packets more slowly than their network connections otherwise support.  Various layers of the system itself may limit bandwidth; security (encryption, decryption, checksumming) in particular can easily be expensive enough to be a bottleneck.  Security can also increase the amount of traffic necessary; authentication of both sides can easily add multiple messages to ultimately send a single small message.\n\n<p></p></li><li>CPU - Can your system requests quickly enough?  Can your system take advantage of multiple CPU cores in a single system to manage load?  Can your system take advantage of multiple computers, potentially distributed across the world to manage load?  How much CPU does your security subsystem require; security (encryption, decryption, checksumming) can use a lot.\n\n<p></p></li><li>Memory - Memory may be limited by physical RAM and swap, kernel configuration, user-level limits, cgroup limits, or per-process limits.  Adding as security subsystem will require more memory.\n\n<p></p><ul>\n<li>Process memory - Each network connection requires some memory in your process. Your library providing the networking interface is almost certainly doing memory allocation on your behalf.\n\n<p></p></li><li>Kernel memory - Each network connection, including incomplete ones, requires some memory for the kernel.\n</li></ul>\n\n<p></p></li><li>File descriptors - Each connection requires an FD, and listening for incoming connections is another FD.  File descriptors are a finite resource on the client and server.  Multiple layers can impose limits: per process limits (ulimit), per user limits, per process group limits (by cgroups or similar), configurable system-wide limits (/proc/sys/fs/file-max on Linux), or technical limits (Only 2^32 FDs can be described in a single program on Linux. I believe Linux can only manage 2^32 total FDs).\n\n<p></p></li><li>Ports -  Ports are a finite resource.  Only 65535 are available on a given network interface.  In practice, the available number will be much smaller: some will be in use by other processes, some are unavailable to non-root processes, and the system configuration will likely limit the range further (/proc/sys/net/ipv4/ip_local_port_range on Linux controlls the ephemeral ports). Closed connections may continue to hold ports for a while to reduce the risk of port-reuse causing problems (TCP's TIME_WAIT state).  In some cases ports can be shared, but this necessitates adding additional identifying information for each TCP connection or UDP packet.\n\n<p></p><ul>\n<li>All computers behind a NAT share a finite number of ports for all connections to hosts outside of the NAT.\n\n<p></p></li><li>Port pairs - TCP connections are identified by the set {client IP address, client port, server IP address, server port}.  Every such set must be unique, limiting the number of potential simultaneously connections between two IP addresses to about 65535*65535. (In practice, this is not a limit.)\n</li></ul>\n\n<p></p></li><li>Firewall state - A firewall/router/NAT has limited resources to manage connections that traverse it.  It might have limits on simultaneous connections, simultaneous connections being initiated, bandwidth, RAM, or others.\nIf the intermediary runs out of resources, a wide variety of undesirable things might happen: the intermediary may stop processing anything, blocking all traffic; it may break existing connections; it may reject new connections; it may stop processing firewall rules.\n</li></ul>\n\n<p>SECURITY: ACCESS AND PRIVACY\n\n</p><p>There is no security in the transport layer, necessitating that applications implement it themselves.  IP packets can be spoofed, meaning even their origin cannot be trusted.  If a network link is compromised enough, it's possible to spoof a full TCP communication.  No trustworthy information is available about the identify of the other side on a connection.  Data can easily be read, modified, replaced, or deleted by intermediaries.\n\n</p><p></p><ul>\n<li>Network snooping - Are communications over the network encrypted to protect against snooping?\n\n<p></p></li><li>Untrusted servers - Can a client safely identify a server to ensure it doesn't send private data to an interloping attacker or allow an attacker to perform a man-in-the-middle attack to make use of the client's credentials?\n\n<p></p></li><li>Untrusted clients - Can a server safely identify a client to ensure that it doesn't accept commands from an un-trusted source, or allow commands beyond what a given source is permitted to do?  This includes returning potentially private information on otherwise seemingly harmless requests.\n\n<p></p></li><li>Distributing identity information - Who creates the private identity information?  If a central server, how does it authenticate someone requesting an identity?\n\n<p></p></li><li>Distributing authentication information - How do clients and servers test that an identity presented to them is valid and grants a particular set of permissions?  How swiftly is that information distributed? Does it require administrator intervention?\n\n<p></p></li><li>Revoking authentication information - How swiftly can an identity be revoked/invalidated?  Can it be done automatically, or does it require administrator intervention?\n\n<p></p></li><li>Replay attacks - Can an attacker (or even a mistake) replay a previously valid stream and cause something to undesirably happen again?  How do you detect and stop them?\n\n<p></p></li><li>Data corruption - Data might be corrupted by accident or intentionally by an attacker.  Is this detected?  If it is detected, how is it recovered from?\n\n<p></p></li><li>Spoofing - An attacker can send packets that appear to come from a different source.  Can you detect that?  Will you potentially send information to an untrusted source, or bother an innocent source which did not make a request?\n\n<p></p></li><li>Debugging security rejections - How much information do you provide a client when a connection is rejected?  More information may help an attacker refine an attack but also helps a valid user diagnose problems.\n\n<p></p></li><li>Privilege escalation - Are there limits to ensure that a another process/computer does not successfully issue requests that are unnecessary for a given purpose?\n</li></ul>\n\n<p>ROBUSTNESS\n\n</p><p>As a system grows, failures will become increasingly frequent.  It is essential that any non-trivial system be robust in the face of failure.\n\n</p><p></p><ul>\n<li>Invalid traffic - Servers will face invalid traffic from a host of sources.  Will it handle the invalid traffic with grace?  Sources include buggy clients, automated security probes, attackers targeting this particular system, attackers targeting other systems, and more.\n\n<p></p></li><li>Blocking operations - While engaging in a blocking operation, a process/thread becomes unresponsive to other requests.  Is this prepared for?  Seemingly safe operations can block for a long time: DNS requests (We have observed multi-minute delays), reading/writing files (particularly network file systems, slow compressed file systems, potentially any large access), and many more.  Writing a system that is aware of every single blocking action is difficult.  Coping with threads or processes consumes more limited resources (typically CPU, RAM).\n\n<p></p></li><li>Automatic recovery - If a part of the system fails, perhaps by crashing, exiting unexpected, or stopping responding to requests, to what extent that it be restarted?\n\n<p></p></li><li>Over-aggressive recovery - In attempting to recover from a down service, a failed network connection, or almost anything else, could attempts to retry or recover actually cause more problems?  Some sort of throttling may be necessary to avoid consuming up any of wide variety of resources.\n\n<p></p></li><li>Timeouts - If there appears to be a communications problem, how long do you want before giving up?  If you don't wait long enough, you waste effort retrying or unnecessarily abandon a successful operation.  If you wait too long, you waste resources on a task that may never success.  Are both sides maintaining the same timeout?  Is it problematic is half of the connection gives up, but the other waits longer? (For example, a task may continue running after the sender has given up on it.)\n</li></ul>\n\n<p>ADDRESSES\n\n</p><p></p><ul>\n<li>IP addresses are not static - What happens if a computer's IP address changes?  Laptops frequently move between networks.  A VM might be migrated to a different host with a different \"real\" IP address.  A server might be moved from one data center to another.  A server might be rebooted, or even had its network restarted, and acquire a different address from DHCP on restart.\n\n<p></p></li><li>Addresses may be rewritten - A NAT will rewrite addresses.  If an external source is arranging connections between computers, it may be difficult for two computers to establish a direct connection because they only have the NAT's address.  If a message payload contains a computer's \"own\" address, it may not be valid outside of the NAT.\n\n<p></p></li><li>Deceptive addresses - A host might natively see that it has address 1.2.3.4, but external systems should actually use address 5.6.7.8.  This might be because a transparent tunnel is in use (ssh).  The host may not be able to identify 5.6.7.8 without specific configuration.  (HTCondor solves with TCP_FORWARDING_HOST.)\n\n<p></p></li><li>Multi-homed hosts - Not all hosts have a single \"real\" IP address.  A host might have several loopback addresses (anything in 127.0.0.*). A host might have a non-standard loopback address (debian may provide one at 127.0.1.1).  A host might have multiple internal-only IP addresses for virtual machines.  Any given interface might have both an IPv4 address and an IPv6 address. A host might have multiple addresses that access the \"real\" internet as well as multiple address to private networks.  An address might appear to be public, but not be usefully routable (behind a strict firewall).  An address might appear to be private, but be publicly routable (behind a NAT).  Can an administrator select an arbitrary subset to use?  Can an administrator simply say \"all interfaces?\"  If the system needs to report its own IP address to someone else, which address does it pick, or does it provide all of them?  Selecting the IP address that the packet is sent out on is not reliable; the information may be handed off to a different computer that sees a different interface.  If it provides all of them, how can the receiver determine if private addresses are usable?  How do you define a security policy for multi-homed hosts?  Can you potentially have different security policies for different interfaces (\"Only commands that arrive on 192.168.0.50 can issue administrator commands.\")\n</li></ul>\n\n<p>CONNECTIVITY\n\n</p><p></p><ul>\n<li>Connectivity - Are you are able to reach a network at all?  Is it behind a firewall? Is it behind a NAT? Is it on an entirely private network?  If both sides are behind different NATs, they typically cannot connect at all without external assistance.  If both sides are behind the same NAT, can you detect that and establish a direct connection?  A \"public\" address is not guaranteed to be accessible from random computers on the public internet.\n\n<p></p></li><li>UDP is scalable but unreliable - UDP is much lower overhead for the sender and receiver.  For the sender it's \"fire and forget.\"  It doesn't require a dedicated port for each connection.   But it's incredibly unreliable.  It can range from 100% of packets being delivered to nothing being delivered.  Can the system do without UDP?  Can it cope with high levels of packet loss?\n\n<p></p></li><li>Intermediaries may silently drop specific packets.   For example, if ACK packets during a TCP handshake are consistently dropped, it will lead to failed connections that use resources on both sides until the connection times out.\n\n<p></p></li><li>IPv4 and IPv6 - You need to be able to support both simultaneously.\n</li></ul>\n\n<p>BULK DATA TRANSFER\n\n</p><p></p><ul>\n<li>Interruption recovery - If large amounts of data are being transmitted, interruptions are far more common.  Will the system restart from scratch, potentially wasting many resources, or can it recover?\n\n<p></p></li><li>Parallelized transfer - Can requests be parallelized to optimize use of bandwidth?  It may make sense to perform transfers for multiple different tasks simultaneously.  It may make sense to perform parallel transfers of different parts of the same data to take advantage of different network paths, or simply to get more bandwidth out of a single network path (research suggests that multiple connections to a single host can provide more bandwidth than a single connection).\n\n<p></p></li><li>User protocols - Do your users have protocols that they want to read data from or write data to?  Do you support them?  Users may have solutions that better fit their problem domain.\n\n<p></p></li><li>Caching - Caching can potentially dramatically speed transfers and reduce bandwidth usage.  Do you support caching?  How do you decide how large of cache to use, when to expire entries, and which entries to expire?\n</li></ul>\n\n<p>ABUSE\n\n</p><p></p><ul>\n<li>Reflection accomplice -  Can a relatively request on the part of an untrusted source potentially cause a response to be sent to a third party?  This can be used as part of a denial of service attack on the third party.  The third party response might be caused by: a spoofed origin on the initial request (the recent DNS attack used this), gaining limited access to the third party, then having the compromised third party request that itself be attacked, or by requests with specifically allow bringing a third party into the loop (some matchmaking and tunnelling services might do this).  If the response is significantly larger than the request, this also become an amplification attack, meaning the attacker spends relatively little bandwidth to hit a target with much more bandwidth.\n\n<p></p></li><li>Proxy accomplice - Can your system be used as a proxy to obscure the source of an attack, be it denial of service or otherwise?  This might be a direct proxy (HTTP CONNECT, SSH tunnel), or perhaps the ability to request a response to a third party connection where the request can control some of what appears in the response.\n\n<p></p></li><li>Acting as a public file server - Can an unauthorized party store data in your system?  Can an unauthorized party read stored data from your system, either inserted by an unauthorized person, or perhaps an authorized person abusing their privileges.\n</li></ul>\n\n<p>MISCELLANEOUS\n\n</p><p></p><ul>\n<li>Efficient bulk operations - If many operations are being done, can they be bundled together for efficiency?  This might include sending over multiple files, submitting multiple tasks, or checking on the status of many jobs.  For queries, \"get me all of this information\" is better than multiple requests; even better is \"tell me everything that has changed since my last query.\"\n\n<p></p></li><li>Denial of service - How easily can an attacker slow your system to an unacceptable level?  Can a relatively small request on the part of an untrusted source consume a large amount of a limited resource (CPU, RAM, bandwidth) in response?  How well does the system handle a distributed denial of service attack?\n\n<p></p></li><li>Sleep/hiberation - What happens if one of the two sides in a connection goes to sleep/hibernates, then returns later?  What happens if the system that slept fails to notice the sleep and fails to update its clock?  Common causes would include a laptop going to sleep or a VM being hibernated during maintenance.\n\n<p></p></li><li>Debugging - Can you easily get logs and other useful information from all components in a system?  Can you easily align those log to track flow between parts of the system?  Intermediaries that you may have no control over may cause you problems by blocking packets or modifying packets; how can you detect this?\n\n<p></p></li><li>Transient and permanent failures - It is difficult to tell if a failure it transient or permanent. How long should you retry for?  How aggressively should you retry?\n\n<p></p></li><li>IPv6 firewalls - Firewalls are slower processing IPv6 packets and frequently have weaker filtering options.   If a security solution assumes a firewall, it must work with the simpler options offered by IPv6 firewalls today.\n\n<p></p></li><li>Channel bonding - For very high bandwidth needs, channel bonding is a useful technique.  Common solutions require administrator intervention on both sides of a given connection.  Application-level solutions are difficult to establish.\n\n<p></p></li><li>Control channel - During a large data transfer, can the two computers involved still communicate control information?  It may be necessary to send updated credentials to replace some that expire, to explain why the data connection is being aborted, to begin a different, simultaneous operation, or for other uses.\n\n<p></p></li><li>Multiple channels - It may be desirable to have different channels for different purposes between two given computers.  Control information may prefer a channel that is low-latency, but not need high-bandwidth.  Bulk data transmission may prefer a channel that is some combination of high-bandwidth and low cost but not need low-latency.  Secure information may be limited to better secured channels and be willing to sacrifice latency, bandwidth, and cost.\n\n<p></p></li><li>\"Nearby\" systems - It is difficult to determine the connectivity properties of computers involved in the system.  It may be desirable to co-schedule resources on computers with high speed interconnects, to prefer to use caches that with more bandwidth or a lower price to a given node, to identify which nodes can use wake-on-lan to wake each other.\n\n<p></p></li><li>Wake on LAN - Wake on LAN does not work over the general internet.  For power aware computing that puts computers to sleep, it may be necessary to have an always-on computer on each subnet to manage wake-on-lan requests.\n\n<p></p></li><li>Time skew - Is the system using absolute time for any purpose?  This might include agreeing on when to abandon a lease and ensuring log files can be compared across computers.  How are you ensuring that the times remain acceptably synchronized.  Can you detect if the synchronization fails?  When you don't rely on absolute time, it is difficult for two computers to agree upon a shared time since network latency is difficult to measure. For long periods of time, clocks on different computers will drift.\n\n<p></p></li><li>Broken connections - A process may not be alerted if a connection is broken.  If waiting to receive data, it could be waiting fruitless for a long time.  TCP keepalive can help, but must be set to an appropriate duration.\n\n<p></p></li><li>Finding peers - How do you identify other computers/processes that are part of the system?  Do they report in to a central server or some sort of distributed name service?  Does a central service maintain a fixed list?  What happens when a computer or process disappears?\n\n<p></p></li><li>DNS isn't always available - Users like seeing DNS names in their logs and configuration files.  Unfortunately DNS adds complications.  Reverse DNS entries are frequently not available.  Computing clusters frequently have no DNS entries at all.\n\n<p></p></li><li>Ports - Can the system run on arbitrary ports?  If the system wants a particular port, how will it cope if the port was claimed by another process?\n\n<p></p></li><li>Coping with outages - What happens when a given process or computer goes down?  What happens when a given subset of processes or computers goes down?  What happens if you experience a network split?</li></ul>\n</blockquote>", "remarks": "<blockquote>\n</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "todo", "last_change": "2014-Feb-21 13:40", "status": "resolved", "created": "2014-Feb-19 15:46", "fixed_version": "2014-Feb-19 15:46", "broken_version": "", "priority": "1", "subsystem": "", "assigned_to": "adesmet", "derived_from": "", "creator": "adesmet", "rust": "", "customer_group": "other", "visibility": "public", "notify": "", "due_date": ""}