{"id": 4040, "title": "Ticket #4040: Optimize condor UserLog IO, via batching", "description": "<blockquote>\nWe ran into an issue where a user submitted 60K jobs (not an issue), but then reprioritized all 60K jobs (condor_qedit <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=JobPrio\" title=\"Job Prio\">JobPrio</a></span>).  Condor handled the condor_qedit just fine, but didn't handle the logging of the attribute changes well.  This IO backed up the schedd, caused SECMAN timeouts for clients, and caused matching failures from the negotiator to that schedd.\n\n<p>If a user streams job changes, we need the schedd to better stream the log output when there are multiple queued entries instead of doing the normal per-entry lock/write/unlock.  It was the repeated file locking per entry that caused the excessive slowness in this particular case today.\n\n</p><p>Furthermore, the user was adjusting the priority of all of their jobs to be the same (lower) priority to give space to their fellow teammates.  This mean that for some jobs the condor_edit was setting <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=JobPrio\" title=\"Job Prio\">JobPrio</a></span> to the same value it had been set to previously, but also logging that it set the value to the same value as previously.  I'd like to see those condor_qedit's become noop's and to not log.</p></blockquote>", "remarks": "<blockquote>\n<em>2013-Nov-05 15:03:55 by tannenba:</em> <br/>\n\nI think the root of the problem here is <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1791\" onclick=\"get_ticket_and_populate_wrapper('1791'); return false;\" title=\"condor_qedit and condor_prio changes should show up in the UserLog\">#1791</a></span>, which added a userlog event for an job attribute changes via qedit and also job priority changes.  I propose reverting <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1791\" onclick=\"get_ticket_and_populate_wrapper('1791'); return false;\" title=\"condor_qedit and condor_prio changes should show up in the UserLog\">#1791</a></span>. The user event log is not a mirror of the job_queue log; it has a specific purpose.  The motivation for <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1791\" onclick=\"get_ticket_and_populate_wrapper('1791'); return false;\" title=\"condor_qedit and condor_prio changes should show up in the UserLog\">#1791</a></span> is unknown.\n\n<p>The behavior to write a userlog event upon every qedit already had to be effectively reverted in ticket <span class=\"ticket\"><a class=\"defer\" href=\"/tickets?ticket=3827\" onclick=\"get_ticket_and_populate_wrapper('3827'); return false;\" title=\"Scalability problems when condor_qedit'ing many jobs\">#3827</a></span>  - my guess is if your user was running v8.0.0.3 (you did not fill in the broken version field) the problem would have never happened.  Lets finish the job and revert the userlog event logging on job prio changes.\n\n</p><p>Any objections?\n\n</p><p></p><hr/>\n<em>2013-Nov-05 16:43:46 by eje:</em> <br/>\n\nI will discuss downstream.  It looks like somebody wanted the event information for qedit, prio, and chirp changes, so I need to determine if just excising them is an acceptable answer.\n\n<p></p><hr/>\n<em>2013-Nov-05 19:55:36 by eje:</em> <br/>\n\nDownstream we need to output these events, and the output needs to be made more scalable to support very large volume operations.\n\n<p></p><hr/>\n<em>2013-Nov-07 12:19:14 by tannenba:</em> <br/>\n\nWell, note that <span class=\"ticket\"><a class=\"defer\" href=\"/tickets?ticket=3827\" onclick=\"get_ticket_and_populate_wrapper('3827'); return false;\" title=\"Scalability problems when condor_qedit'ing many jobs\">#3827</a></span> already broke things downstream.\n\n<p>Also note that batching syncs will not help if each job is logging to a different event log file...\n\n</p><p>The job event log cannot and should not be a clone of the job_queue.log. It is supposed to just log events that change the job status, as needed for consumption by a meta-scheduler like dagman.  Maybe we should have a call to discuss the motivations for why this is needed downstream, or perhaps it could be written down along with requirements.  My point here is maybe the job event log is not the right mechanism to achieve the downstream requirement.\n\n</p><p></p><hr/>\n<em>2013-Nov-12 09:14:42 by eje:</em> <br/>\n\nDownstream customers consider this information to be important to their understanding of their workflow histories.  Customer response to our inquiry was:\n\n<p></p><ul>\n<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1791\" onclick=\"get_ticket_and_populate_wrapper('1791'); return false;\" title=\"condor_qedit and condor_prio changes should show up in the UserLog\">#1791</a></span> provides essential audit logging for a job group - without that\nlogging we would be unable to identify how jobs were being modified,\nand in a large oganization where there are many people (or automated\nprocesses) who could be performing such actions this is critical\ninformation.\n\n<p>And yes, we've seen problematic IO patterns in the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=UserLog\" title=\"User Log\">UserLog</a></span> where\npeople are doing large-scale job modifications - so we need 4040 also.\n</p></ul>\n\n<p>Additionally, at least one upstream customer also would like to preserve the option to record these updates (from <span class=\"ticket\"><a class=\"defer\" href=\"/tickets?ticket=3827\" onclick=\"get_ticket_and_populate_wrapper('3827'); return false;\" title=\"Scalability problems when condor_qedit'ing many jobs\">#3827</a></span>):\n\n</p><p></p><ul>\n2013-Aug-26 12:21:10 by pfc: Can this be made optional? There are definitely instances where we might want qedits to be logged. (In fact, anytime it's not needed for scalability I'd prefer to leave them logged, since classad changes can be important for understanding the life of a job after the fact.\n</ul>\n\n<p>There needs to be a way to continue recording this data on customer request, and to increase the efficiency of output at scale.  A default of not recording it is sensible.\n\n</p><p>Requesting it via command line option, e.g. 'condor_qedit -record-xxx', has been proposed previously, and seems reasonable.\n\n</p><p></p><hr/>\n<em>2013-Nov-12 14:24:56 by tannenba:</em> <br/>\n\nIf the motivation to keep <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1791\" onclick=\"get_ticket_and_populate_wrapper('1791'); return false;\" title=\"condor_qedit and condor_prio changes should show up in the UserLog\">#1791</a></span> is for audit logging, why not use the schedd audit log instead (see <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=3493\" onclick=\"get_ticket_and_populate_wrapper('3493'); return false;\" title=\"Audit Log for Condor schedds\">#3493</a></span>)?  It was designed for auditing, unlike the event log which was designed for use by meta-schedulers like dagman and thus has all sorts of overhead for that purpose (like file locking, aggressive flushing to support 2PC, etc).  Compared to the event log, the audit log provides better auditing meta data (e.g. it actually logs <em>who</em> made the change, something the event log does not do), provides age-based time rotation, is designed to be easy to answer basic what/who/when questions via a simple grep (i.e. all important 'fields' for a record appear on the same line), is centralized so there is just one place to look and to make it easy to copy off to another server for safekeeping (security audit archiving), and logs more relevant \"audit\" information (see <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=3563\" onclick=\"get_ticket_and_populate_wrapper('3563'); return false;\" title=\"Schedd commands to audit\">#3563</a></span>).\n\n<p>Take the simple example of the admin wants to know when attribute foo changed from X to Y.  The schedd audit log can tell you no matter how that attribute got changed, be it via condor_qedit, or via non-obvious changes like condor_chirp or chirp updates from the job itself.\n\n</p><p>If the audit log does not audit something important downstream, I'd like to hear about it!\n\n</p><p>Especially given that a mechanism specifically designed for auditing exists, I am not convinced that auditing is a reason to keep around <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=1791\" onclick=\"get_ticket_and_populate_wrapper('1791'); return false;\" title=\"condor_qedit and condor_prio changes should show up in the UserLog\">#1791</a></span>.\n\n</p><p></p><hr/>\n<em>2013-Nov-12 14:40:12 by pfc:</em> <br/>\n\nI think the question is whether you're are a scientist or an admin -- the audit long is perfect for admin-centered questions involving everything that happens in the context a schedd, but a scientist wants to be able to keep a history of each of their individual workflows alongside the results -- i.e., exactly what the userlog does now.  I.e., the information for them isn't attached to a schedd, it's attached to a workflow.\n\n<p></p><hr/>\n<em>2013-Nov-13 14:47:04 by tannenba:</em> <br/>\n\nNothing concrete yet, but just a thought floating around in my head that is somewhat related to this discussion, so I thought I'd share -- I am thinking of perhaps getting rid of all the code in the schedd that writes to the event logs and consolidating it all into a separate daemon that would run alongside the schedd. This daemon would monitor the job_queue.log (just like the job_router daemon) and be responsible for updating all the various event logs.  This would keep the schedd from blocking all the time on event log locks, syncs, etc, and the increased concurrency from event log writing and regular schedd operations happening in parallel would hopefully improve scalability.  It would also simplify the code, enabling us to do more sophisticated/experimental event notification schemes without the worry/risk of breaking the already overly complicated schedd. Of course, all the event log semantics would have to be preserved, but a key here realizing that events in the log do not have to appear right away.  I.e. it is fine if the event logging daemon is a little bit \"behind\" the schedd, assuming that on the average it is able to keep up.\n\n<p></p><hr/>\n<em>2013-Nov-15 12:10:25 by pfc:</em> <br/>\n\nI love that idea!\n\n<p></p><hr/>\n<em>2013-Nov-15 13:44:58 by eje:</em> <br/>\n\nDoes the job queue log embody all the information needed to preserve semantics of user log, audit log, etc?\n\n<p></p><hr/>\n<em>2014-Mar-25 17:42:15 by eje:</em> <br/>\n\nI have a patch that gets rid of redundant opening and closing of logs, via caching the structures that keep log files and their locks:\n\n<p>V8_1-gt4040-optimize-userlog\n\n</p><p></p><hr/>\n<em>2014-Mar-28 10:35:09 by wenger:</em> <br/>\n\nJust talked with ToddT about this -- we think we should have some numbers on how much this improves performance before deciding it's worthwhile to merge this.\n\n<p>How about this for a simple test?:  submit 100k jobs on hold, and then do some operation on them -- remove them, or change priority or something, and measure how long this takes with and without the caching.  I think you should be able to do that without having much in the way of resources.\n\n</p><p></p><hr/>\n<em>2014-Mar-28 20:14:46 by eje:</em> <br/>\n\nI did some experiments where I submitted 10,000 jobs, all sharing a log file, on hold into the queue.  Then I invoked condor_prio:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">$ condor_prio +1 eje</pre></div>\n\n\n<p>I took 10 samples each for timings of condor_prio.\n\n</p><p>My first experiments I ran on all-local disk.   In this environment, the caching was about 2-3% faster.  A measurable improvement, but not huge.   Turning fsync on and off had a large effect on total time, but did not have much impact the improvements from the caching.\n\n</p><p>My second experiments I configured log files on an NFS mount.  In this case, the caching has a fairly large impact (although interestingly, turning fsync on and off had very little impact).\n\n</p><p>For these experiments, the condor_prio command had a mean execution time of 19.5 seconds with caching, and 30.4 seconds without.  So the mean performance is about 30% faster with caching.   The standard deviation with caching was 1.0 seconds, and without caching it was 2.5, so the caching also improved the consistency of the results: without the caching, I measured some substantial outliers with larger run times.  Turning off fsync made the times slightly better in favor of caching, but the difference was small enough to be not very significant.\n\n</p><p>Overall, the log file caching patch seems like a worthwhile performance improvement, particularly when logging over NFS.   I suspect that larger performance improvements might be possible on NFS mounts with higher latencies, or higher traffic.\n\n</p><p></p><hr/>\n<em>2014-Mar-29 09:25:45 by eje:</em> <br/>\n\nWhen testing on any rev where <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=4111\" onclick=\"get_ticket_and_populate_wrapper('4111'); return false;\" title=\"Non-blocking response to condor_q\">#4111</a></span> is present, it may be useful to set:\n<div class=\"code\">\n<pre class=\"code\">CONDOR_Q_USE_V3_PROTOCOL = false</pre></div>\n\n\n<p>in the event that the new protocol makes it harder to assess the time it takes for a queue operation to complete.\n\n</p><p></p><hr/>\n<em>2014-Apr-01 17:47:51 by eje:</em> <br/>\n\nAs an aside, I noticed a lot of 'creating directory' operations that look redundant, because the lock files themselves should have still been open.  There may be some additional efficiency to be gained here, preventing these on lock files that have already been cached and should still be open.\n\n<p></p><div class=\"code\">\n<pre class=\"code\">03/28/14 14:34:07 directory_util::rec_touch_file: Creating directory /tmp\n03/28/14 14:34:07 directory_util::rec_touch_file: Creating directory /tmp/condorLocks\n03/28/14 14:34:07 directory_util::rec_touch_file: Creating directory /tmp/condorLocks/55\n03/28/14 14:34:07 directory_util::rec_touch_file: Creating directory /tmp/condorLocks/55/08\n</pre></div>\n\n\n<p></p><hr/>\n<em>2014-Apr-02 07:58:52 by gthain:</em> <br/>\n\nAs an aside to the aside, I wonder what speedups could be seen by putting LOCK on /dev/shm?\n\n<p></p><hr/>\n<em>2014-Apr-02 08:01:00 by bbockelm:</em> <br/>\n\nProbably minimal.  I highly doubt that any process gets blocked on disk IO.\n\n<p></p><hr/>\n<em>2014-Apr-02 11:24:14 by pfc:</em> <br/>\n\nFWIW, I think Greg asked because we believe our 10k-node glide-in pool on Stampede was bottlenecked by disk i/o on the schedd host when &gt;9k shadows had to simultaneously broker checkpoint requests from running jobs (due to a mass evict).\n\n<p>Although in theory all the shadows had to do was respond to the starters telling them each to checkpoint locally, with &gt;9k stduniv shadows writing to the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ShadowLog\" title=\"Shadow Log\">ShadowLog</a></span> and userlogs, ~10% of the shadows were too slow to respond, causing jobs to vacate after 10 minutes without a checkpoint.\n\n</p><p>We're not 100% sure this is what happened, but I'm 80% sure and we're retesting now to verify.\n\n</p><p></p><hr/>\n<em>2014-Apr-11 20:03:09 by eje:</em> <br/>\n\nI got a report that this commit might have increased shadow memory by up to 200K.  At the moment, I don't have a concrete theory on how that could happen, unless it was possibly the effect of adding a couple STL type definitions to <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=WriteUserLog\" title=\"Write User Log\">WriteUserLog</a></span> class.  If that was the problem, it's might be solvable by conditionally disabling compilation of that code in <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=WriteUserLog\" title=\"Write User Log\">WriteUserLog</a></span> when building the shadow.\n\n<p></p><hr/>\n<em>2014-Apr-14 10:23:50 by johnkn:</em> <br/>\n\nI think this patch is off the hook for the 200k increase in shadow size.  There appears to be a smaller increase due to this patch, an increase of about 60k on Rhel6 in the Batlab corresponds with the introduction of this patch in the master branch - this was causing the static shadow to fail the shadow memory size test. But the problem seems to have gone away in more recent builds on the master branch.\n\n<p>The gain of 120k is now occurring on the Rhel5 machine on master AND on the async transfer work branch which does not have this patch - so whatever his happening it isn't due to this commit.</p></blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2014-May-01 14:34</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=40042\">[40042]</a></span>: rewrite documentation of 2 new knobs such that their definition matches with what these knobs actually do. <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=4040\" onclick=\"get_ticket_and_populate_wrapper('4040'); return false;\" title=\"Optimize condor UserLog IO, via batching\">#4040</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Apr-22 17:28</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=40019\">[40019]</a></span>: Fix small memory leak in user log caching <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=4040\" onclick=\"get_ticket_and_populate_wrapper('4040'); return false;\" title=\"Optimize condor UserLog IO, via batching\">#4040</a></span>  (By Greg Thain )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Apr-10 14:26</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=39898\">[39898]</a></span>: version history for <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=4040\" onclick=\"get_ticket_and_populate_wrapper('4040'); return false;\" title=\"Optimize condor UserLog IO, via batching\">#4040</a></span>  (By Erik Erlandson )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Apr-10 14:21</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=39896\">[39896]</a></span>: Use a cache of open userlog files (and locks) to improve efficiency of userlog output <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=4040\" onclick=\"get_ticket_and_populate_wrapper('4040'); return false;\" title=\"Optimize condor UserLog IO, via batching\">#4040</a></span>  (By Erik Erlandson )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Apr-10 14:21</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=39897\">[39897]</a></span>: Document configuration parameters for userlog caching <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=4040\" onclick=\"get_ticket_and_populate_wrapper('4040'); return false;\" title=\"Optimize condor UserLog IO, via batching\">#4040</a></span>  (By Erik Erlandson )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2014-Apr-14 10:23", "status": "resolved", "created": "2013-Nov-04 16:09", "fixed_version": "2013-Nov-04 16:09", "broken_version": "", "priority": "3", "subsystem": "DaemonsSubmitNode", "assigned_to": "eje", "derived_from": "", "creator": "eje", "rust": "", "customer_group": "other", "visibility": "public", "notify": "eje@cs.wisc.edu, tannenba@cs.wisc.edu, johnkn@cs.wisc.edu, gthain@cs.wisc.edu, tstclair@redhat.com, matt@cs.wisc.edu, jthomas@redhat.com, pfcouvar@syr.edu, wenger@cs.wisc.edu", "due_date": ""}