{"id": 3623, "title": "Ticket #3623: DAGMan doesn't do the right thing when submit of a nested subDAG fails", "description": "<blockquote>\nWhen a nested dag is submitted with a nonexistent DAG file, DAGman does not mark the job as failed (moving it to STATUS_ERROR).  Instead it stays in STATUS_READY, not moved to STATUS_SUBMITTED, and is moved out of readyQ.   Then DAGMan will be in a state where it cannot move forward, and fail with an obscure and unhelpful error message:\n<div class=\"code\">\n<pre class=\"code\">ERROR: DAG finished but not all nodes are complete -- checking for a cycle...\n... ERROR: no cycle found; unknown error condition\n</pre></div>\n\nFix DAGMan so that it marks a job that fails in such a manner to be an error.</blockquote>", "remarks": "<blockquote>\n<em>2013-May-14 12:31:26 by nwp:</em> <br/>\n\nWe have the following in the dagman.out file:\n<div class=\"code\">\n<pre class=\"code\">04/22/13 14:08:10 Submitting Condor Node 12e06b192be3df114c663d6b00cab693 job(s)...\n04/22/13 14:08:10 submitting: condor_submit -a dag_node_name' '=' '12e06b192be3df114c663d6b00cab693 -a +DAGManJobId' '=' '8975512 -a DAGManJobId' '=' '8975512 -a submit_event_notes' '=' 'DAG' 'Node:' '12e06b192be3df114c663d6b00cab693 -a macroihopecache' '=' 'H1L1-RINCA_FIRST_RINGDOWN_QF_LOG_B_INJ_CAT_2_VETO-931035296-1524214.cache -a macrovetosegmentsname' '=' 'VETO_CAT2_CUMULATIVE -a macrovetosegments' '=' '/home/pbaker/S6_runs/s6a/931035296-935798487/segments/H1L1V1-VETOTIME_CAT_2-931035296-4763191.xml -a macroinstruments' '=' 'H1,L1,V1 -a DAG_STATUS' '=' '2 -a FAILED_COUNT' '=' '1 -a +DAGParentNodeNames' '=' '\"\" -a +KeepClaimIdle' '=' '20 cbc_ripedown_rerun.simulation.thinca_to_coinc.sub\n04/22/13 14:08:10 Event: ULOG_SUBMIT for Condor Node 12e06b192be3df114c663d6b00cab693 (8981096.0.0)\n04/22/13 14:08:23 Event: ULOG_EXECUTE for Condor Node 12e06b192be3df114c663d6b00cab693 (8981096.0.0)\n04/22/13 14:08:23 Event: ULOG_IMAGE_SIZE for Condor Node 12e06b192be3df114c663d6b00cab693 (8981096.0.0)\n04/22/13 14:08:23 Event: ULOG_JOB_TERMINATED for Condor Node 12e06b192be3df114c663d6b00cab693 (8981096.0.0)\n04/22/13 14:08:23 Node 12e06b192be3df114c663d6b00cab693 job proc (8981096.0.0) completed successfully.\n04/22/13 14:08:23 Node 12e06b192be3df114c663d6b00cab693 job completed\n</pre></div>\n\nAt the end, we have the following, when DAGMan errors out and dumps the DAG:\n<div class=\"code\">\n<pre class=\"code\">04/22/13 15:10:45 ERROR: DAG finished but not all nodes are complete -- checking for a cycle...\n04/22/13 15:10:45 ... ERROR: no cycle found; unknown error condition\n04/22/13 15:10:45 ---------------------- Job ----------------------\n04/22/13 15:10:45       Node Name: 12e06b192be3df114c663d6b00cab693\n04/22/13 15:10:45            Noop: false\n04/22/13 15:10:45          NodeID: 0\n04/22/13 15:10:45     Node Status: STATUS_DONE\n04/22/13 15:10:45 Node return val: -1\n04/22/13 15:10:45 Job Submit File: cbc_ripedown_rerun.simulation.thinca_to_coinc.sub\n04/22/13 15:10:45   Condor Job ID: [not yet submitted]\n04/22/13 15:10:45       Q_PARENTS: &lt;END&gt;\n04/22/13 15:10:45       Q_WAITING: &lt;END&gt;\n04/22/13 15:10:45      Q_CHILDREN: 2098110567c13d76d957bc1543fab25b, &lt;END&gt;\n</pre></div>\n\nSo DAGMan sees the job finishing successfully, but does not record the return\nvalue?\n\n<p>I see that the last message comes after the DAG tries to read the rescue DAG, successfully runs a few jobs, then barfs with \"unknown error condition\", and fails.  Probably the Node return value is not set in a rescue DAG, so this is a red herring.\n\n</p><p></p><hr/>\n<em>2013-May-14 12:41:31 by wenger:</em> <br/>\n\nDo you have the original DAG file, rescue DAG(s), etc., involved in this?\n\n<p>BTW, as I recall the code that decides when the DAG is \"finished\" is more complicated than one might expect.  I had to mess with that when I added final nodes, and unfortunately probably made it even more complicated (although I did try to do some cleaning up).\n\n</p><p></p><hr/>\n<em>2013-May-14 13:01:54 by wenger:</em> <br/>\n\nI think the original email is a little misleading -- when DAGMan hits this error, I think it dumps info about <strong>all</strong> of the node jobs -- so the one that's in the email is not necessarily part of the problem.  Further down there are some jobs with STATUS_READY instead of STATUS_DONE -- so it looks like the problem is in the (kind of tricky) code that decides when the DAG is finished.\n\n<p></p><hr/>\n<em>2013-May-14 13:08:47 by wenger:</em> <br/>\n\nMore info from the emails:\n\n<p></p><pre>      From: Paul T Baker &lt;paultbaker@gmail.com&gt;\nSubject: Re: [CondorLIGO] [DASWG] Re: pipedown reruns\nDate: April 23, 2013 11:19:08 AM EDT\nTo: \"Peter F. Couvares\" &lt;pfcouvar@syr.edu&gt;\n</pre>\n\n<p>At one point a missing file caused a failure.  I put the file\nin the right place and the rescue dag ran until `completion'.\n I've included that rescue dag and the rescue dag made at the\nend.  I'll try running that rescue dag now... I don't know why\nI didn't try yesterday.\n\n</p><p></p><pre>      From: Paul T Baker &lt;paultbaker@gmail.com&gt;\nSubject: Re: [CondorLIGO] [DASWG] Re: pipedown reruns\nDate: April 23, 2013 11:41:52 AM EDT\nTo: \"Peter F. Couvares\" &lt;pfcouvar@syr.edu&gt;\nCc: \"cdcapano@syr.edu\" &lt;cdcapano@syr.edu&gt;\n</pre>\n\n<p>digging a little deeper I may have found the problem:\n04/23/13 08:19:57 ERROR: condor_submit_dag -no_submit failed\nfor node 2ced337eabcc4b7754310fd1d0955ed8.\n04/23/13 08:19:57 Recursive submit command: &lt;condor_submit_dag\n-no_submit -update_submit -dagman /usr/bin/condor_dagman\n-autorescue 1\ncbc_ripedown_rerun_mvsc_FULL_DATA_CAT_2_VETO_n2000_l65_s14_c6.dag&gt;\n04/23/13 08:19:57 ERROR: condor_submit_dag -no_submit failed on\nDAG file\ncbc_ripedown_rerun_mvsc_FULL_DATA_CAT_2_VETO_n2000_l65_s14_c6.dag.\n\n</p><p>running mvsc_dag as /bin/true it never generates the MVSC sub\ndags.  So those 4 dags are never made, and their child jobs\nwill never be run.  Why the dag didn't crash and burn in a way\nI'm familiar with, I still don't know.\n\n</p><p></p><hr/>\n<em>2013-May-14 16:17:01 by nwp:</em> <br/>\n\nLooks like the job enters a kind of limbo:\n<div class=\"code\">\n<pre class=\"code\">3827         if ( runSubmitDag( *_submitDagDeepOpts, node-&gt;GetDagFile(),\n3828                     node-&gt;GetDirectory(), isRetry ) != 0 ) {\n3829             debug_printf( DEBUG_QUIET,\n3830                         \"ERROR: condor_submit_dag -no_submit failed \"\n3831                         \"for node %s.\\n\", node-&gt;GetJobName() );\n3832                 // Hmm -- should this be a node failure, since it probably\n3833                 // won't work on retry?  wenger 2010-03-26\n3834             if( node-&gt;_hasNodePriority &amp;&amp; node-&gt;_nodePriority &lt; _submitDagDeepOpts-&gt;priority ){\n3835                 swap_priorities(node,_submitDagDeepOpts);\n3836             }\n3837             return SUBMIT_RESULT_NO_SUBMIT;\n3838         }\n</pre></div>\n\nand\n<div class=\"code\">\n<pre class=\"code\">1585\n1586             } else if ( submit_result == SUBMIT_RESULT_NO_SUBMIT ) {\n1587                 // No op.\n1588\n1589             } else {\n</pre></div>\n\nThese are in <code>src/condor_dagman/dag.cpp</code>\n\n<p></p><hr/>\n<em>2013-May-14 16:19:11 by nwp:</em> <br/>\n\nShould have said that this code was from master, not 7.8\n\n<p></p><hr/>\n<em>2013-May-15 09:41:26 by nwp:</em> <br/>\n\nAs I posted to the ligo list the following dag shows the problem\n<div class=\"code\">\n<pre class=\"code\">subdag external 0 does-not-exist.dag\n</pre></div>\n\n\n<p></p><hr/>\n<em>2013-May-15 11:10:59 by nwp:</em> <br/>\n\nPushed a fix onto <code>V7_9-gittrac_3623-branch</code>. Test results are in <a class=\"external\" href=\"http://submit-2.batlab.org/results/run-details.php?runid=127568\">Batlab dashboard</a>.  Kent, would you please review?\n\n<p></p><hr/>\n<em>2013-May-15 17:38:08 by wenger:</em> <br/>\n\nNathan -- looks good, go ahead and merge...\n\n<p></p><hr/>\n<em>2013-May-20 16:19:34 by wenger:</em> <br/>\n\nChanged the title to hopefully better reflect the bug -- if the nested subDAG runs but fails, it didn't trigger this problem...</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2013-May-28 14:00</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=35894\">[35894]</a></span>: minor rewording of version history item for <span class=\"ticket\"><a class=\"defer\" href=\"/tickets?ticket=3623\" onclick=\"get_ticket_and_populate_wrapper('3623'); return false;\" title=\"DAGMan doesn't do the right thing when submit of a nested subDAG fails\">#3623</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2013-May-15 11:06</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=35705\">[35705]</a></span>: Indicate an error when we cannot submit a nested DAG <span class=\"ticket\"><a class=\"defer\" href=\"/tickets?ticket=3623\" onclick=\"get_ticket_and_populate_wrapper('3623'); return false;\" title=\"DAGMan doesn't do the right thing when submit of a nested subDAG fails\">#3623</a></span> Hide the CondorID. When looking for bugs in <span class=\"ticket\"><a class=\"defer\" href=\"/tickets?ticket=3623\" onclick=\"get_ticket_and_populate_wrapper('3623'); return false;\" title=\"DAGMan doesn't do the right thing when submit of a nested subDAG fails\">#3623</a></span>, I tried to find all the places we changed the ID, but it was difficult. It turned out to be a false path as far as the bug goes, but seems like a good thing to do anyway.\u00a0[...]\n (By Nathan W. Panike )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2013-May-20 16:19", "status": "defer", "created": "2013-May-14 11:42", "fixed_version": "2013-May-14 11:42", "broken_version": "v070807", "priority": "5", "subsystem": "Dag", "assigned_to": "nwp", "derived_from": "", "creator": "nwp", "rust": "", "customer_group": "ligo", "visibility": "public", "notify": "wenger@cs.wisc.edu pfcouvar@syr.edu,pcouvare@caltech.edu", "due_date": ""}