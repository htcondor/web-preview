{"id": 6870, "title": "Ticket #6870: scitokens: remote starter does not get credentials from shadow", "description": "<blockquote>\nWhen a job with tokens lands on a remote execute machine, the tokens do not get transferred correctly. The starter complains about:\n\n<p></p><div class=\"verbatim\">\n<pre>01/17/19 16:15:57 CREDMON: got cred\n01/17/19 16:15:57 CREDMON: writing data to /etc/batch_credds/jpatton.cred.tmp\n01/17/19 16:15:57 CREDMON: failed to decode credential into file (/etc/batch_credds/jpatton.cred)!\n</pre></div>\n\n\n<p>These messages are generated from lines 2736-2765 in <a class=\"file\" href=\"rlog?f=src/condor_starter.V6.1/jic_shadow.cpp\">/src/condor_starter.V6.1/jic_shadow.cpp</a> .\n\n</p><p>The full StarterLog.slotX for the job looks like this:\n\n</p><p></p><div class=\"verbatim\">\n<pre>01/17/19 16:15:57 Result of reading /etc/issue:  \\S\n01/17/19 16:15:57 Result of reading /etc/redhat-release:  CentOS Linux release 7.6.1810 (Core)\n01/17/19 16:15:57 Using IDs: 8 processors, 8 CPUs, 0 HTs\n01/17/19 16:15:57 Reading condor configuration from '/etc/condor/condor_config'\n01/17/19 16:15:57 Enumerating interfaces: lo 127.0.0.1 up\n01/17/19 16:15:57 Enumerating interfaces: eth0 172.18.0.3 up\n01/17/19 16:15:57 Enumerating interfaces: lo ::1 up\n01/17/19 16:15:57 Enumerating interfaces: eth0 fe80::42:acff:fe12:3 up\n01/17/19 16:15:57 ******************************************************\n01/17/19 16:15:57 ** condor_starter (CONDOR_STARTER) STARTING UP\n01/17/19 16:15:57 ** /usr/sbin/condor_starter\n01/17/19 16:15:57 ** SubsystemInfo: name=STARTER type=STARTER(8) class=DAEMON(1)\n01/17/19 16:15:57 ** Configuration: subsystem:STARTER local:&lt;NONE&gt; class:DAEMON\n01/17/19 16:15:57 ** $CondorVersion: 8.8.0 Jan 03 2019 BuildID: 457757 PackageID: 8.8.0-1 $\n01/17/19 16:15:57 ** $CondorPlatform: x86_64_RedHat7 $\n01/17/19 16:15:57 ** PID = 308\n01/17/19 16:15:57 ** Log last touched 1/17 16:02:13\n01/17/19 16:15:57 ******************************************************\n01/17/19 16:15:57 Using config source: /etc/condor/condor_config\n01/17/19 16:15:57 Using local config sources:\n01/17/19 16:15:57    /etc/condor/condor_config.local\n01/17/19 16:15:57 config Macros = 70, Sorted = 69, StringBytes = 1820, TablesBytes = 2568\n01/17/19 16:15:57 CLASSAD_CACHING is OFF\n01/17/19 16:15:57 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR\n01/17/19 16:15:57 SharedPortEndpoint: waiting for connections to named socket 54_cc3b_33\n01/17/19 16:15:57 DaemonCore: command socket at &lt;172.18.0.3:9618?addrs=172.18.0.3-9618&amp;noUDP&amp;sock=54_cc3b_33&gt;\n01/17/19 16:15:57 DaemonCore: private command socket at &lt;172.18.0.3:9618?addrs=172.18.0.3-9618&amp;noUDP&amp;sock=54_cc3b_33&gt;\n01/17/19 16:15:57 Setting maximum accepts per cycle 8.\n01/17/19 16:15:57 Will use TCP to update collector cm.test &lt;172.18.0.2:9618&gt;\n01/17/19 16:15:57 Entering JICShadow::receiveMachineAd\n01/17/19 16:15:57 Communicating with shadow &lt;172.18.0.2:9618?addrs=172.18.0.2-9618&amp;noUDP&amp;sock=90_29bd_21&gt;\n01/17/19 16:15:57 Shadow version: $CondorVersion: 8.8.0 Jan 03 2019 BuildID: 457757 PackageID: 8.8.0-1 $\n01/17/19 16:15:57 Submitting machine is \"cm.test\"\n01/17/19 16:15:57 Instantiating a StarterHookMgr\n01/17/19 16:15:57 Job does not define HookKeyword, not invoking any job hooks.\n01/17/19 16:15:57 setting the orig job name in starter\n01/17/19 16:15:57 setting the orig job iwd in starter\n01/17/19 16:15:57 Job doesn't specify x509userproxy, assuming not needed\n01/17/19 16:15:57 Submit FsDomain: \"5283ad377c87\"\n01/17/19 16:15:57  Local FsDomain: \"4eea7e6fdf1c\"\n01/17/19 16:15:57 ShouldTransferFiles is \"IF_NEEDED\" but job's FileSystemDomain does NOT match local value, transfering files\n01/17/19 16:15:57 Submit UidDomain: \"test\"\n01/17/19 16:15:57  Local UidDomain: \"test\"\n01/17/19 16:15:57 Initialized user_priv as \"jpatton\"\n01/17/19 16:15:57 Copied machine ad's MachineResources to ProvisionedResources\n01/17/19 16:15:57 Copied machine ad's Cpus to job ad's CpusProvisioned\n01/17/19 16:15:57 Copied machine ad's AssignedCpus to job ad\n01/17/19 16:15:57 Copied machine ad's Memory to job ad's MemoryProvisioned\n01/17/19 16:15:57 Copied machine ad's AssignedMemory to job ad\n01/17/19 16:15:57 Copied machine ad's Disk to job ad's DiskProvisioned\n01/17/19 16:15:57 Copied machine ad's AssignedDisk to job ad\n01/17/19 16:15:57 Copied machine ad's Swap to job ad's SwapProvisioned\n01/17/19 16:15:57 Copied machine ad's AssignedSwap to job ad\n01/17/19 16:15:57 Updating *Provisioned and Assigned* attributes:\nDiskProvisioned = 7575413\nMemoryProvisioned = 1481\nCpusProvisioned = 1\nProvisionedResources = \"Cpus Memory Disk Swap\"\n01/17/19 16:15:57 Entering JICShadow::updateShadow()\n01/17/19 16:15:57 Sent job ClassAd update to startd.\n01/17/19 16:15:57 Leaving JICShadow::updateShadow(): success\n01/17/19 16:15:57 Done moving to directory \"/var/lib/condor/execute/dir_308\"\n01/17/19 16:15:57 JICShadow::initIOProxy(): Job does not define WantIOProxy; setting to false\n01/17/19 16:15:57 JICShadow::initIOProxy(): Job does not define WantRemoteUpdates; setting to false.\n01/17/19 16:15:57 JICShadow::initIOProxy(): Job does not define WantDelayedUpdates; enabling delayed updates.\n01/17/19 16:15:57 Chirp config summary: IO false, Updates false, Delayed updates true.\n01/17/19 16:15:57 Initializing IO proxy with config file at /var/lib/condor/execute/dir_308/.chirp.config.\n01/17/19 16:15:57 Initialized IO Proxy.\n01/17/19 16:15:57 LocalUserLog::initFromJobAd: path_attr = StarterUserLog\n01/17/19 16:15:57 LocalUserLog::initFromJobAd: xml_attr = StarterUserLogUseXML\n01/17/19 16:15:57 No StarterUserLog found in job ClassAd\n01/17/19 16:15:57 Starter will not write a local UserLog\n01/17/19 16:15:57 Job has SendCredential=true\n01/17/19 16:15:57 CREDMON: cleared mark file /etc/batch_credds/jpatton.mark\n01/17/19 16:15:57 CREDMON: obtaining credentials for user jpatton domain DOMAIN from shadow &lt;172.18.0.2:9618?addrs=172.18.0.2-9618&amp;noUDP&amp;sock=90_29bd_21&gt;\n01/17/19 16:15:57 SharedPortClient: sent connection request to &lt;172.18.0.2:9618&gt; for shared port id 90_29bd_21\n01/17/19 16:15:57 AUTH_ERROR: Cannot resolve network address for KDC in requested realm\n01/17/19 16:15:57 authenticate_self_gss: acquiring self credentials failed. Please check your Condor configuration file if this is a server process. Or the user environment variable if this is a user process.\n\nGSS Major Status: General failure\nGSS Minor Status Error Chain:\nglobus_gsi_gssapi: Error with GSI credential\nglobus_gsi_gssapi: Error with gss credential handle\nglobus_credential: Valid credentials could not be found in any of the possible locations specified by the credential search order.\nValid credentials could not be found in any of the possible locations specified by the credential search order.\nAttempt 1\nglobus_credential: Error reading host credential\nglobus_sysconfig: Could not find a valid certificate file: The host cert could not be found in:\n1) env. var. X509_USER_CERT\n2) /etc/grid-security/hostcert.pem\n3) $GLOBUS_LOCATION/etc/hostcert.pem\n4) $HOME/.globus/hostcert.pem\n\nThe host key could not be found in:\n1) env. var. X509_USER_KEY\n2) /etc/grid-security/hostkey.pem\n3) $GLOBUS_LOCATION/etc/hostkey.pem\n4) $HOME/.globus/hostkey.pem\n\n\nAttempt 2\nglobus_credential: Error reading proxy credential\nglobus_sysconfig: Could not find a valid proxy certificate file location\nglobus_sysconfig: Error with key filename\nglobus_sysconfig: File does not exist: /tmp/x509up_u0 is not a valid file\nAttempt 3\nglobus_credential: Error reading user credential\nglobus_sysconfig: Error with certificate filename: The user cert could not be found in:\n1) env. var. X509_USER_CERT\n2) $HOME/.globus/usercert.pem\n3) $HOME/.globus/usercred.p12\n\n\n\n01/17/19 16:15:57 SECMAN: required authentication with &lt;172.18.0.2:9618&gt; failed, so aborting command CREDD_GET_PASSWD.\n01/17/19 16:15:57 ERROR: AUTHENTICATE:1003:Failed to authenticate with any method|AUTHENTICATE:1004:Failed to authenticate using GSI|GSI:5003:Failed to authenticate.  Globus is reporting error (851968:50).  There is probably a problem with your credentials.  (Did you run grid-proxy-init?)|AUTHENTICATE:1004:Failed to authenticate using KERBEROS|AUTHENTICATE:1004:Failed to authenticate using FS\n01/17/19 16:15:57 Failed to send CREDD_GET_PASSWD command to shadow\n01/17/19 16:15:57 CREDMON: got cred\n01/17/19 16:15:57 CREDMON: writing data to /etc/batch_credds/jpatton.cred.tmp\n01/17/19 16:15:57 CREDMON: failed to decode credential into file (/etc/batch_credds/jpatton.cred)!\n01/17/19 16:15:57 Failed to initialize JobInfoCommunicator, aborting\n01/17/19 16:15:57 Unable to start job.\n01/17/19 16:15:57 **** condor_starter (condor_STARTER) pid 308 EXITING WITH STATUS 1\n01/17/19 16:15:57 Deleting the StarterHookMgr\n</pre></div>\n\n\n<p>It appears as if the job is trying to get more than just OAuth tokens with <code>SendCredential=true</code> having been set automatically in the job ad, though it's not clear that the extra credential request is the problem.</p></blockquote>", "remarks": "<blockquote>\n<em>2019-Jan-17 10:46:39 by jpatton:</em> <br/>\n\nHere's a corresponding <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ShadowLog\" title=\"Shadow Log\">ShadowLog</a></span>\n\n<p></p><div class=\"verbatim\">\n<pre>01/17/19 16:45:14 Result of reading /etc/issue:  \\S\n\n01/17/19 16:45:14 Result of reading /etc/redhat-release:  CentOS Linux release 7.6.1810 (Core)\n\n01/17/19 16:45:14 Using IDs: 8 processors, 8 CPUs, 0 HTs\n01/17/19 16:45:14 Reading condor configuration from '/etc/condor/condor_config'\n01/17/19 16:45:14 Enumerating interfaces: lo 127.0.0.1 up\n01/17/19 16:45:14 Enumerating interfaces: eth0 172.18.0.2 up\n01/17/19 16:45:14 Enumerating interfaces: lo ::1 up\n01/17/19 16:45:14 Enumerating interfaces: eth0 fe80::42:acff:fe12:2 up\n01/17/19 16:45:14 ******************************************************\n01/17/19 16:45:14 ** condor_shadow (CONDOR_SHADOW) STARTING UP\n01/17/19 16:45:14 ** /usr/sbin/condor_shadow\n01/17/19 16:45:14 ** SubsystemInfo: name=SHADOW type=SHADOW(6) class=DAEMON(1)\n01/17/19 16:45:14 ** Configuration: subsystem:SHADOW local:&lt;NONE&gt; class:DAEMON\n01/17/19 16:45:14 ** $CondorVersion: 8.8.0 Jan 03 2019 BuildID: 457757 PackageID: 8.8.0-1 $\n01/17/19 16:45:14 ** $CondorPlatform: x86_64_RedHat7 $\n01/17/19 16:45:14 ** PID = 501\n01/17/19 16:45:14 ** Log last touched 1/17 16:15:57\n01/17/19 16:45:14 ******************************************************\n01/17/19 16:45:14 Using config source: /etc/condor/condor_config\n01/17/19 16:45:14 Using local config sources:\n01/17/19 16:45:14    /etc/condor/condor_config.local\n01/17/19 16:45:14 config Macros = 77, Sorted = 77, StringBytes = 2227, TablesBytes = 1280\n01/17/19 16:45:14 CLASSAD_CACHING is OFF\n01/17/19 16:45:14 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR\n01/17/19 16:45:14 SharedPortEndpoint: waiting for connections to named socket 90_29bd_22\n01/17/19 16:45:14 DaemonCore: command socket at &lt;172.18.0.2:9618?addrs=172.18.0.2-9618&amp;noUDP&amp;sock=90_29bd_22&gt;\n01/17/19 16:45:14 DaemonCore: private command socket at &lt;172.18.0.2:9618?addrs=172.18.0.2-9618&amp;noUDP&amp;sock=90_29bd_22&gt;\n01/17/19 16:45:14 Setting maximum accepts per cycle 8.\n01/17/19 16:45:14 Will use TCP to update collector cm.test &lt;172.18.0.2:9618&gt;\n01/17/19 16:45:14 Spool format version requires &gt;= 1 (I support version 1)\n01/17/19 16:45:14 Spool format version is 1 (I require version &gt;= 1)\n01/17/19 16:45:14 Reading job ClassAd from STDIN\n01/17/19 16:45:14 Initializing a VANILLA shadow for job 9.0\n01/17/19 16:45:14 (9.0) (501): UserLog = /home/jpatton/log\n01/17/19 16:45:14 (9.0) (501): WriteUserLog::initialize: opened /home/jpatton/log successfully\n01/17/19 16:45:14 (9.0) (501): in RemoteResource::initStartdInfo()\n01/17/19 16:45:14 (9.0) (501): Entering DCStartd::activateClaim()\n01/17/19 16:45:14 (9.0) (501): SharedPortClient: sent connection request to startd slot1@4eea7e6fdf1c for shared port id 21_4bfb_3\n01/17/19 16:45:14 (9.0) (501): DCStartd::activateClaim: successfully sent command, reply is: 1\n01/17/19 16:45:14 (9.0) (501): Request to run on slot1@4eea7e6fdf1c &lt;172.18.0.3:9618?addrs=172.18.0.3-9618&amp;noUDP&amp;sock=21_4bfb_3&gt; was ACCEPTED\n01/17/19 16:45:14 (9.0) (501): Resource slot1@4eea7e6fdf1c changing state from PRE to STARTUP\n01/17/19 16:45:14 (9.0) (501): DaemonKeepAlive: in SendAliveToParent()\n01/17/19 16:45:14 (9.0) (501): Completed DC_CHILDALIVE to daemon at &lt;172.18.0.2:34526&gt;\n01/17/19 16:45:14 (9.0) (501): DaemonKeepAlive: Leaving SendAliveToParent() - success\n01/17/19 16:45:15 (9.0) (501): entering FileTransfer::Init\n01/17/19 16:45:15 (9.0) (501): entering FileTransfer::SimpleInit\n01/17/19 16:45:15 (9.0) (501): Entering FileTransfer::InitDownloadFilenameRemaps\n01/17/19 16:45:15 (9.0) (501): FILETRANSFER: protocol \"http\" handled by \"/usr/libexec/condor/curl_plugin\"\n01/17/19 16:45:15 (9.0) (501): FILETRANSFER: protocol \"https\" handled by \"/usr/libexec/condor/curl_plugin\"\n01/17/19 16:45:15 (9.0) (501): FILETRANSFER: protocol \"ftp\" handled by \"/usr/libexec/condor/curl_plugin\"\n01/17/19 16:45:15 (9.0) (501): FILETRANSFER: protocol \"file\" handled by \"/usr/libexec/condor/curl_plugin\"\n01/17/19 16:45:15 (9.0) (501): FILETRANSFER: protocol \"data\" handled by \"/usr/libexec/condor/data_plugin\"\n01/17/19 16:45:15 (9.0) (501): Directory::setOwnerPriv() -- path /var/lib/condor/spool/9/0/cluster9.proc0.subproc0.tmp does not exist (yet).\n01/17/19 16:45:15 (9.0) (501): Directory::Rewind(): path \"/var/lib/condor/spool/9/0/cluster9.proc0.subproc0.tmp\" does not exist (yet)\n01/17/19 16:45:15 (9.0) (501): Directory::setOwnerPriv() -- path /var/lib/condor/spool/9/0/cluster9.proc0.subproc0 does not exist (yet).\n01/17/19 16:45:15 (9.0) (501): Directory::Rewind(): path \"/var/lib/condor/spool/9/0/cluster9.proc0.subproc0\" does not exist (yet)\n01/17/19 16:45:15 (9.0) (501): Inside RemoteResource::updateFromStarter()\n01/17/19 16:45:15 (9.0) (501): authenticate_self_gss: acquiring self credentials failed. Please check your Condor configuration file if this is a server process. Or the user environment variable if this is a user process.\n\nGSS Major Status: General failure\nGSS Minor Status Error Chain:\nglobus_gsi_gssapi: Error with GSI credential\nglobus_gsi_gssapi: Error with gss credential handle\nglobus_credential: Valid credentials could not be found in any of the possible locations specified by the credential search order.\nValid credentials could not be found in any of the possible locations specified by the credential search order.\nAttempt 1\nglobus_credential: Error reading host credential\nglobus_sysconfig: Could not find a valid certificate file: The host cert could not be found in:\n1) env. var. X509_USER_CERT\n2) /etc/grid-security/hostcert.pem\n3) $GLOBUS_LOCATION/etc/hostcert.pem\n4) $HOME/.globus/hostcert.pem\n\nThe host key could not be found in:\n1) env. var. X509_USER_KEY\n2) /etc/grid-security/hostkey.pem\n3) $GLOBUS_LOCATION/etc/hostkey.pem\n4) $HOME/.globus/hostkey.pem\n\n\nAttempt 2\nglobus_credential: Error reading proxy credential\nglobus_sysconfig: Could not find a valid proxy certificate file location\nglobus_sysconfig: Error with key filename\nglobus_sysconfig: File does not exist: /tmp/x509up_u0 is not a valid file\nAttempt 3\nglobus_credential: Error reading user credential\nglobus_sysconfig: Error with certificate filename: The user cert could not be found in:\n1) env. var. X509_USER_CERT\n2) $HOME/.globus/usercert.pem\n3) $HOME/.globus/usercred.p12\n\n\n\n01/17/19 16:45:15 (9.0) (501): DC_AUTHENTICATE: authentication of &lt;172.18.0.3:40907&gt; did not result in a valid mapped user name, which is required for this command (81099 CREDD_GET_PASSWD), so aborting.\n01/17/19 16:45:15 (9.0) (501): DC_AUTHENTICATE: reason for authentication failure: AUTHENTICATE:1003:Failed to authenticate with any method|AUTHENTICATE:1004:Failed to authenticate using GSI|GSI:5003:Failed to authenticate.  Globus is reporting error (851968:50).  There is probably a problem with your credentials.  (Did you run grid-proxy-init?)|AUTHENTICATE:1004:Failed to authenticate using KERBEROS|AUTHENTICATE:1004:Failed to authenticate using FS|FS:1004:Unable to lstat(/tmp/FS_XXXCTspQD)\n01/17/19 16:45:15 (9.0) (501): condor_read(): Socket closed when trying to read 5 bytes from startd slot1@4eea7e6fdf1c\n01/17/19 16:45:15 (9.0) (501): IO: EOF reading packet header\n01/17/19 16:45:15 (9.0) (501): Can no longer talk to condor_starter &lt;172.18.0.3:9618&gt;\n01/17/19 16:45:15 (9.0) (501): Trying to reconnect job 5283ad377c87#9.0#1547743514\n01/17/19 16:45:15 (9.0) (501): Trying to reconnect to disconnected job\n01/17/19 16:45:15 (9.0) (501): LastJobLeaseRenewal: 1547743514 Thu Jan 17 16:45:14 2019\n01/17/19 16:45:15 (9.0) (501): JobLeaseDuration: 2400 seconds\n01/17/19 16:45:15 (9.0) (501): Resource slot1@4eea7e6fdf1c changing state from STARTUP to RECONNECT\n01/17/19 16:45:15 (9.0) (501): JobLeaseDuration remaining: 2399\n01/17/19 16:45:15 (9.0) (501): Attempting to locate disconnected starter\n01/17/19 16:45:15 (9.0) (501): gjid is 5283ad377c87#9.0#1547743514 claimid is &lt;172.18.0.3:9618&gt;#1547736931#58#...\n01/17/19 16:45:15 (9.0) (501): SharedPortClient: sent connection request to startd slot1@4eea7e6fdf1c for shared port id 21_4bfb_3\n01/17/19 16:45:15 (9.0) (501): locateStarter(): ClaimId (&lt;172.18.0.3:9618&gt;#1547736931#58#[CryptoMethods=\"3DES\";Encryption=\"NO\";Integrity=\"NO\";]34257972cf2876bb188f8a3ba8435a9127b5e43b) and GlobalJobId ( 5283ad377c87#9.0#1547743514 ) not found\n01/17/19 16:45:15 (9.0) (501): Reconnect FAILED: Job not found at execution machine\n01/17/19 16:45:15 (9.0) (501): Exiting with JOB_SHOULD_REQUEUE\n01/17/19 16:45:15 (9.0) (501): **** condor_shadow (condor_SHADOW) pid 501 EXITING WITH STATUS 107\n01/17/19 16:45:15 (9.0) (501): WriteUserLog::user_priv_flag (~) is 0\n</pre></div>\n\n\n<p></p><hr/>\n<em>2019-Jan-17 10:51:06 by bbockelm:</em> <br/>\n\nI think this might be the same as <span class=\"ticket\"><a class=\"resolved\" href=\"tktview?tn=6867\" title=\"scitokens: starter silently ignores error when fetching creds\">#6867</a></span>: when the remote starter fails to talk to the credd (in your case, it appears the starter has failed to authenticate with the credd), the code ignores the error code and tries to execute the code anyway.\n\n<p></p><hr/>\n<em>2019-Jan-17 12:03:17 by jfrey:</em> <br/>\n\nIt looks like your starter is failing through to the pre-SciTokens credential transfer code, and you need to set TOKENS=True in the config to use the new transfer code.\n\n<p></p><hr/>\n<em>2019-Jan-17 13:16:32 by jpatton:</em> <br/>\n\nPer Brian, ToddT, and Jaime's findings, the major issue here is what was laid out in <span class=\"ticket\"><a class=\"resolved\" href=\"tktview?tn=6867\" title=\"scitokens: starter silently ignores error when fetching creds\">#6867</a></span> (the condor_starter ignores token transfer errors due to non-encrypted transfer), but we'll track progress in this ticket.\n\n<p>We also need to document that <code>TOKENS</code> (or whatever it ends up being called) should be set <code>True</code> on the execute machine as well as the submit machine to enable the token transfer mechanism, and that the daemons must be authenticated. But, per <span class=\"ticket\"><a class=\"new\" href=\"tktview?tn=6869\" title=\"scitokens: Abandon ZKM_QUERY_CREDS\">#6869</a></span>, the new token transfer mechanism should not be the <em>only</em> method for transferring credentials.\n\n</p><p></p><hr/>\n<em>2019-Feb-01 14:12:21 by jpatton:</em> <br/>\n\nSince this was actually <span class=\"ticket\"><a class=\"resolved\" href=\"tktview?tn=6867\" title=\"scitokens: starter silently ignores error when fetching creds\">#6867</a></span>, it was resolved in <span class=\"ticket\"><a class=\"resolved\" href=\"tktview?tn=6867\" title=\"scitokens: starter silently ignores error when fetching creds\">#6867</a></span>. This ticket remains for documentation purposes.</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "defect", "last_change": "2019-Feb-01 14:12", "status": "resolved", "created": "2019-Jan-17 10:29", "fixed_version": "2019-Jan-17 10:29", "broken_version": "v080800", "priority": "1", "subsystem": "Daemons", "assigned_to": "jfrey", "derived_from": "#6513", "creator": "jpatton", "rust": "", "customer_group": "scitokens", "visibility": "public", "notify": "jpatton@cs.wisc.edu,tannenba@cs.wisc.edu,bbockelman@morgridge.org,dabrown@syr.edu", "due_date": ""}