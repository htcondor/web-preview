{"id": 1994, "title": "Ticket #1994: transfer queue needs better support for dealing with job suspension", "description": "<blockquote>\nThe file transfer queue on submit.chtc.wisc.edu has been observed in several instances to become backlogged for hours without making much progress.  At least one cause of this problem is suspension of jobs that are transferring input files.  This happens in CHTC to whole-machine jobs that are suspended while waiting for jobs on all other slots to finish.\n\n<p>I don't know if suspension always causes file transfer to be suspended, but in CHTC, that is what I observe.  Here is output from ps --forest that shows the condor_starter child process in a suspended state:\n\n</p><p></p><div class=\"verbatim\">\n<pre>USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\ncondor   30284  0.0  0.0  27120  3384 ?        Ss   12:59   0:00      \\_ condor_starter -f -a slot10 submit.chtc.wisc.edu\ncondor   30286  0.0  0.0  26988  1604 ?        T    12:59   0:00          \\_ condor_starter -f -a slot10 submit.chtc.wisc.edu\n</pre></div>\n\n\n<p>The workaround is to disable queueing of stage-ins:\n\n</p><p></p><div class=\"verbatim\">\n<pre>MAX_CONCURRENT_UPLOADS = 0\n</pre></div>\n\n\n<p>As an aside, I also note that the starter appears to stop sending ALIVEs to the startd when in this state.  In the <code>StartLog</code> I observe the following after the job (file transfer) has been suspended for an hour:\n\n</p><p></p><div class=\"verbatim\">\n<pre>03/23/11 13:59:13 ERROR: Child pid 30284 appears hung! Killing it hard.\n</pre></div>\n\n\n<p>When this happens, the file transfer is aborted, and the count of active transfers is decremented as it should be.  However, the likely result is that a new whole-machine job will soon come along and plug things up again.  (But at least it must enter at the end of the queue, so deadlock is avoided.)</p></blockquote>", "remarks": "<blockquote>\n<em>2011-Mar-23 14:35:00 by tannenba:</em> <br/>\n\nStrange.  So when the startd decides to suspend, it should daemon core signal the starter to suspend the job, but that should not suspend the starter itself.  So i do not know why the starter would fail to send daemoncore keepalives.  Also, not certain why the starter child process is being suspended .... is something going on due to privsep and/or procd involvement?\n\n<p></p><hr/>\n<em>2011-Mar-23 15:45:08 by danb:</em> <br/>\n\nI also see that the file transfer communication timeout is rather large, which may explain why the shadow doesn't give up sooner:\n\n<p></p><div class=\"verbatim\">\n<pre>STARTER_UPLOAD_TIMEOUT = 3600\n</pre></div>\n\n\n<p>With a shorter timeout, the problem of the file transfer queue getting plugged up by suspended transfers may be less of a problem.\n\n</p><p></p><hr/>\n<em>2011-Mar-25 17:02:48 by danb:</em> <br/>\n\nThe suspension of the starter's file-transfer sub-process is being done explicitly in the file-transfer object:\n\n<p></p><div class=\"verbatim\">\n<pre>int\nFileTransfer::Suspend()\n{\n    int result = TRUE;  // return TRUE if there currently is no thread\n\n    if (ActiveTransferTid != -1 ) {\n        ASSERT( daemonCore );\n\tresult = daemonCore-&gt;Suspend_Thread(ActiveTransferTid);\n    }\n\n    return result;\n}\n</pre></div>\n\n\n<p>And in the starter:\n\n</p><p></p><div class=\"verbatim\">\n<pre>        // If we have a file transfer object, we want to tell it to\n        // suspend any work it might be doing...\n    if( filetrans ) {\n\tfiletrans-&gt;Suspend();\n    }\n</pre></div>\n\n\n<p></p><hr/>\n<em>2011-Mar-25 22:11:23 by danb:</em> <br/>\n\nI have committed a patch that improves the reporting of transfer queue state, which should at least make this problem easier to manage in the future.  The state of the queue is logged periodically and is published in the schedd ad.  Transfers that exceed the maximum age limit are reported via the log and email to the administrator.\n\n<p>What remains to be done:\n\n</p><p></p><ol>\n<li>decide whether it is desired that file transfer is suspended when the slot is suspended.\n\n<p></p></li><li>if so, then is it good enough to rely on the read/write timeouts to avoid hanging for too long?  The default read/write timeout is 5 minutes.  In CHTC we had jacked this up to 1 hour to workaround problems with parallel universe.\n\n<p></p></li><li>also, can the default of 2 hours for MAX_TRANSFER_QUEUE_AGE be improved?  Should this mechanism take per-job information into account?\n</li></ol>\n\n<p></p><hr/>\n<em>2011-Oct-24 17:02:20 by danb:</em> <br/>\n\nWe now understand why the starter stops sending heartbeats to the startd.  The starter hangs when doing a syscall to the shadow, which is stuck doing file transfer, because the starter's file transfer child process is suspended.  The shadow does file transfer in its main process because parallel universe breaks if a sub-process is used.  (The file transfer object only supports having one sub-process at a time.)\n\n<p></p><hr/>\n<em>2011-Oct-24 17:10:05 by danb:</em> <br/>\n\nIn a conversation with Todd and Greg, we came up with the following short-term plan for improving things: add a configurable knob that controls whether the starter suspends file transfer or not.\n\n<p>Longer-term we would like to be able to set this policy from the startd's SUSPEND/CONTINUE expressions.  This means that somehow the file transfer status needs to be made visible.\n\n</p><p></p><hr/>\n<em>2011-Nov-03 10:33:59 by danb:</em> <br/>\n\nOur belief that a shorter STARTER_UPLOAD_TIMEOUT could help avoid transfers plugging up the queue while the transfer is suspended for a long time turned out to be false hope.\n\n<p>As the name implies, STARTER_UPLOAD_TIMEOUT only applies to the starter's side of the connection.  There is no timeout on the shadow's side.  In fact, I now see that we explicitly avoid having a timeout on the shadow side for the very reason we are now wishing we had one.  Here's the code in <code>FileTransfer::HandleCommands()</code> that is responsible:\n\n</p><p></p><pre>    // turn off timeouts on sockets, since our peer could get suspended\n    // (like in the case of the starter sending files back to the shadow)\n    sock-&gt;timeout(0);</pre>\n</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-25 22:01</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=21167\">[21167]</a></span>: Added better reporting of transfer queue state. <span class=\"ticket\"><a class=\"stalled\" href=\"/tickets?ticket=1994\" onclick=\"get_ticket_and_populate_wrapper('1994'); return false;\" title=\"transfer queue needs better support for dealing with job suspension\">#1994</a></span> The schedd periodically logs state of the transfer queue. It also advertises the current state in its daemon ad. When a transfer exceeds MAX_TRANSFER_QUEUE_AGE, an email is sent to the administrator explaining the problem.  (By Dan Bradley )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2014-Aug-07 12:18", "status": "stalled", "created": "2011-Mar-23 14:10", "fixed_version": "2011-Mar-23 14:10", "broken_version": "v070700", "priority": "3", "subsystem": "FileTransfer", "assigned_to": "danb", "derived_from": "", "creator": "danb", "rust": "", "customer_group": "cms", "visibility": "public", "notify": "dan@hep.wisc.edu, tannenba@cs.wisc.edu, tstclair@redhat.com", "due_date": ""}