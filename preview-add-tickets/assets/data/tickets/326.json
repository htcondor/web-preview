{"id": 326, "title": "Ticket #326: sh-like control of stdout/err for jobs", "description": "<blockquote>\n(This is based on a discussion between adesmet, gthain, and psilord.)\n\n<p>Condor's handling of stdout and stderr is pretty primative.  You either capture it or now.  If you capture it, it must be to a unique file.  If both stdout and stderr go to the same file, the result is undefined (but you'll probably lose data).  If multiple jobs write to the same stdout or stderr, you'll probably lose data.\n\n</p><p>/bin/sh supports a rich set of options, and it would be nice to offer this level of option to Condor users.  Key features:\n\n</p><p></p><ol>\n<li>Redirect stdout and stderr into a single file, interleaved as the lines were emitted.  This would be similar to \"cmd 2&gt;&amp;1 &gt; outfile\" in sh.  This is handy for, say, compiler output.  (Because of buffering you can't guarantee that the lines interleave correctly, but the niave implementation will likely be Good Enough; after all, it works for /bin/sh.)\n</li><li>Append to stdout and stderr, instead of truncating and writing.  This is potentially useful for 1. programs doing their own checkpointing, and 2. lots of jobs that you want to merge the output on.\n</li></ol>\n\n<p>Possible syntax:\n</p><ul>\n<li>Ad hoc:\n<ul>\n<li>append_stdout = true\n</li><li>append_stderr = true\n</li><li>stdout = output.txt\n</li><li>stderr = output.txt\n</li></ul>\n</li><li>sh-like\n<ul>\n<li>io = 2&gt;&amp;1 &gt;&gt; output.txt</li></ul>\n</li></ul>\n</blockquote>", "remarks": "<blockquote>\n<em>2009-Mar-16 14:29:11 by gthain:</em> <br/>\n\nAnother syntax might be perl-like:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">output = \"&gt;&gt;append_to_me\"\nerror  = \"&gt;&amp;1\"\n</pre></div>\n\n\n<p></p><hr/>\n<em>2009-Apr-08 15:27:29 by tlmiller:</em> <br/>\n\nThis problem becomes possible to solve with post-processing if <span class=\"ticket\"><a class=\"new\" href=\"tktview?tn=370\" title=\"Timestamp stdout stderr lines\">#370</a></span> is implemented, although doing it \"natively\" would be nicer to the user.\n\n<p>As an extension of this idea, for the parallel universe, if would be cute to allow streaming output from one job to be streaming input to another.  I'm not sure, however, to what extent Condor really wants to support pipelining without intermediate files as a computational model.  (In addition to the latency advantages of concurrency, you also wouldn't have buffer or track potentially large intermediate files.  If you explicitly support pipelining as a computation model, what you probably want to do is let Condor co- or not co- schedule pipelined computations as the matchmaker sees fit.  This would require some special support from Condor, even if the interface ended up in DAGMan, with explicit data dependencies, rather than ordering dependencies.)\n</p><hr/>\n<em>2010-Oct-20 15:59:08 by jfrey:</em> <br/>\n\nBulk change of target version from v070504 to v070505 using ./ticket-target-mover.\n<hr/>\n<em>2011-Jan-27 14:21:33 by danb:</em> <br/>\n\nBulk change of target version from v070505 to v070506 using ./ticket-target-mover.\n<hr/>\n<em>2011-Feb-01 14:49:30 by tannenba:</em> <br/>\n\nBulk change of target version from v070506 to NULL using ./ticket-target-mover.</blockquote>", "derived_tickets": "", "attachments": "", "check_ins": "", "type": "enhance", "last_change": "2011-Feb-01 14:50", "status": "new", "created": "2009-Mar-16 14:21", "fixed_version": "2009-Mar-16 14:21", "broken_version": "", "priority": "4", "subsystem": "", "assigned_to": "", "derived_from": "", "creator": "adesmet", "rust": "", "customer_group": "other", "visibility": "public", "notify": "psilord@cs.wisc.edu", "due_date": ""}