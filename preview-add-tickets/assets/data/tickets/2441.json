{"id": 2441, "title": "Ticket #2441: Condor startd on Windows can't run more than 8 jobs simultaneously", "description": "<blockquote>\nOn a 40 core machine running Win2k8 SP2, a single STARTD can only run about 8 jobs simultaneously.  after about 8 jobs are running the schedd reports that claim activation is failing.\n\n<p>This ticket was created to separate the relatively trivial bug if condor not detecting all 40 cpus from the more difficult scaleability issues. see <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2381\" onclick=\"get_ticket_and_populate_wrapper('2381'); return false;\" title=\"Condor only detects 32 out of 40 physical cores on a Win2k8 R2 machine\">#2381</a></span> for the trivial bug.\n\n</p><p>Note that some of the remarks below  were moved from <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2381\" onclick=\"get_ticket_and_populate_wrapper('2381'); return false;\" title=\"Condor only detects 32 out of 40 physical cores on a Win2k8 R2 machine\">#2381</a></span> to here.\n\n</p><p>Ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2453\" onclick=\"get_ticket_and_populate_wrapper('2453'); return false;\" title=\"Figure out why we can only run about 8 jobs on a windows exec node\">#2453</a></span> created to track work figuring out what the problem is.</p></blockquote>", "remarks": "<blockquote>\n<em>2011-Aug-12 16:16:27 by tstclair:</em> <br/>\n\njust triaging so it's on the radar feel free to amend\n\n<p></p><hr/>\n<em>2011-Aug-17 12:50:50 by tannenba:</em> <br/>\n\nAdditional info / thoughts:\n\n<p>Cycle reports this problem did not happen in Win XP, 2k, 2k3.  They think the problem may be correlated with the new networking stack that was first rolled out in vista/HPC Server/2k8, and they have definitely seen it with HPCServer 2k3/2k8, Win 2k8.  On these platforms, Cycle reports that the problem can be observed with as few as 12 slots :(. The more slots, the more consistently it happens.\n\n</p><p>One possible (albeit cumbersome) immediate work-around could be to run multiple startds on the same machine, aka 4 startds w/ 8 slots instead of one startd with 32 slots. Perhaps a <span class=\"wiki\"><a href=\"wiki?p=HowToAdminRecipes\" title=\"How To Admin Recipes\">HOWTO</a></span> article on how to configure multiple startds under one master would be helpful? The HOWOTO could explain how to configure (create log &amp; exec directories, set STARTD_NAME, set master to start them), and also some of the pros/cons (e.g. some STARTD machine ad attributes, like <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=NonCondorLoadAvg\" title=\"Non Condor Load Avg\">NonCondorLoadAvg</a></span>, are system-wide and will no longer make sense if you are running multiple startds).\n\n</p><p></p><hr/>\n<em>2011-Aug-17 12:52:41 by tannenba:</em> <br/>\n\nThis issue seems specific to Windows, as we have often run more than 12 slots on Linux w/o seeing this problem.\n\n<p></p><hr/>\n<em>2011-Aug-17 12:56:33 by tannenba:</em> <br/>\n\nRandom shot in the dark thought: a quick/dirty look at the logs and it appears the problem manifests when the schedd is activating claims to the startd, the startd times out. Activation will cause the startd to spawn a starter. One difference between Condor on Linux vs Windows is signaling between startd and starter happens via posix signals on Linux, but Windows uses daemonCore created CEDAR sockets causing us to hit a deadlock between schedd, startd, starter ?\n\n<p></p><hr/>\n<em>2011-Aug-22 08:32:31 by tstclair:</em> <br/>\n\nWhat happens if they change _TIMEOUT_INVERVAL? on the schedd..\n\n<p>E.g. raise all boats just to see what happens.\n\n</p><p><em>2011-Aug-22 13:19:42 by ichesal:</em> <br/>\n\nI raised the shadow and startd timeouts to 20 -- no difference. And failures on the comm channel were just as fast.\n</p><hr/>\n<hr/>\n<em>2011-Oct-03 10:23:33 by ichesal:</em> <br/>\n\nI have an update for this ticket, the result of testing with multiple startd's on the 40-core machine.\n\n<p><strong>TL;DR:</strong> Multiple startd's don't help the situation. Would you like to arrange access to the machine?\n\n</p><p>Throughout the tests a 5-startd setup on a 40-core machine was used. The configuration for the tests was:\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\"># Fake more CPUs than Condor can count\nNUM_CPUS = 40\n\n# Tell the master to run the procd\nMASTER.USE_PROCD = True\n\n# Always run\nSTART = True\n\n# Define the first STARTD on this machine\nSTARTD1 = $(STARTD)\nSTARTD1_ARGS = -f -local-name S1\nSTARTD1_LOG = $(LOCAL_DIR)/log/StartdLog.S1\nSTARTD1_EXECUTE = $(LOCAL_DIR)/execute.S1\nSTARTD1_ENVIRONMENT = \"_condor_STARTER_LOG=$(LOG)/StarterLog.S1\"\nSTARTD.S1.NUM_SLOTS = 8\nSTARTD.S1.STARTD_NAME = S1\nSTARTD.S1.STARTD_LOG = $(STARTD1_LOG)\nSTARTD.S1.STARTD_EXEUTE = $(STARTD1_EXECUTE)\nDAEMON_LIST = $(DAEMON_LIST), STARTD1\n\n# Define the second STARTD on this machine\nSTARTD2 = $(STARTD)\nSTARTD2_ARGS = -f -local-name S2\nSTARTD2_LOG = $(LOCAL_DIR)/log/StartdLog.S2\nSTARTD2_EXECUTE = $(LOCAL_DIR)/execute.S2\nSTARTD2_ENVIRONMENT = \"_condor_STARTER_LOG=$(LOG)/StarterLog.S2\"\nSTARTD.S2.NUM_SLOTS = 8\nSTARTD.S2.STARTD_NAME = S2\nSTARTD.S2.STARTD_LOG = $(STARTD2_LOG)\nSTARTD.S2.STARTD_EXEUTE = $(STARTD2_EXECUTE)\nDAEMON_LIST = $(DAEMON_LIST), STARTD2\n\n# Define the third STARTD on this machine\nSTARTD3 = $(STARTD)\nSTARTD3_ARGS = -f -local-name S3\nSTARTD3_LOG = $(LOCAL_DIR)/log/StartdLog.S3\nSTARTD3_EXECUTE = $(LOCAL_DIR)/execute.S3\nSTARTD3_ENVIRONMENT = \"_condor_STARTER_LOG=$(LOG)/StarterLog.S3\"\nSTARTD.S3.NUM_SLOTS = 8\nSTARTD.S3.STARTD_NAME = S3\nSTARTD.S3.STARTD_LOG = $(STARTD3_LOG)\nSTARTD.S3.STARTD_EXEUTE = $(STARTD3_EXECUTE)\nDAEMON_LIST = $(DAEMON_LIST), STARTD3\n\n# Define the fourth STARTD on this machine\nSTARTD4 = $(STARTD)\nSTARTD4_ARGS = -f -local-name S4\nSTARTD4_LOG = $(LOCAL_DIR)/log/StartdLog.S4\nSTARTD4_EXECUTE = $(LOCAL_DIR)/execute.S4\nSTARTD4_ENVIRONMENT = \"_condor_STARTER_LOG=$(LOG)/StarterLog.S4\"\nSTARTD.S4.NUM_SLOTS = 8\nSTARTD.S4.STARTD_NAME = S4\nSTARTD.S4.STARTD_LOG = $(STARTD4_LOG)\nSTARTD.S4.STARTD_EXEUTE = $(STARTD4_EXECUTE)\nDAEMON_LIST = $(DAEMON_LIST), STARTD4\n\n# Define the fifth STARTD on this machine\nSTARTD5 = $(STARTD)\nSTARTD5_ARGS = -f -local-name S5\nSTARTD5_LOG = $(LOCAL_DIR)/log/StartdLog.S5\nSTARTD5_EXECUTE = $(LOCAL_DIR)/execute.S5\nSTARTD5_ENVIRONMENT = \"_condor_STARTER_LOG=$(LOG)/StarterLog.S5\"\nSTARTD.S5.NUM_SLOTS = 8\nSTARTD.S5.STARTD_NAME = S5\nSTARTD.S5.STARTD_LOG = $(STARTD5_LOG)\nSTARTD.S5.STARTD_EXEUTE = $(STARTD5_EXECUTE)\nDAEMON_LIST = $(DAEMON_LIST), STARTD5\n\nDC_DAEMON_LIST = +STARTD1 STARTD2 STARTD3 STARTD4 STARTD5\n</pre></div>\n\n\n<p>Jobs were sleep jobs set to run for one hour ensuring: 1) the CPUs were actually supposed to be quiet; 2) there was plenty of time for Condor to fill the machine before jobs started to complete.\n\n</p><p><strong>Test Machine 1: Win2k8</strong>\n\n</p><p>Ran these tests with and without the procd enabled on the machine.\n\n</p><p>With the procd we could only get 5 jobs started (slot1 on each of the 5 startds ran a job, subsequent slots failed to start their jobs with a comm error recorded between the startd and starter). The CPU for the procd was intense. Using 100% of 1 CPU the entire time. The CPU of the 5 condor_starter processes was similarly intense the entire time.\n\n</p><p>Without the procd we could get a few more jobs running but the CPU of the condor_master, condor_startds and condor_starters was intense. Each of those using 100% of a CPU apiece.\n\n</p><p><strong>Test Machine 2: Win2k8 R2</strong>\n\n</p><p>Ran these tests with and without the procd enabled on the machine.\n\n</p><p>With the procd we got 27 sleep jobs running (though condor_status showed 37 claimed CPUs on the machine). With the procd in use the condor_procd was using 100% CPU as was the condor_startds, but the condor_starters were at the expected 0% CPU level.\n\n</p><p>Without the procd we could only get ~5 jobs startd. The CPU use of the condor_master, condor_startds and condor_starters was 100% apiece. Jobs were running the slot1 slots for each startd.\n\n</p><p></p><hr/>\n<em>2011-Oct-24 16:30:55 by ichesal:</em> <br/>\n\nThe 7.6.5 preview from TJ is so close.\n\n<p>The good news:\n\n</p><p>Job startup and job termination -- both of those happen <strong>much</strong> faster than they ever have. Near instant when it works well.\n\n</p><p>For 40 sleep jobs Condor was able to take the machine from empty to all 40 slots running sleep jobs in a few seconds.\n\n</p><p>The bad news:\n\n</p><p>For 40 jobs that do actual CPU-bound processing Condor could only get 33 of the slots running jobs. It did fill them quickly, a few seconds at most before everything was running. The remaining 7 slots refused to run jobs. Run attempts failed because of interprocess I/O errors. These can be seen in the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=StartLog\" title=\"Start Log\">StartLog</a></span>. I'm attaching all the log files as well as screen cap of the machine in a steady state, 33/40 slots occupied, so you can see over all CPU use from taskman. The configuration used on the machine is also contained in the zip file.\n\n</p><p>This is definitely a better performing Condor release. Even while it was showing interprocess I/O I could still run condor_status -direct against the machine and the startd would respond. In the 7.6.4 release this isn't possible.\n\n</p><p></p><hr/>\n<em>2011-Oct-24 16:32:40 by ichesal:</em> <br/>\n\nZip file with the logs and configs is too big to be attached. Here's a download link: <a class=\"external\" href=\"http://dl.dropbox.com/u/870088/condor/condor-7.6.5-testing-logs.zip\">http://dl.dropbox.com/u/870088/condor/condor-7.6.5-testing-logs.zip</a>\n\n<p></p><hr/>\n<em>2011-Nov-07 09:49:22 by ichesal:</em> <br/>\n\nI'm re-testing the load jobs with John's patched binary today. Greatly reduced log verbosity, no logging for the procd. I'll let you know how it goes.\n\n<p>- Ian\n\n</p><p></p><hr/>\n<em>2011-Nov-11 12:40:05 by ichesal:</em> <br/>\n\nHi guys,\n\n<p>I was able to re-run the 7.6.5-PRE tests. This time: logging left at the default level on the STARTD and turned off completely on the PROCD. The jobs were CPU-bound jobs that were expected to run for about an hour each. We left the machine up for about 10 minutes and steady state was 30/40 slots occupied by jobs. The other 10 slots would try to start jobs, fail, repeat.\n\n</p><p>Log files and the config files used are available here: <a class=\"external\" href=\"http://dl.dropbox.com/u/870088/condor/condor-7.6.5-retest-logs.zip\">http://dl.dropbox.com/u/870088/condor/condor-7.6.5-retest-logs.zip</a>\n\n</p><p>Let me know if you need anything else.\n\n</p><p>Thanks!\n\n</p><p>- Ian</p></blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"abandoned\" href=\"/tickets?ticket=2424\" onclick=\"get_ticket_and_populate_wrapper('2424'); return false;\" title=\"windows startd does not scale beyond 12 slots\">#2424</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nwindows startd does not scale beyond 12 slots</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2453\" onclick=\"get_ticket_and_populate_wrapper('2453'); return false;\" title=\"Figure out why we can only run about 8 jobs on a windows exec node\">#2453</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nFigure out why we can only run about 8 jobs on a windows exec node</td></tr>\n</tbody></table>", "attachments": "", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Nov-07 08:56</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=28143\">[28143]</a></span>: statistics to measure performance of process monitoring. <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2441\" onclick=\"get_ticket_and_populate_wrapper('2441'); return false;\" title=\"Condor startd on Windows can't run more than 8 jobs simultaneously\">#2441</a></span> ===VersionHistory:None=== not intended to be user visible stats  (By John (TJ) Knoeller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Nov-07 08:56</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=28142\">[28142]</a></span>: performance measurement code for PROCAPI. builds on *nix but mostly only measures performance of the windows version of PROCAPI. in support of <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2441\" onclick=\"get_ticket_and_populate_wrapper('2441'); return false;\" title=\"Condor startd on Windows can't run more than 8 jobs simultaneously\">#2441</a></span> ===VersionHistory:None=== no user visible changes  (By John (TJ) Knoeller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Nov-04 16:12</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=28134\">[28134]</a></span>: statistics to measure performance of process monitoring. <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2441\" onclick=\"get_ticket_and_populate_wrapper('2441'); return false;\" title=\"Condor startd on Windows can't run more than 8 jobs simultaneously\">#2441</a></span> ===VersionHistory:None=== not intended to be user visible stats  (By John (TJ) Knoeller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Nov-04 16:06</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=28133\">[28133]</a></span>: performance measurement code for PROCAPI. builds on *nix but mostly only measures performance of the windows version of PROCAPI. in support of <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2441\" onclick=\"get_ticket_and_populate_wrapper('2441'); return false;\" title=\"Condor startd on Windows can't run more than 8 jobs simultaneously\">#2441</a></span> ===VersionHistory:None=== no user visible changes  (By John (TJ) Knoeller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Oct-20 09:27</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"chngview?cn=27913\">[27913]</a></span>: Change the windows implementation of CSysInfo::GetParentPID to use <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=NtQueryInformationProcess\" title=\"Nt Query Information Process\">NtQueryInformationProcess</a></span> rather than CreateToolhelp32Snapshot. This results in a 2000x performance improvement in ProcAPI::snapshot which in turn provides a partial fix for <span class=\"ticket\"><a class=\"resolved\" href=\"/tickets?ticket=2441\" onclick=\"get_ticket_and_populate_wrapper('2441'); return false;\" title=\"Condor startd on Windows can't run more than 8 jobs simultaneously\">#2441</a></span> - claim activation fail when more than 8 jobs running\u00a0[...]\n (By John (TJ) Knoeller )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2012-Dec-17 12:08", "status": "resolved", "created": "2011-Sep-07 15:35", "fixed_version": "2011-Sep-07 15:35", "broken_version": "v070600", "priority": "2", "subsystem": "Win32", "assigned_to": "tannenba", "derived_from": "#2381", "creator": "johnkn", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tstclair@redhat.com, tannenba@cs.wisc.edu, ichesal@cyclecomputing.com", "due_date": "20111110"}