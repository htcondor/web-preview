{"id": 1489, "title": "Ticket #1489: Fix distribution problems with condor_hdfs", "description": "<blockquote>\nThe condor_hdfs daemon is missing some needed jar files, and in general needs to be fixed so that it works with the public distribution of condor</blockquote>", "remarks": "<blockquote>\n<em>2010-Jul-07 12:40:59 by matt:</em> <br/>\n\nIs it going to be possible to use an HDFS from <a class=\"external\" href=\"http://hadoop.apache.org/hdfs\">http://hadoop.apache.org/hdfs</a> vs using one bundled with the Condor distribution?\n\n<p></p><hr/>\n<em>2010-Jul-07 13:13:16 by tstclair:</em> <br/>\n\nI could easily change this inside of the cmake build files for the hadoop externals.\n\n<p></p><hr/>\n<em>2010-Jul-07 14:29:51 by ilikhan:</em> <br/>\n\nI reviewed Condor source code for hadoop daemon, there were a few bugs. I fixed them.\n\n<p>Also updated the code to support new version ( 0.20.2 ) of HDFS.\n\n</p><p>You can either use HDFS package from <a class=\"external\" href=\"http://hadoop.apache.org/hdfs\">http://hadoop.apache.org/hdfs</a> or let condor_daemon to manage it.\n\n</p><p>I tried following test cases:\n* HDFS package ( 0.20.2 release from Apache) as namenode, condor_hdfs as data node.\n* condor_hdfs as namenode, another local copy of condor_hdfs as data_node\n\n</p><p>In both cases I put around 700MB test files. It seems that current code is working without problem.  I will commit changes ( in both source code and externals) as soon as possible.\n\n</p><p></p><hr/>\n<em>2010-Jul-07 21:15:24 by ilikhan:</em> <br/>\n\nFollowing changes made:\n\n<p>[ilikhan@harry] (164)$ git status\n# On branch master\n# Changes to be committed:\n#   (use \"git reset HEAD &lt;file&gt;...\" to unstage)\n#\n#       new file:   externals/bundles/hadoop/0.20.2/URLS\n#       new file:   externals/bundles/hadoop/0.20.2/build_hadoop-0.20.2\n#       new file:   externals/bundles/hadoop/0.20.2/build_hadoop-0.20.2.bat\n#\n# Changed but not updated:\n#   (use \"git add &lt;file&gt;...\" to update what will be committed)\n#   (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n#\n#       modified:   src/condor_examples/condor_config.generic\n#       modified:   src/condor_examples/condor_config.local.generic\n#       modified:   src/condor_hdfs/hadoop.cpp\n#       modified:   src/configure.ac\n#\n\n</p><p>[ilikhan@harry] (162)$ git diff\ndiff --git a/src/condor_examples/condor_config.generic b/src/condor_examples/condor_config.generic\nindex 344d754..3e125dd 100644\n--- a/src/condor_examples/condor_config.generic\n+++ b/src/condor_examples/condor_config.generic\n@@ -1083,7 +1083,7 @@ COLLECTOR                 = $(SBIN)/condor_collector\n STARTER_LOCAL                  = $(SBIN)/condor_starter\n JOB_ROUTER                      = $(LIBEXEC)/condor_job_router\n ROOSTER                         = $(LIBEXEC)/condor_rooster\n-HDFS                           = $(LIBEXEC)/condor_hdfs\n+HDFS                           = $(SBIN)/condor_hdfs\n SHARED_PORT                    = $(LIBEXEC)/condor_shared_port\n TRANSFERER                     = $(LIBEXEC)/condor_transferer\n\n</p><p>diff --git a/src/condor_examples/condor_config.local.generic b/src/condor_examples/condor_config.local.generic\ndiff --git a/src/condor_examples/condor_config.local.generic b/src/condor_examples/condor_config.local.generic\nindex 3951475..52c4e07 100644\n--- a/src/condor_examples/condor_config.local.generic\n+++ b/src/condor_examples/condor_config.local.generic\n@@ -30,7 +30,7 @@ KILL = FALSE\n ##  This macro determines what daemons the condor_master will start and keep its watchful eyes on.\n ##  The list is a comma or space separated list of subsystem names\n\n</p><p>-DAEMON_LIST = COLLECTOR, MASTER, NEGOTIATOR, SCHEDD, STARTD\n+DAEMON_LIST = COLLECTOR, MASTER, NEGOTIATOR, SCHEDD, STARTD, HDFS\n\n</p><p> ##  Sets how often the condor_negotiator starts a negotiation cycle.\n ##  It is defined in seconds and defaults to 60 (1 minute).\ndiff --git a/src/condor_hdfs/hadoop.cpp b/src/condor_hdfs/hadoop.cpp\nindex 10db8c6..7179fa9 100644\n--- a/src/condor_hdfs/hadoop.cpp\n+++ b/src/condor_hdfs/hadoop.cpp\n@@ -471,7 +471,7 @@ void Hadoop::startService(int type) {\n\n</p><p></p><pre>                 //For now always run name server with upgrade option, In case\n                 //Hadoop Jar files are updated to a newer version.\n-                arglist.AppendArg(\"-upgrade\");\n+                //arglist.AppendArg(\"-upgrade\");\n         }\n</pre>\n\n<p></p><pre>         MyString argString;\ndiff --git a/src/configure.ac b/src/configure.ac\nindex 3aaeb23..6a8ac39 100644\n--- a/src/configure.ac\n+++ b/src/configure.ac\n@@ -3199,7 +3199,7 @@ CHECK_EXTERNAL([curl],[7.19.6-p1],[soft])\n #Look for hadoop jars, required by HDFS daemon as well by hdfs file plugin\n # Only build hadoop external if hdfs is enabled\n AS_IF([test \"x$enable_hdfs\" = xyes],\n-  [CHECK_EXTERNAL([hadoop],[0.20.0-p2],[soft])])\n+  [CHECK_EXTERNAL([hadoop],[0.20.2],[soft])])\n</pre>\n\n<p> if test \"x$_cv_opsys\" = \"xLINUX\" ; then\n\n</p><p></p><hr/>\n<em>2010-Jul-07 21:37:22 by matt:</em> <br/>\n\nWho did the review?\n\n<p></p><div class=\"verbatim\">\n<pre>http://nmi-s006.cs.wisc.edu/results/Run-condor-details.php?runid=254831&amp;type=build&amp;user=cndrauto\n\n                                               Build Results\ntrunk-2010-7-7\t254831 \t2010-07-07 22:32:16 \tFAILED\n                                                Passed \t1\n                                                Pending\t1\n                                                Failed \t12\n</pre></div>\n\n\n<p></p><hr/>\n<em>2010-Jul-08 11:00:43 by ilikhan:</em> <br/>\n\nAt the first push accidentally I wrote hadoop version as 0.20.0 instead of 0.20.2 but then I fixed it.\n\n<p></p><hr/>\n<em>2010-Nov-19 07:08:27 by matt:</em> <br/>\n\nThis ticket is a code change (defect or enhance) not todo, what version did it go into?</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1494\" onclick=\"get_ticket_and_populate_wrapper('1494'); return false;\" title=\"Fix web interface problems with condor_hdfs\">#1494</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nFix web interface problems with condor_hdfs</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body><blockquote>\n<ul>\n<li><a href=\"../files/198/hadoop-0.20.2-upgrade.patch\">hadoop-0.20.2-upgrade.patch</a>\n3072 bytes added by ilikhan on 2010-Jul-09 16:49:27 UTC.\n</li></ul>\n</blockquote></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Jul-09 12:03</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/3107b4e18ba2e7440cbf6aa2bfff85ff4ce970a0\">[18563]</a></span>: added patch files for condor_hdfs daemon upgrade, see tickets <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1489\" onclick=\"get_ticket_and_populate_wrapper('1489'); return false;\" title=\"Fix distribution problems with condor_hdfs\">#1489</a></span> and <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1494\" onclick=\"get_ticket_and_populate_wrapper('1494'); return false;\" title=\"Fix web interface problems with condor_hdfs\">#1494</a></span>  (By ilikhan )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2010-Nov-19 11:20", "status": "resolved", "created": "2010-Jul-07 11:00", "fixed_version": "2010-Jul-07 11:00", "broken_version": "v070403", "priority": "3", "subsystem": "Daemons", "assigned_to": "ilikhan", "derived_from": "", "creator": "gthain", "rust": "", "customer_group": "other", "visibility": "public", "notify": "matt@cs.wisc.edu, tstclair@redhat.com", "due_date": ""}