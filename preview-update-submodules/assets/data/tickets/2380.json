{"id": 2380, "title": "Ticket #2380: Have option to run DAG Pre/Post scripts as starter Pre/Post scripts", "description": "<blockquote>\nThis came up during a previous LIGO call -- they wanted to be able to have the PRE and POST scripts run on the same machine as the job, and it was suggested that a way to do this was by actually running them as starter Pre and Post scripts.  It was then suggested that it would be good if there was some way to get DAGMan itself to automatically translate a DAG PRE/POST script to a starter PRE/POST script.  (I don't know if the way to do this would be to have some global setting that would run all of the scripts in the starter, or maybe a different keyword for scripts that should be run by the starter.)\n\n<p>Hmm -- something I just thought about -- this obviously won't work for scheduler-universe node jobs.  If you try to do this for a scheduler-universe node job, DAGMan should issue an error if Condor itself doesn't.</p></blockquote>", "remarks": "<blockquote>\n<em>2012-Apr-20 14:29:42 by wenger:</em> <br/>\n\nStarter scripts are now documented in 7.7.6 (see <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2379\" onclick=\"get_ticket_and_populate_wrapper('2379'); return false;\" title=\"Starter Pre and Post scripts are not documented\">#2379</a></span>).  I can't really link to the docs yet, because 7.7.6 isn't released yet...\n\n<p></p><hr/>\n<em>2013-Jan-25 12:23:42 by wenger:</em> <br/>\n\nI was thinking about how to specify in the DAG file that you want to run your scripts as starter scripts, and I was thinking something like this:\n\n<p></p><pre>  SCRIPT [STARTER] PRE JobName ExecutableName [arguments]\n</pre>\n\n<p></p><pre>  SCRIPT [STARTER] POST JobName ExecutableName [arguments]\n</pre>\n\n<p>or else maybe:\n\n</p><p></p><pre>  STARTER_SCRIPT PRE JobName ExecutableName [arguments]\n</pre>\n\n<p></p><pre>  STARTER_SCRIPT POST JobName ExecutableName [arguments]\n</pre>\n\n<p>Anyone have a strong preference for one way or the other?\n\n</p><p></p><hr/>\n<em>2013-Jan-25 12:36:14 by wenger:</em> <br/>\n\nJust created V7_9-gittrac_2380-branch for this...\n\n<p></p><hr/>\n<em>2013-Jan-25 13:16:50 by tannenba:</em> <br/>\n\nKent, you should write a design document for what you are thinking before writing a lot of code....  thanks.\n\n<p></p><hr/>\n<em>2013-Jan-25 13:23:27 by wenger:</em> <br/>\n\nYes, I need to do some testing to fully understand how the starter scripts work before I come up with a design...\n\n<p></p><hr/>\n<em>2013-Feb-22 16:21:12 by wenger:</em> <br/>\n\nNote: the starter pre and post scripts are documented on the condor_submit man page.\n\n<p></p><hr/>\n<em>2013-Feb-25 15:22:03 by wenger:</em> <br/>\n\nDAGMan should be able to specify starter pre and post scripts using the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=PreCmd\" title=\"Pre Cmd\">PreCmd</a></span>, <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=PostCmd\" title=\"Post Cmd\">PostCmd</a></span>, and Pre/PostArgs and/or Pre/PostArguments classad attributes.  Without some changes to condor_submit, though, I don't think there's any way for DAGMan to add the pre or post script to the input file list for file transfer -- I need to do a little more checking on that.\n\n<p>If I'm right, though, we'll have to make some changes to condor_submit to implement this.\n\n</p><p></p><hr/>\n<em>2013-Feb-25 15:51:57 by wenger:</em> <br/>\n\nHmm -- another issue is that the semantics of starter post scripts are different than that of DAGMan POST scripts, in that the starter post scripts are not run if the job is evicted -- we need to think about how to deal with that.\n\n<p>Hmm -- here's another issue -- getting back the exit code of the starter post script!  We really need to do that -- I'll have to look at the code, I guess, and see whether that gets saved anywhere...\n\n</p><p></p><hr/>\n<em>2013-Mar-05 10:26:59 by wenger:</em> <br/>\n\nHmm -- something else I just thought of (assuming we don't have a shared filesystem):  if a PRE or POST script uses an input file that's not specified as an input file in the submit file, we'd have to add that to the list of files that gets transferred.  It may be tricky to figure this out -- we can't really know if an argument to one of the scripts is a file name or not.  We can obviously figure out that we need to add the scripts themselves, but input files are much trickier.\n\n<p></p><hr/>\n<em>2013-Mar-05 15:03:29 by wenger:</em> <br/>\n\nJust to clarify what I was referring to in the previous remark:\n\n<p>Say we have an input file in1 that the PRE script transforms to in2, which is then the input to the actual executable of the job.  Then, if we run the PRE script in the \"normal\" way, the file we have to transfer is in2.  But if we run the PRE script as a starter script, we have to transfer in1.\n\n</p><p>(My goal is to be able to have everything work in the same way whichever way you're running the scripts, but I think that may not be possible in all cases.)\n\n</p><p></p><hr/>\n<em>2013-May-03 13:58:56 by wenger:</em> <br/>\n\nI just talked with Carsten about this at HTCondor week and clarified their use case, which is as follows:\nThey have jobs for which data has to be copied onto the execute machine, and copied back after the job runs.  (They are doing this copying outside of HTCondor's file transfer mechanism.)  The big thing is that they need to throttle the \"input copying\" separately from the compute jobs (and maybe throttle the \"output copying\" too (although that's not as much of a problem because the compute jobs don't all finish at once)).\n\n<p>So running the PRE and POST scripts as starter scripts is not really what they need, because if they do that DAGMan can't throttle the scripts separately from the actual jobs.\n\n</p><p>I can think of a couple of ways to address this, maybe there are others:\n\n</p><p></p><ol>\n<li>Make the copying tasks actual HTCondor jobs, with a capability to make a given input, compute, and output job all land on the same machine.  Then you could do the throttling with DAGMan node categories.\n\n<p></p></li><li>Have the PRE and POST script know what machine the job will run/ran on.  I'm wondering if we could do something like this:  submit the job in a special state where it gets matched with a machine but not actually run; then DAGMan runs the PRE script, and when that finishes does something to allow the job to continue.  Once the job finishes, it goes into a special state that doesn't do stuff like transferring files back; in the mean time DAGMan runs the POST script, and when it's finished tells the job to do the normal HTCondor post-job stuff.  (We'd have to add some special PRE and POST script arguments to tell the scripts the machine that the job landed on, and probably its directory.)  Then you could do the throttling with maxpre/maxpost.\n</li></ol>\n\n<p></p><hr/>\n<em>2014-May-20 11:40:46 by wenger:</em> <br/>\n\nI'm going to reduce the priority of this one because we don't need it as much if we implement the more flexible retry feature (<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1309\" onclick=\"get_ticket_and_populate_wrapper('1309'); return false;\" title=\"DAGMan: retry subset of a DAG\">#1309</a></span>).\n\n<p></p><hr/>\n<em>2015-Dec-09 13:21:38 by wenger:</em> <br/>\n\nResurrecting this ticket as per discussion on today's LIGO call.\n\n<p></p><hr/>\n<em>2015-Dec-16 11:11:11 by wenger:</em> <br/>\n\nToddT thinks we should do this -- probably combined with checksumming all file transfers by default.\n\n<p></p><hr/>\n<em>2019-Apr-10 15:03:46 by pfc:</em> <br/>\n\nI'm assuming solely based on the age of this ticket that it's safe to demote to priority 5 and defer.  If I'm wrong, please speak up.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-10 15:04</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/f33ac7baac5d095c1fc2d359d970b46b0b9dba61\">[35367]</a></span>: Gittrac <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2380\" onclick=\"get_ticket_and_populate_wrapper('2380'); return false;\" title=\"Have option to run DAG Pre/Post scripts as starter Pre/Post scripts\">#2380</a></span>: Committing some diagnostic code on the branch.  (By Kent Wenger )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2019-Apr-10 15:03", "status": "defer", "created": "2011-Aug-12 11:46", "fixed_version": "2011-Aug-12 11:46", "broken_version": "v070700", "priority": "5", "subsystem": "Dag", "assigned_to": "", "derived_from": "", "creator": "wenger", "rust": "", "customer_group": "ligo", "visibility": "public", "notify": "wenger@cs.wisc.edu, tannenba@cs.wisc.edu, pfcouvar@syr.edu, coatsworth@cs.wisc.edu,pcouvare@caltech.edu", "due_date": ""}