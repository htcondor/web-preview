{"id": 189, "title": "Ticket #189: Allow Selector class to use epoll system call where available", "description": "<blockquote>\nWhen using CCB, we may have a lot of file descriptors to poll for.  The select(2) interface is rather slow when you poll with a lot of FDs, linux 2.6 added the epoll system call which scales better.  We should configure check for epoll, and change the selector object to use epoll where available.</blockquote>", "remarks": "<blockquote>\n<em>2014-Oct-29 09:05:24 by bbockelm:</em> <br/>\n\nWe've already started to use epoll in the CCB.\n\n<p>Looking at the CMS scale test system (200k slots) load on CCB-only collectors versus the pool collector, I'd speculate that the use of select() is causing significant CPU usage.\n\n</p><p>A few significant parts of implementing this:\n</p><ul>\n<li>epoll can have overhead to setup the set of listeners.  We wouldn't want to do this each time we return to DC.  This means the selector has to know whether it's a \"long term\" object or \"short term\" object.\n</li><li>epoll can cause starvation if not designed right.  The kernel returns an active object at a time, in undefined order.  We'd need to decide if we would want to read out all possible sockets each execution cycle.\n<ul>\n<li>Maybe strongly consider whether to have a selector instance per 'priority level'?\n</li></ul>\n</li><li>DC::Driver (and many parts of DC) would need to be overhauled so we have a single, long-lived selector instance.\n</li></ul>\n\n<p></p><hr/>\n<em>2014-Nov-23 11:34:01 by bbockelm:</em> <br/>\n\nOk, I've been looking into this a bit more.  I think this can be done in a few steps:\n<ol>\n<li>Refactor <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DaemonCore\" title=\"Daemon Core\">DaemonCore</a></span> so all management of sockTable is done in a separate class.  At the same time, move to a long-lived selector object; the selector is updated whenever sockets are added / deleted.  Pipes and the signal FD are registered at each DC driver loop.\n<ul>\n<li>Where possible, move from using the selector's is_fd_ready() interface directly to an iterator over ready sockets.\n</li></ul>\n</li><li>Refactor DC so the pipe lifetime management is done in a separate class; the long-lived selector is only changed when pipes are added / deleted.\n</li><li>Refactor the selector to use epoll internally.\n</li></ol>\n\n<p>The optional follow-up work would then be:\n</p><ul>\n<li>Switch from a signal FD to an event FD on appropriate Linux platforms.  Saves a syscall every DC driver loop.\n</li><li>Check for expired sockets once a second.\n</li><li>Do not iterate through all the descriptors every DC driver loop - instead, iterate through only the ready ones. This eliminates the necessity of having to do the recheck logic.\n</li></ul>\n\n<p></p><hr/>\n<em>2014-Nov-30 20:28:37 by bbockelm:</em> <br/>\n\nAlright, committed step 1 of the above outline; see branch V8_3-gt189.\n\n<p>As one might expect, it's a pretty big refactor of hairy daemon_core.cpp code.  I'd like to get this reviewed before moving on to step 2.  Luckily, the remainder of the patches should be smaller, straightforward steps for the reviewer to follow.\n\n</p><p></p><hr/>\n<em>2015-Jan-09 13:06:06 by bbockelm:</em> <br/>\n\nSome more information to help with performance evaluation:\n<ul>\n<li>In CMS, we want to eventually have a single collector to support 200k startds.\n</li><li>I estimate the corresponding sustained update rate is 400Hz.\n</li><li>During a DC::Driver loop, select is called once.  After one socket has been serviced, poll is called on any other socket marked as ready by the original select call.  <strong>Hence</strong>, we can't really extrapolate linearly - as select slows down, we poll more often.  Poll is <strong>much</strong> faster in this case.\n</li></ul>\n\n<p></p><hr/>\n<em>2015-Jan-09 14:48:19 by gthain:</em> <br/>\n\nI'm not sure that select is a huge bottleneck.  I ran a test with 200k concurrent connections to a single collector, and select was generally 50 microseconds or faster.\n\n<p></p><hr/>\n<em>2015-Jan-13 09:39:23 by gthain:</em> <br/>\n\nSeeing as the system cpu bottleneck is because of forking, we're going to abandon this ticket for now.  Work to address excessive forking is in <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=4821\" onclick=\"get_ticket_and_populate_wrapper('4821'); return false;\" title=\"Only fork collector for a few ad types\">#4821</a></span></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body><blockquote>\n<ul>\n<li><a href=\"../files/860/times.gif\">times.gif</a>\n6866 bytes added by gthain on 2015-Jan-09 20:48:58 UTC.\n<br/>\nHere's a graph of select times vs. number of established connections to a single schedd.<br/>\n</li></ul>\n</blockquote></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Dec-29 10:10</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/4a9111e8bb40ab38b6be7a7e3628b801d1d9c023\">[42040]</a></span>: Bugfixes for centralized epoll. <span class=\"ticket\"><a class=\"abandoned\" href=\"/wiki-archive/tickets/?ticket=189\" onclick=\"get_ticket_and_populate_wrapper('189'); return false;\" title=\"Allow Selector class to use epoll system call where available\">#189</a></span>  (By Brian Bockelman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Dec-07 05:16</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/de621df223bdbb00073a0bc40f6887f10d5673d5\">[42038]</a></span>: Switch DC to epoll. <span class=\"ticket\"><a class=\"abandoned\" href=\"/wiki-archive/tickets/?ticket=189\" onclick=\"get_ticket_and_populate_wrapper('189'); return false;\" title=\"Allow Selector class to use epoll system call where available\">#189</a></span> Using the central <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=SockManager\" title=\"Sock Manager\">SockManager</a></span> class, we now use epoll for all registered sockets. Note that select is still used for pipes - I consider this OK because the daemon we are most concerned about (the collector) keeps no pipes.\u00a0[...]\n (By Brian Bockelman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2014-Nov-30 20:24</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/7e8a33bfe26ea4c53e4137bc81eaad78b7c6a2fb\">[41777]</a></span>: This commit introduces the concept of a \"Socket Manager\", which manages the socket table and a corresponding selector. <span class=\"ticket\"><a class=\"abandoned\" href=\"/wiki-archive/tickets/?ticket=189\" onclick=\"get_ticket_and_populate_wrapper('189'); return false;\" title=\"Allow Selector class to use epoll system call where available\">#189</a></span>\u00a0[...]\n (By Brian Bockelman )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2015-Jan-13 09:39", "status": "abandoned", "created": "2009-Feb-05 15:08", "fixed_version": "2009-Feb-05 15:08", "broken_version": "v070300", "priority": "5", "subsystem": "Daemons", "assigned_to": "gthain", "derived_from": "", "creator": "gthain", "rust": "", "customer_group": "other", "visibility": "public", "notify": "", "due_date": ""}