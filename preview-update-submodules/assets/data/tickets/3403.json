{"id": 3403, "title": "Ticket #3403: Have DAGMan option for retries to land on different machines", "description": "<blockquote>\nI just ran into a case working with BMRB where jobs were failing because of a problem on an OSG execute machine, and retries weren't doing any good because jobs kept landing on the same machine.  It would be really nice to just have a flag in DAGMan to say \"force retries to land on a different execute machine than the job failed on\".  In fact, it would be really nice to say, \"if any job of category X fails on a certain execute machine, don't let any more jobs of category X land on that machine\".</blockquote>", "remarks": "<blockquote>\n<em>2012-Dec-28 11:21:12 by nwp:</em> <br/>\n\nCHTC tries to do this by using <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRemoteHost\" title=\"Last Remote Host\">LastRemoteHost</a></span>, but this messes up autoclustering, slowing down the negotiator.\n\n<p></p><hr/>\n<em>2013-Jan-08 14:51:57 by wenger:</em> <br/>\n\nWe just discussed this on today's LIGO call, and the LIGO people think this is a good idea.  They would like this feature to be on by default when/if it's implemented.  I guess the question is whether you turn it on/off at the DAG level or the node level.\n\n<p>Also, I'm thinking we could do something like:\n\n</p><p></p><pre>  RETRY_GROUP &lt;node name&gt; &lt;group name&gt;\n</pre>\n\n<p>to designate groups that share the list of \"black hole\" execute machines.\n\n</p><p></p><hr/>\n<em>2013-Jan-08 15:43:20 by pfc:</em> <br/>\n\nFor me, the groups idea is nifty but I wouldn't hold up the basic individual-host functionality for it.  Unless it's trivial to do together, maybe separate the two?\n\n<p></p><hr/>\n<em>2013-Jan-22 11:49:24 by wenger:</em> <br/>\n\nOkay, now I'm thinking of doing something like this:\n\n<p></p><pre>  RETRY_ON_DIFFERENT_MACHINE &lt;node name&gt; [retry group]\n</pre>\n\n<p>I'm thinking that we'd probably want to encourage people to do the retry groups, because then you'd get a bunch of jobs all avoiding the same machines, so they'd all be the same matchmaking-wise.\n\n</p><p>I guess we could implement it first without the group feature, if that's significantly quicker, though.  I'm thinking we'd have a separate retry object dealing with the machines to avoid -- if nodes are in a retry group, they'd all point to the same retry object; if they're not in a group, each node would point to its own retry object.  Then, to implement groups, we'd just have to be able to create the retry objects accordingly.\n\n</p><p>This may also take some changes to condor_submit, so that DAGMan can specify conditions that get added into the requirements.\n\n</p><p></p><hr/>\n<em>2013-Jan-22 13:04:23 by wenger:</em> <br/>\n\nAlso, maybe there should be a configuration knob for the maximum number of \"black hole\" machines we will try to avoid.\n\n<p></p><hr/>\n<em>2013-Jan-23 18:19:29 by bbockelm:</em> <br/>\n\nWhy not add this to condor_submit proper?\n\n<p></p><hr/>\n<em>2013-Mar-06 14:34:20 by wenger:</em> <br/>\n\nI just mentioned this to Bill Taylor, and he said he'd really like this feature.  He's essentially doing it \"manually\" for his jobs now.\n\n<p>One further note is that we might want to expand this to say, \"I want my retries to land on a different <strong>site</strong>\" (not just a different individual machine).</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2013-Mar-06 14:34", "status": "new", "created": "2012-Dec-28 11:06", "fixed_version": "2012-Dec-28 11:06", "broken_version": "v070902", "priority": "4", "subsystem": "Dag", "assigned_to": "", "derived_from": "", "creator": "wenger", "rust": "", "customer_group": "chtc", "visibility": "public", "notify": "wenger@cs.wisc.edu, bt@cs.wisc.edu", "due_date": ""}