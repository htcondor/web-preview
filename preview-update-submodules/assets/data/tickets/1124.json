{"id": 1124, "title": "Ticket #1124: Make condor_tests better", "description": "<blockquote>\nFor 7.5 there is a general task to make Condor's tests \"better.\"  This encompasses a lot of things, so this ticket will collect them.  Check the list of derived tickets below for specific entries.\n\n<p>Some tickets can't be listed as child tickets because they're children of some other ticket.  Here's a list of those special cases:\n\n</p><p></p><ul>\n<li>Ticket <span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1074\" onclick=\"get_ticket_and_populate_wrapper('1074'); return false;\" title=\"Eval Behavior Testing Frameworks &amp; Unit Testing Frameworks\">#1074</a></span>: Eval Behavior Testing Frameworks &amp; Unit Testing Frameworks\n</li></ul>\n\n<p>Also worth reviewing is <a class=\"external\" href=\"http://condor-wiki.cs.wisc.edu/index.cgi/rptview?rn=4&amp;Type=ALL&amp;Status=ALL+BUT+RESOLVED&amp;Subsys=Tests&amp;Group=ALL&amp;Visibility=ALL&amp;Created_By=ALL&amp;Assigned_To=ALL\">this list of unresolved tickets in the \"Regression Tests\" category</a>.\n\n</p><p><span class=\"section\"></span></p><h2>High Level Goals</h2>\n\n<p>We'd like to address the following issues that exist w/ condor_tests :\n\n</p><p></p><ol>\n<li>Blurring of framework -vs- test. The line that separates \"what is a test\" and \"what is the framework\" has become blurred.  This resulted in a lot of cut-n-paste code, meaning bugs need to be discovered and fixed over and over.\n\n<p></p></li><li>Tests are too complicated/lengthy to write.  Writing a test is much harder than it needs to be, than if shared functionality was actually identified, documented, and living in a shared place.\n\n<p></p></li><li>False positives.  (1) We have many more tests written than we actually run -- these tests are sitting in limbo because they create false positives.  (2) The test harness/framework itself is very fragile, also creating false positives. (3) Some tests that have false positives are too critical to put into \"limbo\", so we run them anyhow.  This means every time they fail, the release wrangler needs to spend time figuring out if it is a false alarm.\n\n<p></p></li><li>Many tests we run on Unix are not run on Windows, for no particularly good reason.  Plus at some point, the test harness for Unix and Windows diverged, also for no good long-term reason.\n\n<p></p></li><li>Parallel testing non-deterministically fails, severely limiting its utility.  By \"parallel\" testing, I don't mean testing parallel universe, I mean enabling the test harness run more than one test simultaneously.  The goal is a faster test/feedback loop, and also significantly reduce our resource impact on NMI.  Currently running one test at a time our test suite takes 18 hours with the load average on the machine very small.  Running 25 tests simultaneously, we finish in a couple hours.\n\n<p></p></li><li>Blurring of running tests inside NMI -vs- outside of NMI.  I want the Condor tests to be independent of NMI, i.e. someone can download the Condor source and run the regression tests on their own workstation.  Again, due to blurring of layers, some test functionality is broken outside of NMI.\n\n<p></p></li><li>All our regression (and unit tests) are functional.  We'd like some tests to address regressions in performance and resource consumption.\n</li></ol>\n\n<p><span class=\"section\"></span></p><h2>Estimated Timeline</h2>\n\n<p></p><ul>\n<li>Make it easy for a new tests to consist of a single file\n<ol>\n<li>[? days, ????-??-?? danb] generate .cmd files on the fly, as opposed to having a condor_tests/*.cmd file per .run that submits a job. Ideally have a \"default\" submit file that the caller can override.\n</li><li>[? days, ????-??-?? danb] Write arbitrary files out, for use as \"write_file('mytest.c', &lt;&lt;ENDOFC);\". This way the *.c, *.C, *.h, *.pl, *.in, etc files can be put inside the single .run file.\n</li><li>[? days, ????-??-?? danb] Document this as the New Way To Do It.\n</li><li>[? days, ????-??-?? ?] Once done, covert a few older tests to this system as a proof of concept\n</li><li>[?] Tests should self-identify as to which platforms and test sets they should run on. Perhaps a \"--info\" option that batch_test.pl runs to extract the information, or perhaps we run the test on all platforms, returning a special \"okay,skipped\" result reported separately (and allowing us to distinguish \"didn't run for unknown reason\" versus \"didn't run by intent\")\n</li><li>[The Future] Then get a student to bulk convert older tests, only bothering with easy ones. Any problems with a test, leave it alone and move on.\n</li></ol>\n\n<p></p></li><li>Add new performance/scalability tests\n<ol>\n<li>[dependency] Make it easy for a new tests to consist of a single file\n</li><li>[? days, ????-??-?? danb] Create new performance/scalability tests.\n</li></ol>\n\n<p></p></li><li>Improve test isolation (Prerequisite to making parallel tests work, cleaning up test direct/simplifying debugging of tests, allowing tests to run repeatedly)\n<ol>\n<li>[2 days, 2010-02-19 adesmet] Cleanup batch_test.pl\n</li><li>[4 days, 2010-02-24 adesmet] Run tests in newly created work directory.  Blacklist all old tests to not do this.\n</li><li>[2 days, 2010-02-26 adesmet] Fix a few representative tests to confirm to running work directories, remove from blacklist.\n</li><li>[1 day, 2010-03-01 adesmet] Document that all new tests must confirm to this system.\n</li><li>[The Future] Fix tests that can't confirm.\n</li></ol>\n\n<p></p></li><li>Make running tests in a loop easier (to ease developerment/debugging)\n<ol>\n<li>[dependency] Improve test isolation (see above)\n</li><li>[3 days, 2010-03-04 adesmet] More aggressively clean up child processes.  In particular, shut down daemons when tests fail (currently leaks daemons).\n</li><li>[3 days, 2010-03-08 adesmet] Fix tests that can't be run in a loop.  (This is really just a special case of \"Fix tests that can't conform\" above.)\n</li></ol>\n\n<p></p></li><li>Get parallel tests running\n<ol>\n<li>[dependency] Improve test isolation (see above)\n</li><li>[5 days, 2010-03-15 adesmet] Get parallel tests working.\n</li><li>[1 day, 2010-03-16 adesmet] Enable parallel tests in NMI by default.\n</li></ol>\n\n<p></p></li><li>Clean up fragile tests\n<ol>\n<li>[ongoing danb] Monitor nightly tests, identify flakey tests.\n</li><li>[?] Go through identified flakey tests and make them more robust.\n</li><li>[?] Investigate disabled tests. Fix those that can be salvaged and reenable them.  Remove fundamentally flawed ones.\n</li></ol>\n\n<p></p></li><li>Unify Unix/Windows testing code paths.\n<ol>\n<li>[10 days, 2010-03-30 adesmet]  Have the same system (batch_test.pl) drive both the Windows and Unix tests.  Currently Windows uses its own system.\n</li><li>[3 daays, 2010-04-02 adesmet] Review tests not running on Windows, enable any that should work under Windows.\n</li></ol>\n</li></ul>\n\n<p><span class=\"section\"></span></p><h2>Junk drawer</h2>\nRandom thoughts; if they're good ideas, they should become their own tickets\n<ul>\n<li>Windows tests run using a different system. We should unify them.\n</li><li>Reduce false positives\n</li><li>Move business logic for testing out of nmi_glue\n</li><li>Parallize tests\n</li><li>Tests should store information about itself internally: which platforms it supports, which lists its in.  Currently this is stored in different places.\n</li><li>Run all the tests always. If a given test isn't appopriate on a particular platform, it should run but return some well known \"skip\" value.\n</li><li>Ideally, I should be able to download Condor, \"./configure &amp;&amp; make &amp;&amp; make test\" and have it Just Work.\n<ul>\n<li>Why do I need to \"make release\"?\n</li><li>Why do I need to explicitly put the release_dir in my PATH? (Doubly so, since it demands that the release_dir exist in the first place.)\n</li><li>Why doesn't \"make test\" work? (does it?)\n</li><li>Why do I need to pass a bunch of options to \"batch_test.pl\"\n</li></ul>\n</li><li>batch_test.pl should create a test-run/pid_of_batch_test.pl/testname directory for each test.  This will make finding the correct results, cleaning up, and ensuring that\n</li><li>Rename batch_test.pl to batch_test. Implementation language is irrelevant.\n</li><li>Why isn't \"-c\" (cleanup) the default for batch_test.pl if \"-b\" (set up a new Condor) is present? It's surprising that a Condor test would leave new daemons running.\n</li><li>Why doesn't \"-b\" default to using ../release_dir/*bin instead of \"whatever happens to be in the path.\"\n</li><li>Why do I need to specify -f to list a list containing a list of tests to run. Why do I need to specify -t to list an executable to run.  Why not just assume that any filenames passed in are such files.  If it ends in .run, it's a test.  If it ends in _list, it's a list.  If we're feeling really bold, scan the file; if it looks like a list of files, it's a list, otherwise it's a test.\n</li><li>Many test builds are broken up into subdirs called g77, gcc, gpp, and gfortran.  That's not helpful or useful at all.  Break up by test name?  Or just a big old \"binaries\"?\n</li><li>I appear to need \"-dir .\" to batch_test.pl to get non-standard universe tests to work. It should Just Work.\n<ul>\n<li>Reportedly \"-dir .\" means standard universe tests don't work.\n</li></ul>\n</li><li>Requests from psilord - Clean up means \"shut down running daemons\"\n<ul>\n<li>When a test is turned off, it should be marked as \"skipped\" in the test\nsuite output so we don't forget about it due to out of sight, out of mind.\n</li><li>Should clean up after itself after a Ctrl-C\n</li><li>Should clean up after itself if tests fail\n</li><li><span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=8\" onclick=\"get_ticket_and_populate_wrapper('8'); return false;\" title='Add \"use warnings\" and \"use strict\" to test scripts'>#8</a></span> use strict use warnings\n</li><li>Many condor tests cannot be repeatedly run; left over files cause problems. All tests should clean themselves up.\n<ul>\n<li>Possible failures:job_vmu_basic.run job_vmu_cdrom.run job_vmu_ckpt.run\n</li></ul>\n</li><li>\"batch_test.pl -b\" reportedly only tests standard universe.\n</li><li>The NMI glue builds the tests in the test suite in a radically different manner than how a developer does it. Basically, the test glue builds a few named targets, then each test actually needing to be run is built independently. Since some of those tests rely on a new dependency which has to exist in the toplevel condor_tests/ directory, I'd have to add a new make invocation in the glue to ensure it exists. Make can't do it itself, because there are completely separate Makefiles in condor_tests/ condor_tests/gcc condor_tests/g77 condor_tests/gpp condor_tests/f90 that don't really know about each other. (Mentioned as part of <span class=\"ticket\"><a class=\"abandoned\" href=\"/wiki-archive/tickets/?ticket=974\" onclick=\"get_ticket_and_populate_wrapper('974'); return false;\" title=\"NMI Glue is a Pit of Despair\">#974</a></span>)\n</li></ul>\n</li><li>There are 1,207 files in condor_tests as of the head of master.  They consist of the following; some are directories:\n<div class=\"code\">\n<pre class=\"code\">    323 *.run\n    295 *.cmd\n    217 *.pl\n     73 *.dag\n     44 *.template\n     41 *.c\n     35 *postsrc\n     11 job_dagman_*subdir*\n     10 *.cpp\n      9 *.java\n      9 *.data\n      9 *.class\n      7 *.sh\n      6 *.in\n      6 *.gz\n      6 *.f\n      6 *.config\n      3 *.pm\n      3 *.cfg\n      2 *.tgz\n      2 *.h\n      2 *.common\n     88 OTHER\n</pre></div>\n\n</li></ul>\n\n<p><span class=\"subsection\"></span></p><h3>Alan's proposal</h3>\n\n<p>Assumptions:\n</p><ul>\n<li>Work must be interruptable. Ideally every few days the test system should be observably better it at least a small way.  All-or-nothing is too dangerous.\n</li><li>The existing test infrastructure is huge and hairy.  We must accept that we're unlikely to fix everything.  Focus on future work and low hanging fruit in the old work.\n</li><li>A single Grand Unified System probably won't work.  Testing is inherently complex and varied.\n</li></ul>\n\n<p>We should have two high level goals:\n</p><ol>\n<li>\"./configure &amp;&amp; make &amp;&amp; make test &amp;&amp; make test\" should Just Work.\n</li><li>Clean up our mess/make development easier.\n</li></ol>\n\n<p>These have many parts:\n</p><ol>\n<li>\"./configure &amp;&amp; make &amp;&amp; make test &amp;&amp; make test\" should Just Work.\n<ul>\n<li>\"make test\" should \"cd condor_tests &amp;&amp; make &amp;&amp; ./batch_test.pl\" (easy)\n</li><li>\"make\" at the top level should imply \"make release\" or the tests should work on a normal \"make\" that lacks a matching \"make release\".\n</li><li>\"./batch_test.pl\" should: configure and start up a local condor using the binaries built in ../, run the list_quick tests, shut down condor.  This is mostly a matter of changing defaults, although we'll ideally want batch_test.pl to be aggressive about cleaning up started Condor daemons during abnormal exits.\n</li><li>Why \"make test\" twice?  Some tests can't run twice in a row.  This makes a \"doesn't work, try a fix, try a test\" fail in non-obvious ways.  Identify broken tests and fix them.\n</li></ul>\n\n<p></p></li><li>Clean up our mess/make development easier.\n<ul>\n<li>Cut down on the number of files in the test directory\n<ul>\n<li>Make it easy for a new tests to consist of a single file\n<ul>\n<li>Flesh out condor_scripts/CondorTest.pm with new functionality to:\n<ul>\n<li>generate .cmd files on the fly, as opposed to having a condor_tests/*.cmd file per .run that submits a job.  Ideally have a \"default\" submit file that the caller can override.\n</li><li>Write arbitrary files out, for use as \"write_file('mytest.c', &lt;&lt;ENDOFC);\".  This way the *.c, *.C, *.h, *.pl, *.in, etc files can be put inside the single .run file.\n</li></ul>\n</li><li>Document this as the New Way To Do It.\n</li><li>Once done, covert a few older tests to this system as a proof of concept\n</li><li>Then get a student to bulk convert older tests, only bothering with easy ones. Any problems with a test, leave it alone and move on.\n</li></ul>\n</li><li>Tests should run inside of a newly created work directory: This will simplify 1. finding results, especially after multiple runs 2. cleaning up, and 3. finding test files after a test has been run.\n<ul>\n<li>condor_tests/results/$timestamp_batch_test_pl_started-$pid_of_batch_test_pl/$testname.\n</li><li>This will almost certainly break many old tests, solution: whitelist old tests that don't Just Work. All new tests should conform.\n</li><li>Another good student task would be taking that whitelist and moving the easiest to fix ones out of the whitelist.\n</li><li>Some tests expect to share files with other tests.  A shared directory (condor_tests/results/$timestamp_batch_test_pl_started-$pid_of_batch_test_pl/shared) should do the job.  But, we should avoid doing so if feasible. If particular input is widely reused, perhaps it belongs in condor_scripts/CondorTest.pm.\n</li></ul>\n</li><li>Test binary builds should be cleaned up.  Many test builds are broken up into subdirs called g77, gcc, gpp, and gfortran. That's not helpful or useful at all. Break up by test name? Or just a big old \"binaries\"?\n</li></ul>\n</li><li>If the tests started up Condor daemons (because of \"-b\" or the new default), it should shut them down when batch_test.pl exits.  Right now if you run a series of tests that fail or are interrupted, you leave daemons behind.  This make testing in a loop a nuisance.\n<ul>\n<li>If -b or equivalent, -c should be also be set by default unless specifically overridden.\n</li><li>If -c is set, and the program exits for any reason (exit, die or SIGINT), shut them down.</li></ul>\n</li></ul>\n</li></ol>\n</blockquote>", "remarks": "<blockquote>\n<hr/>\n<em>2010-Oct-20 16:03:30 by jfrey:</em> <br/>\n\nBulk change of target version from v070504 to v070505 using ./ticket-target-mover.\n<hr/>\n<em>2011-Jan-27 14:46:04 by danb:</em> <br/>\n\nBulk change of target version from v070505 to v070506 using ./ticket-target-mover.\n<hr/>\n<em>2011-Feb-01 14:49:30 by tannenba:</em> <br/>\n\nBulk change of target version from v070506 to NULL using ./ticket-target-mover.</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=297\" onclick=\"get_ticket_and_populate_wrapper('297'); return false;\" title=\"Test Cruft Code Review\">#297</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nTest Cruft Code Review</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1074\" onclick=\"get_ticket_and_populate_wrapper('1074'); return false;\" title=\"Eval Behavior Testing Frameworks &amp; Unit Testing Frameworks\">#1074</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nEval Behavior Testing Frameworks &amp; Unit Testing Frameworks</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1125\" onclick=\"get_ticket_and_populate_wrapper('1125'); return false;\" title=\"make in condor_tests needlessly recreates symlinks\">#1125</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nmake in condor_tests needlessly recreates symlinks</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1146\" onclick=\"get_ticket_and_populate_wrapper('1146'); return false;\" title=\"Give CondorTest.pm a more idiomatic object-oriented interface\">#1146</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nGive CondorTest.pm a more idiomatic object-oriented interface</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"stalled\" href=\"/wiki-archive/tickets/?ticket=1147\" onclick=\"get_ticket_and_populate_wrapper('1147'); return false;\" title=\"Make tests more self contained / expand CondorTests.pm\">#1147</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nMake tests more self contained / expand CondorTests.pm</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1148\" onclick=\"get_ticket_and_populate_wrapper('1148'); return false;\" title='Refactor \"report on test and exit\" code from test into CondorTest.pm'>#1148</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nRefactor \"report on test and exit\" code from test into CondorTest.pm</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1149\" onclick=\"get_ticket_and_populate_wrapper('1149'); return false;\" title=\"Change bare system() calls to runcmd() in .run files in test suite\">#1149</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nChange bare system() calls to runcmd() in .run files in test suite</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"abandoned\" href=\"/wiki-archive/tickets/?ticket=1150\" onclick=\"get_ticket_and_populate_wrapper('1150'); return false;\" title=\"Long term monitor nightly tests\">#1150</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nLong term monitor nightly tests</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1152\" onclick=\"get_ticket_and_populate_wrapper('1152'); return false;\" title='Simplify testing: \"./configure &amp;&amp; make &amp;&amp; make test\"'>#1152</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nSimplify testing: \"./configure &amp;&amp; make &amp;&amp; make test\"</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"stalled\" href=\"/wiki-archive/tickets/?ticket=1153\" onclick=\"get_ticket_and_populate_wrapper('1153'); return false;\" title=\"per-test-run subdir / allow repeated runs of batch_test.pl\">#1153</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nper-test-run subdir / allow repeated runs of batch_test.pl</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1154\" onclick=\"get_ticket_and_populate_wrapper('1154'); return false;\" title=\"Tests should know / report own description and classes\">#1154</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nTests should know / report own description and classes</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1155\" onclick=\"get_ticket_and_populate_wrapper('1155'); return false;\" title=\"Clean up testing documentation\">#1155</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nClean up testing documentation</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1978\" onclick=\"get_ticket_and_populate_wrapper('1978'); return false;\" title=\"Bad hack in condor_tests causes git annoyance\">#1978</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nBad hack in condor_tests causes git annoyance</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=1983\" onclick=\"get_ticket_and_populate_wrapper('1983'); return false;\" title=\"condor_test programs modify git tracked files\">#1983</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\ncondor_test programs modify git tracked files</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2011-Mar-30 11:31", "status": "stalled", "created": "2010-Jan-20 11:05", "fixed_version": "2010-Jan-20 11:05", "broken_version": "", "priority": "4", "subsystem": "Tests", "assigned_to": "adesmet", "derived_from": "", "creator": "adesmet", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tannenba@cs.wisc.edu, tstclair@redhat.com", "due_date": "PARENT"}