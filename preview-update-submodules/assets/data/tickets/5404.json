{"id": 5404, "title": "Ticket #5404: condor_shadow triggers kernel crash / job restart", "description": "<blockquote>\n#### MESSAGE 1 #####\n\n<p>On Nov 13, 2015, at 3:46 PM, Patrick Brady &lt;patrick@gravity.phys.uwm.edu&gt; wrote:\n\n</p><p>Hi Juan, Stuart:\n\n</p><p>we've been trying to understand a behavior in a dag that ran at Caltech and would like some help.  We have a test low-latency dag that was running at CIT in\n\n</p><p>/home/gstlalcbctest/observing/1/trigs_ts\n\n</p><p>The dag was restarted ar 11/11/15 06:27:29  and one of the jobs that we are trying to understand was submitted and began to be executed\n\n</p><p></p><pre>  11/11/15 06:32:38 Event: ULOG_SUBMIT for Condor Node gstlal_inspiral_0002 (27941471.0.0)\n  11/11/15 06:32:54 Event: ULOG_EXECUTE for Condor Node gstlal_inspiral_0002 (27941471.0.0)\n  11/11/15 06:42:54   Node gstlal_inspiral_0002, Condor ID 27941471, status STATUS_SUBMITTED\n</pre>\n\n<p>but then later\n\n</p><p></p><pre>  11/12/15 21:23:00   Node gstlal_inspiral_0002, Condor ID 27941471, status STATUS_SUBMITTED\n  11/12/15 21:48:52 Event: ULOG_EXECUTE for Condor Node gstlal_inspiral_0002 (27941471.0.0)\n  11/12/15 22:11:14   Node gstlal_inspiral_0002, Condor ID 27941471, status STATUS_SUBMITTED\n</pre>\n\n<p>So the job stopped executing for some reason and was restarted.  We tracked down that the job was originally running on node628 and restarted on a new node around 21:48. Unfortunately, I don't know which node it was restarted on because I forgot to take a note of that before the dag was stopped.\n\n</p><p>I did log into node628 and there is an indication of a vacate request going to that node on 11/12/15 around 21:46, but we're not 100% sure what that was or where it came from.\n\n</p><p>Is there an easy way to understand? More than one jobs was affected by this.  We don't have the details, but it could be extracted from the dagman.out file if needed.\n\n</p><p>Thanks for your help,\n\n</p><p>P\n\n</p><p>#### REPLY ####\n\n</p><p>Patrick,\n\tIt looks like this is due to the following kernel bug that was introduced in the kernel we are currently running but has been fixed upstream,\n<a class=\"external\" href=\"http://oss.sgi.com/archives/xfs/2015-09/msg00263.html\">http://oss.sgi.com/archives/xfs/2015-09/msg00263.html</a>\nI need to look a bit further but I suspect we will schedule a kernel patch/reboot on the cluster next Tuesday that will hopefully clean this up (along with another annoying warning we have been seeing for a while). Keep reading for more details.\n\n</p><p>From the Shadow log file it looks like there was a communication problem between the Submit machine (ldas-grid.ligo.caltech.edu) and the first execute machine this job tried to run on (node6280), and that it was then resubmitted to node605 where it ran for ~13.5 hours before it was gracefully removed. I no longer see that job in the queue on the submit machine.\n\n</p><p></p><pre>  [root@ldas-grid ~]# grep 27941471 /var/log/condor/ShadowLog\n  11/11/15 06:32:48 Initializing a VANILLA shadow for job 27941471.0\n  11/11/15 06:32:48 (27941471.0) (1902): Request to run on slot1@node628.cluster.ldas.cit &lt;10.14.3.128:57976&gt; was ACCEPTED\n  11/12/15 21:38:03 (27941471.0) (1902): attempt to connect to &lt;10.14.0.12:39278&gt; failed: Connection timed out (connect errno = 110).  Will keep trying for 300 total seconds (237 to go).\n  11/12/15 21:48:47 Initializing a VANILLA shadow for job 27941471.0\n  11/12/15 21:48:47 (27941471.0) (15594): Request to run on slot1@node605.cluster.ldas.cit &lt;10.14.3.105:42484&gt; was ACCEPTED\n  11/13/15 13:23:53 (27941471.0) (15594): Requesting graceful removal of job.\n  11/13/15 13:24:40 (27941471.0) (15594): Job 27941471.0 is being evicted from slot1@node605.cluster.ldas.cit\n  11/13/15 13:24:40 (27941471.0) (15594): **** condor_shadow (condor_SHADOW) pid 15594 EXITING WITH STATUS 102\n</pre>\n\n<p>On node628 the job starts,\n\n</p><p></p><pre>  [root@node628 condor]# grep 27941471 StartLog\n  11/11/15 06:32:48 slot1_3: Remote job ID is 27941471.0\n  [root@node628 condor]# grep 27941471 StarterLog.slot1_3\n  11/11/15 06:32:48 (pid:14436) Job 27941471.0 set to execute immediately\n  11/11/15 06:32:48 (pid:14436) Starting a VANILLA universe job with ID: 27941471.0\n  11/11/15 06:32:48 (pid:14436) Output file: /mnt/qfs6/gstlalcbctest/observing/1/trigs_ts/logs/gstlal_inspiral_0002-27941471-0.out\n  11/11/15 06:32:48 (pid:14436) Error file: /mnt/qfs6/gstlalcbctest/observing/1/trigs_ts/logs/gstlal_inspiral_0002-27941471-0.err\n</pre>\n\n<p>and in more detail from StarterLog.slot1_3 it failed to shutdown cleanly and report back to the shadow,\n\n</p><p></p><pre>  11/11/15 06:32:49 (pid:14436) Running job as user gstlalcbctest\n  11/11/15 06:32:49 (pid:14436) Create_Process succeeded, pid=14438\n  11/12/15 21:46:59 (pid:14436) Got SIGTERM. Performing graceful shutdown.\n  11/12/15 21:46:59 (pid:14436) ShutdownGraceful all jobs.\n  11/12/15 21:47:21 (pid:14436) condor_write(): Socket closed when trying to write 508 bytes to &lt;10.14.0.12:48554&gt;, fd is 16\n  11/12/15 21:47:21 (pid:14436) Buf::write(): condor_write() failed\n  11/12/15 21:48:05 (pid:14436) Process exited, pid=14438, status=1\n  11/12/15 21:48:05 (pid:14436) condor_write(): Socket closed when trying to write 564 bytes to &lt;10.14.0.12:48554&gt;, fd is 16\n  11/12/15 21:48:05 (pid:14436) Buf::write(): condor_write() failed\n  11/12/15 21:48:05 (pid:14436) condor_write(): Socket closed when trying to write 77 bytes to &lt;10.14.0.12:48554&gt;, fd is 16\n  11/12/15 21:48:05 (pid:14436) Buf::write(): condor_write() failed\n  11/12/15 21:48:05 (pid:14436) Failed to send job exit status to shadow\n  11/12/15 21:48:05 (pid:14436) JobExit() failed, waiting for job lease to expire or for a reconnect attempt\n  11/12/15 21:48:05 (pid:14436) Returning from CStarter::JobReaper()\n  11/12/15 21:52:03 (pid:14436) Got SIGQUIT.  Performing fast shutdown.\n  11/12/15 21:52:03 (pid:14436) ShutdownFast all jobs.\n  11/12/15 21:52:03 (pid:14436) condor_write(): Socket closed when trying to write 77 bytes to &lt;10.14.0.12:48554&gt;, fd is 16\n  11/12/15 21:52:03 (pid:14436) Buf::write(): condor_write() failed\n  11/12/15 21:52:03 (pid:14436) Failed to send job exit status to shadow\n  11/12/15 21:52:03 (pid:14436) **** condor_starter (condor_STARTER) pid 14436 EXITING WITH STATUS 0\n</pre>\n\n<p>Here are the reported problems by the kernel on ldas-grid associated with condor_shadow processes,\n\n</p><p></p><pre>  [root@ldas-grid ~]# grep condor_shadow /var/log/messages\n  Nov  9 22:04:21 ldas-grid kernel: Pid: 27825, comm: condor_shadow Not tainted 2.6.32-573.3.1.el6.x86_64 #1\n  Nov 10 02:37:23 ldas-grid kernel: Pid: 30046, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 10 07:46:36 ldas-grid kernel: Pid: 29100, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 10 08:04:42 ldas-grid kernel: Pid: 26765, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 10 12:06:32 ldas-grid kernel: Pid: 6989, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 10 12:06:43 ldas-grid kernel: Pid: 4864, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 10 19:07:04 ldas-grid kernel: Pid: 16304, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 02:38:34 ldas-grid kernel: Pid: 4271, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 17:50:02 ldas-grid kernel: Pid: 1813, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 17:56:30 ldas-grid kernel: Pid: 27429, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 19:03:59 ldas-grid kernel: Pid: 22028, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 21:16:51 ldas-grid kernel: Pid: 14006, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 21:35:06 ldas-grid kernel: Pid: 25351, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 21:44:44 ldas-grid kernel: Pid: 7360, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 22:27:47 ldas-grid kernel: Pid: 23125, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 01:02:21 ldas-grid kernel: Pid: 21609, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 03:27:20 ldas-grid kernel: Pid: 30062, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 03:36:24 ldas-grid kernel: Pid: 9572, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 03:50:36 ldas-grid kernel: Pid: 10130, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 04:06:06 ldas-grid kernel: Pid: 14958, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 04:10:46 ldas-grid kernel: Pid: 29160, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 04:23:10 ldas-grid kernel: Pid: 23199, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 05:51:50 ldas-grid kernel: Pid: 14969, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 09:52:55 ldas-grid kernel: Pid: 1534, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 14:01:29 ldas-grid kernel: Pid: 7163, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 14:03:45 ldas-grid kernel: Pid: 17850, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 17:54:34 ldas-grid kernel: Pid: 18142, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 18:10:53 ldas-grid kernel: Pid: 5964, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 22:05:26 ldas-grid kernel: Pid: 12643, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 12 22:08:43 ldas-grid kernel: Pid: 12683, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n</pre>\n\n<p>With more detail on one example about the time of your incident,\n\n</p><p></p><pre>  Nov 11 21:44:44 ldas-grid kernel: ------------[ cut here ]------------\n  Nov 11 21:44:44 ldas-grid kernel: WARNING: at fs/dcache.c:758 d_delete+0x260/0x2c0() (Tainted: G        W  -- ------------   )\n  Nov 11 21:44:44 ldas-grid kernel: Hardware name: SYS-6028TP-HTTR\n  Nov 11 21:44:44 ldas-grid kernel: Modules linked in: nfsd exportfs autofs4 ipmi_devintf nfs lockd fscache auth_rpcgss\n  nfs_acl sunrpc cpufreq_ondemand acpi_cpufreq freq_table mperf ipt_REJECT nf_conntrack_ipv4 nf_defrag_ipv4 iptable_filter ip_tables\n  ip6t_REJECT nf_conntrack_ipv6 nf_defrag_ipv6 xt_state nf_conntrack ip6table_filter ip6_tables ipv6 microcode iTCO_wdt\n  iTCO_vendor_support sb_edac edac_core i2c_i801 i2c_core sg lpc_ich mfd_core shpchp joydev power_meter acp\n  i_ipmi ipmi_si ipmi_msghandler ioatdma ixgbe dca ptp pps_core mdio ext4 jbd2 mbcache raid1 sd_mod crc_t10dif xhci_hcdahci\n  wmi dm_mirror dm_region_hash dm_log dm_mod [last unloaded: scsi_wait_scan]\n  Nov 11 21:44:44 ldas-grid kernel: Pid: 7360, comm: condor_shadow Tainted: G        W  -- ------------    2.6.32-573.3.1.el6.x86_64 #1\n  Nov 11 21:44:44 ldas-grid kernel: Call Trace:\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff81077491&gt;] ? warn_slowpath_common+0x91/0xe0\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff810774fa&gt;] ? warn_slowpath_null+0x1a/0x20\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff811ae660&gt;] ? d_delete+0x260/0x2c0\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff811a0908&gt;] ? vfs_rmdir+0xe8/0xf0\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff811a3b64&gt;] ? do_rmdir+0x184/0x1f0\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff81197a03&gt;] ? sys_newfstat+0x33/0x40\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff810e8ab7&gt;] ? audit_syscall_entry+0x1d7/0x200\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff811a3c26&gt;] ? sys_rmdir+0x16/0x20\n  Nov 11 21:44:44 ldas-grid kernel: [&lt;ffffffff8100b0d2&gt;] ? system_call_fastpath+0x16/0x1b\n  Nov 11 21:44:44 ldas-grid kernel: ---[ end trace 06070fe116beef00 ]---\n</pre>\n\n<p>Thanks.\n\n</p><p>--\nStuart Anderson  anderson@ligo.caltech.edu\n<a class=\"external\" href=\"http://www.ligo.caltech.edu/~anderson\">http://www.ligo.caltech.edu/~anderson</a></p></blockquote>", "remarks": "<blockquote>\n<em>2015-Nov-17 13:13:22 by tpdownes:</em> <br/>\n\n(from Stuart)\n\n<p>I am not sure the kernel messages I reported yesterday related condor_shadow failures are indeed already fixed in a newer upstream kernel release so I have just opened the following ticket with <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RedHat\" title=\"Red Hat\">RedHat</a></span>. If that does not result in a definitive answer before Tuesday PM then we will likely push one LDAS-CIT job submit machine to the latest upstream kernel (2.6.32-573.8.1.el6.x86_64), leave one at the current version (2.6.32-573.3.1.el6.x86_64) and revert one to the previous version (kernel-2.6.32-573.el6.x86_64) to get more data on this bug.\n\n</p><p>Note, these messages are happening primarily on the busiest Condor submit machines ldas-grid and ldas-pcdev1, with only 4 occurrences elsewhere, i.e.,\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\">  [root@ldas-grid ~]# for i in ldas-grid ldas-pcdev1 ldas-pcdev3 ldas-pcdev4 emfollow cbc detchar; do echo -n \"$i : \"; ssh $i \"cat /var/log/messages* | grep -c dcache\"; done\n  ldas-grid : 258\n  ldas-pcdev1 : 33\n  ldas-pcdev3 : 0\n  ldas-pcdev4 : 0\n  emfollow : 0\n  cbc : 4\n  detchar : 0\n</pre></div>\n\n\n<p>Note, there are also no dcache kernel messages (from condor_shadow or any other processes) on any of the CIT cluster nodes.\n\n</p><p>P.S. Juan, I think the simple reason that the newer RH 573.7.1 and 573.8.1 kernel updates are only in the fastbugs repository is that they are simply bug fixes and don\u2019t have any security fixes in them.\n\n</p><p>Thanks.\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\">&gt; Begin forwarded message:\n&gt;\n&gt; From: bugzilla@redhat.com\n&gt; Date: November 14, 2015 at 4:11:59 PM PST\n&gt; To: anderson@ligo.caltech.edu\n&gt; Subject: [Bug 1282117] New: WARNING: at fs/dcache.c:758 d_delete+0x260/0x2c0()\n&gt;\n&gt; https://bugzilla.redhat.com/show_bug.cgi?id=1282117\n&gt;\n&gt;            Bug ID: 1282117\n&gt;           Summary: WARNING: at fs/dcache.c:758 d_delete+0x260/0x2c0()\n&gt;           Product: Red Hat Enterprise Linux 6\n&gt;           Version: 6.1\n&gt;         Component: kernel\n&gt;     Sub Component: File Systems\n&gt;          Severity: high\n&gt;          Assignee: swhiteho@redhat.com\n&gt;          Reporter: anderson@ligo.caltech.edu\n&gt;        QA Contact: fs-qe@redhat.com\n&gt;             Group: private\n&gt;\n&gt;\n&gt;\n&gt; Description of problem:\n&gt;\n&gt; On two different quad-CPU Xeon systems running 2.6.32-573.3.1.el6.x86_64 are\n&gt; regularly throwing the following WARNING,\n&gt;\n&gt; Nov  9 22:04:21 ldas-grid kernel: ------------[ cut here ]------------\n&gt; Nov  9 22:04:21 ldas-grid kernel: WARNING: at fs/dcache.c:758\n&gt; d_delete+0x260/0x2c0() (Not tainted)\n&gt; Nov  9 22:04:21 ldas-grid kernel: Hardware name: SYS-6028TP-HTTR\n&gt; Nov  9 22:04:21 ldas-grid kernel: Modules linked in: nfsd exportfs autofs4\n&gt; ipmi_devintf nfs lockd fscache auth_rpcgss nfs_acl sunrpc cpufreq_ondemand\n&gt; acpi_cpufreq freq_table mperf ipt_REJECT nf_conntrack_ipv4 nf_defrag_ipv4\n&gt; iptable_filter ip_tables ip6t_REJECT nf_conntrack_ipv6 nf_defrag_ipv6 xt_state\n&gt; nf_conntrack ip6table_filter ip6_tables ipv6 microcode iTCO_wdt\n&gt; iTCO_vendor_support sb_edac edac_core i2c_i801 i2c_core sg lpc_ich mfd_core\n&gt; shpchp joydev power_meter acpi_ipmi ipmi_si ipmi_msghandler ioatdma ixgbe dca\n&gt; ptp pps_core mdio ext4 jbd2 mbcache raid1 sd_mod crc_t10dif xhci_hcd ahci wmi\n&gt; dm_mirror dm_region_hash dm_log dm_mod [last unloaded: scsi_wait_scan]\n&gt; Nov  9 22:04:21 ldas-grid kernel: Pid: 27825, comm: condor_shadow Not tainted\n&gt; 2.6.32-573.3.1.el6.x86_64 #1\n&gt; Nov  9 22:04:21 ldas-grid kernel: Call Trace:\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff81077491&gt;] ?\n&gt; warn_slowpath_common+0x91/0xe0\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff810774fa&gt;] ?\n&gt; warn_slowpath_null+0x1a/0x20\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff811ae660&gt;] ? d_delete+0x260/0x2c0\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff811a0908&gt;] ? vfs_rmdir+0xe8/0xf0\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff811a3b64&gt;] ? do_rmdir+0x184/0x1f0\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff81197a03&gt;] ? sys_newfstat+0x33/0x40\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff810e8ab7&gt;] ?\n&gt; audit_syscall_entry+0x1d7/0x200\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff811a3c26&gt;] ? sys_rmdir+0x16/0x20\n&gt; Nov  9 22:04:21 ldas-grid kernel: [&lt;ffffffff8100b0d2&gt;] ?\n&gt; system_call_fastpath+0x16/0x1b\n&gt; Nov  9 22:04:21 ldas-grid kernel: ---[ end trace 06070fe116beeef3 ]---\n&gt;\n&gt;\n&gt; Version-Release number of selected component (if applicable):\n&gt;\n&gt; kernel 2.6.32-573.3.1.el6.x86_64\n&gt;\n&gt; How reproducible:\n&gt;\n&gt; Happening on average a few times per day per system\n&gt;\n&gt; Steps to Reproduce:\n&gt; 1. Submit lots of HTCondor job\n&gt; 2.\n&gt; 3.\n&gt;\n&gt; Actual results:\n&gt;\n&gt; condor_shadow failure as reported by the kernel above in /var/log/messages\n&gt;\n&gt; Expected results:\n&gt;\n&gt; Avoid the above kernel message\n&gt;\n&gt; Additional info:\n&gt;\n&gt; This link appears to be a similar report of this problem being introduced\n&gt; between 2.6.32-573.el6.x86_64 and 2.6.32-573.3.1.el6.x86_64,\n&gt;\n&gt; http://oss.sgi.com/archives/xfs/2015-09/msg00264.html\n\n&gt; I don't see anything in the release notes for 2.6.32-573.7.1.el6.x86_64 or\n&gt; 2.6.32-573.8.1.el6.x86_64 that refers to dcache  indicating this has been fixed\n&gt; yet?\n&gt;\n\n</pre></div>\n\n&gt; --\n&gt; You are receiving this mail because:\n&gt; You reported the bug.\n\n<p>--\nStuart Anderson  anderson@ligo.caltech.edu\n<a class=\"external\" href=\"http://www.ligo.caltech.edu/~anderson\">http://www.ligo.caltech.edu/~anderson</a></p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "todo", "last_change": "2015-Nov-17 14:37", "status": "defer", "created": "2015-Nov-17 13:07", "fixed_version": "2015-Nov-17 13:07", "broken_version": "v080210", "priority": "5", "subsystem": "", "assigned_to": "gthain", "derived_from": "", "creator": "tpdownes", "rust": "", "customer_group": "ligo", "visibility": "public", "notify": "pcouvare@caltech.edu", "due_date": ""}