{"id": 2377, "title": "Ticket #2377: support pilot job management", "description": "<blockquote>\nOn July 29, Miron, Igor, Brian, Jaime, and I (Dan) met to begin coming up with a plan for first-class support for \"resource provisioning.\"  Concretely, what this means is managing generic pilot jobs in a distributed computing environment such as OSG.\n\n<p>Milestones:\n\n</p><p></p><ul>\n<li>[DONE] 2011-08-19, Dan - create a first draft of the plan, based on what was discussed\n</li></ul>\n\n<p><span class=\"section\"></span></p><h2>Objectives </h2>\n\n<p></p><ol>\n<li>Design a resource provisioning service to be deployed at grid sites. Existing job management services, such as the OSG CE, have been used for resource provisioning through the use of pilot jobs. This approach works but requires that the demand for resources be expressed indirectly by instantiating individual pilot jobs rather than by an explicit statement of what is desired.  Therefore ...\n\n<p></p></li><li>The service should provide an interface for clients to request the provisioning of resources.  An example of a \"provisioned resource\" is a pilot job running on a batch slot possessing a specified minimal amount of RAM and disk.  Other types of provisioned resources may also be considered.\n\n<p></p></li><li>If the pilot job terminates or the resource it was using becomes unavailable, it is the responsibility of the service, not the client, to attempt reprovisioning the resource, as long as the request remains in force.  (For convenience, it may be appropriate to have a special type of request where the termination of the pilot job automatically reduces the size of the request and is therefore not restarted.  However, this would be an added feature, not the mainstay of what we mean by resource provisioning.)\n\n<p></p></li><li>Arbitrary types of pilots should be supported (i.e. an executable supplied by the client).\n\n<p></p></li><li>The translation of pilot requests to jobs should be configurable by the site.  For example, the site admin might want to use specific queues for some types of jobs, without exposing this detail to outside users.\n\n<p></p></li><li>The service should support multiple VOs.\n\n<p></p></li><li>Clients should be able to reliably remove their previously submitted requests.\n\n<p></p></li><li>Clients should be able to conveniently modify their previously submitted requests.  For example, the number of desired resources of a specific type may increase or decrease over time.\n\n<p></p></li><li>Requests for resources should have a renewable lease.  If the lease is not renewed, the request is removed and resources are freed.\n\n<p></p></li><li>Clients should be able to monitor the status of requests. For example, the number of current and recently allocated resources could be queried.\n\n<p></p></li><li>Clients should be able to access relevant error logs for ease of debugging.\n</li></ol>\n\n<p>Question: do we <em>require</em> that the service support multi-instance requests, or is this not a core principle?  e.g. Should the service be required to support requests for N&gt;1 pilots, or is it acceptable for an implementation to only support requests for N=1.\n\n</p><p><span class=\"section\"></span></p><h2>implementation A - glideinWMS</h2>\n\n<p>The glideinWMS could be extended to meet the design goals.  The framework already provides a protocol for making requests, but the requests are not for generic pilots of type X.\n\n</p><p>The factory component could be implemented using something very close to the existing glideinWMS factory.  It would run at the target site and would submit pilots into the batch system, either directly or via a schedd that forwards jobs to the local batch system via the blahp.\n\n</p><p>The broker component would be another instance of the glideinWMS factory, but instead of submitting pilot jobs, it would send aggregate requests to the pilot factories at the sites.  The existing protocol for sending requests from the frontend to the factory could be used, but it would need to be extended to support arbitrary types of pilots.\n\n</p><p>Retrieval of pilot failure diagnostics would need to be implemented.  This is already on the wish-list for glideinWMS as it exists today.\n\n</p><p><span class=\"section\"></span></p><h2>implementation B - Condor</h2>\n\n<p>This is an exercise to think about Condor components (existing or missing) that could be used to implement the design goals.\n\n</p><p>We considered implementing the factory as a schedd plus additional appendages that implement the factory logic.  The broker could communicate with the schedd using the Condor-C protocol.\n\n</p><p><span class=\"subsection\"></span></p><h3>B.1 scheduler universe factory</h3>\n\n<p>Pilot jobs could exist in the schedd queue with the expression <span class=\"quote\">OnExitRemove=False</span>, so they keep running until removed.  These jobs are forwarded to the local site batch system via the blahp.\n\n</p><p>The broker could manipulate these pilot jobs directly, but that violates one of our design goals of having the broker only deal in aggregate requests.  Alternatively, the broker could submit scheduler universe jobs that translate aggregate requests into operations on individual pilots.  There are two models for how this could work:\n\n</p><p></p><ol>\n<li>the scheduler universe tasks submitted by the broker could be crondor tasks that periodically evaluate state and perform actions; the broker can modify the request by updating attributes of the crondor job's ad or by removing/replacing the job.  This way of doing things sounds similar to Derek's Campus Grid Factory, as pointed out in Brian's comment below.\n\n<p></p></li><li>the scheduler universe tasks are long-running jobs that have their own internal event loop.  For example, an early-stage prototype that modified dagman to keep N jobs running could be adapted to this role.\n</li></ol>\n\n<p>One problem with implementing pilots as jobs that automatically resubmit themselves with <span class=\"quote\">OnExitRemote=False</span> is how to collect failure diagnostics for run attempts that fail.  One solution would be to have failed glideins go on hold until their logs are harvested.  Another solution would be to make Condor support logging to files with names that change with each run attempt (e.g. support $$([RunCount]) in the stderr/stdout names).\n\n</p><p><span class=\"subsection\"></span></p><h3>B.2 JobRouter factory</h3>\n\n<p>This idea is based on Brian's patch, which is attached to this ticket.  The <span class=\"quote\">JobRouter</span> could be modified to do 1-to-N transformations instead of 1-to-1 job transformations.  This allows it to become a pilot factory.  The source job would serve as a pilot request.  The destination jobs would be the pilots.  Attributes of the source job specify the desired number of pilots to instantiate.  The routing table (i.e. the transformation description) would be designed to do whatever is necessary to make the jobs run on the local site (e.g. use the blahp or Condor-C or Globus).\n\n</p><p>Aggregate stats about the pilots could be fed back into attributes of the pilot request ad, which could be conveniently queried by the broker.  We would need to work out how error diagnostics could be fed back to the broker.</p></blockquote>", "remarks": "<blockquote>\n<em>2011-Aug-11 18:35:27 by bbockelm:</em> <br/>\n\nAt first blush, implementation (B) looks a lot like Derek's Campus Grid Factory (CGF).  (Of course, a lot of this is theme and variation)\n\n<p>CGF is a crondor job that runs at the remote site.  It inserts some offline ads - one per defined pilot type - into the collector.  The remote negotiator matches against the offline ad and notifies the collector.  If the CGF sees a recently matched ad, it will submit a job.\n\n</p><p>If we wanted to extend it to this use case, we would need to\n</p><ul>\n<li>Instead of looking to see if the slots have been negotiated with and submitting a few jobs at a time, we would want the broker to be able to request N running and M idle.\n<ul>\n<li>Concretely, VO A could write a <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAd\" title=\"Class Ad\">ClassAd</a></span> for a job, push it to the  collector, and then update it as its requested job load changes.  Note that this changes semantics of what is kept in the offline ad: job descriptions instead of machine descriptions.  Need to think through the consequences of that.\n</li><li>Note we've got a push-based system, and a mechanism to auto-expire requests.  Do we want push or poll?\n</li></ul>\n</li><li>Think deeper about security.  We don't necessarily need to associate a proxy with a pilot, but we need to make sure that users can't change each other's requests.  I.e., VO B can't change the number of requests in the VO A, or mess with its startup script.  It seems like the extension could be done with small changes to the collector and keep the existing authorization scheme.\n</li><li>Truthfully, the factory is very simple in this case.  If it could be DC-based, could we do something clever with condor_fetchlog to deliver logs back to the broker upon request?\n</li></ul>\n\n<p>How does this differentiate from using the gWMS factory at each site?\n</p><ul>\n<li>Authorization is done entirely within Condor.  No proxies are required for the whole scheme, but it is completely compatible with the OSG security infrastructure.\n</li><li>All the non-Condor pieces are run and managed by Condor.  The non-Condor parts are simple enough that it's plausible to replace with a Condor daemon; this way, we would tap into the existing ecosystem (auth, log fetching, configuration, etc).\nOther than that, its very, very similar.  Existing CGF uses gWMS libraries.\n</li></ul>\n\n<p>Stray, unrelated thought that might be off-the-wall: Consider submitting to a Condor site.  When you submit a gWMS pilot to Condor, you start a condor_starter within a condor_starter.  Even in the case of PanDA, you submit a starter-like-executable inside a starter.  What if the startd launched the custom starter from the pilot system?  Is it possible to launch a starter with only a claim, have it update the slot's <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAd\" title=\"Class Ad\">ClassAd</a></span> based on what it finds in the environment, <strong>then</strong> get a job?  Can a starter be launched with a claim?  Or only with a job?\n\n</p><p></p><hr/>\n<em>2011-Aug-11 18:46:21 by sfiligoi:</em> <br/>\n\nRe: What if the startd launched the custom starter from the pilot system?\n\n<p>This was discussed several times in the past and discarded as a bad idea.\nThe whole idea of a pilot is that it is independent of the site setup.\n\n</p><p>In the case of glideins, you want at least:\n</p><ul>\n<li>custom Condor version\n</li><li>custom Condor config\n</li><li>independent matchmaking of the local policies\n</li><li>validation and dynamic config creation\n</li></ul>\n\n<p></p><hr/>\n<em>2011-Aug-12 9:54:21 by danb:</em> <br/>\n\n\n<p>I changed \"coordinator\" in all of the above to \"broker\" because it's shorter.\n\n</p><p></p><hr/>\n<em>2011-Aug-12 18:09:54 by sfiligoi:</em> <br/>\n\nI am not sure that the design goal should really be:\n\"the broker only deals in aggregate requests\"\n\n<p>My impression from the discussion with Miron is that we do not want to keep submitting jobs just to maintain the same amount of glideins running.\nThat's the main goal.\n\n</p><p>And this is a major problem with the document as it is now; we are starting with describing the implementation. We don't describe what are the objectives.\n\n</p><p>I propose we try to first agree to what are the goals first; and write them down. We then need a signoff from ourselves as a group, then get a sign off by Miron. (iterating as needed)\nWe may be trying to solve the wrong problem, else.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body><blockquote>\n<ul>\n<li><a href=\"../files/434/multicast_router.patch\">multicast_router.patch</a>\n29962 bytes added by bbockelm on 2011-Aug-12 03:27:58 UTC.\n<br/>\nWhat about something along the lines of the attached patch?\n\n<p>Currently, the jobrouter knows how to do arbitrary translation of jobs, but does a one-to-one translation between source and destination.  With this patch, given a specific <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAd\" title=\"Class Ad\">ClassAd</a></span>, will do a one-to-many translation.\n\n</p><p>Internally, I introduce a new class (<span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=PilotJob\" title=\"Pilot Job\">PilotJob</a></span>) that can hold one or more <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RoutedJobs\" title=\"Routed Jobs\">RoutedJobs</a></span>.  In the event loop, the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=PilotJob\" title=\"Pilot Job\">PilotJob</a></span> creates <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RoutedJobs\" title=\"Routed Jobs\">RoutedJobs</a></span> until it has hit the target number running or the target of queued jobs.\n\n</p><p>NOTE/CAVEAT: this compiles, but doesn't likely work (it represents a plausible idea).  I have not put in any mechanisms for failure recovery if the job router is killed.  I also have not put in any counter to track how many <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RoutedJobs\" title=\"Routed Jobs\">RoutedJobs</a></span> the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=PilotJob\" title=\"Pilot Job\">PilotJob</a></span> creates.  Finally, I have not considered the impact of the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RoutedJobs\" title=\"Routed Jobs\">RoutedJobs</a></span> updating the source job directly; likely we want something different if it's a pilot.\n\n</p><p>The jobrouter can handle proxies; I haven't thought it through, but I don't see any reason why this scheme wouldn't be able to do the same.\n\n</p><p>This would use the existing callout mechanism to do arbitrary transformations of jobs.  So, if you would submit a GT2 on Condor-C job to an enabled schedd, the site admin could change the job router's transform to match the site setup (i.e., vanilla -&gt; pbs/blahp).\n\n</p><p>This is really the minimal amount of work I can think of to implement the project.\n\n</p><p>Thoughts?<br/>\n</p></li><li><a href=\"../files/435/PilotProvisioningDesignDoc.docx\">PilotProvisioningDesignDoc.docx</a>\n133889 bytes added by danb on 2011-Aug-12 18:15:36 UTC.\n<br/>\nThis document contains a summary of the design discussion as of 2011-08-12.<br/>\n</li></ul>\n</blockquote></body></html>", "check_ins": "", "type": "enhance", "last_change": "2011-Aug-18 16:39", "status": "pending", "created": "2011-Aug-11 15:31", "fixed_version": "2011-Aug-11 15:31", "broken_version": "v070000", "priority": "4", "subsystem": "", "assigned_to": "danb", "derived_from": "", "creator": "danb", "rust": "", "customer_group": "other", "visibility": "public", "notify": "isfiligoi@ucsd.edu,dan@hep.wisc.edu,jfrey@cs.wisc.edu,bbockelm@cse.unl.edu", "due_date": ""}