{"id": 1985, "title": "Ticket #1985: condor_submit -remote <fails>", "description": "<blockquote>\nIt's trying to spool non-existent output files...?\n\n<p></p><div class=\"code\">\n<pre class=\"code\">$ condor_submit -debug -remote grid0.lab.bos.redhat.com y.sub\n03/18/11 13:36:44 Locale: English_United States.1252\nSubmitting job(s).\n1 job(s) submitted to cluster 13395.\n03/18/11 13:36:57 ReliSock: put_file: Failed to open file c:\\temp\\mrg_13395.0.lo\ng, errno = 2.\n03/18/11 13:36:57 DoUpload: (Condor error code 13, subcode 2) SUBMIT at 10.11.9.\n224 failed to send file(s) to &lt;10.16.43.33:39820&gt;: error reading from c:\\temp\\mr\ng_13395.0.log: (errno 2) No such file or directory; SCHEDD failed to receive fil\ne(s) from &lt;10.11.9.224:52438&gt;\n\nDCSchedd::spoolJobFiles:7002:File transfer failed for target job 13395.0: SUBMIT\n at 10.11.9.224 failed to send file(s) to &lt;10.16.43.33:39820&gt;: error reading fro\nm c:\\temp\\mrg_13395.0.log: (errno 2) No such file or directory; SCHEDD failed to\n receive file(s) from &lt;10.11.9.224:52438&gt;\nERROR: Failed to spool job files.\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2011-Mar-18 16:02:04 by tstclair:</em> <br/>\n\nI've traced it through to file_transfer.cpp:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">if ( Ad-&gt;LookupString(ATTR_ULOG_FILE, buf) == 1 ) {\n\t\tUserLogFile = strdup(condor_basename(buf));\n\t\t\t// add to input files if sending from submit to the schedd\n\t\tif ( (simple_init) &amp;&amp; (!nullFile(buf)) ) {\n\t\t\tif ( !InputFiles-&gt;file_contains(buf) )\n\t\t\t\tInputFiles-&gt;append(buf);\n\t\t}\n\t}\n\n</pre></div>\n\n\n<p>but this makes no sense to me at all, why would you transfer in an output file?  especially one == $(Cluster).$(Process).log\n\n</p><p></p><hr/>\n<em>2011-Mar-21 15:53:36 by zmiller:</em> <br/>\n\ni believe this problem is a result of changing who writes the submit event, which happened in 7.5.4.\n\n<p>previously, condor_submit wrote the event, and so the log file existed and was able to be transferred.  as of 7.5.4, the schedd writes the event, so the log file is missing, resulting in this error.\n\n</p><p>1) this appears to be a windows-only problem.  on unix, condor_submit touches all output files (including the log file) to test for permission to write.  hence, the log file does still exist on unix.\n\n</p><p>2) on unix this exposed another bug, documented in ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1991\" onclick=\"get_ticket_and_populate_wrapper('1991'); return false;\" title=\"condor_transfer_data seems to be missing log events\">#1991</a></span>.\n\n</p><p></p><hr/>\n<em>2011-Mar-22 15:38:31 by jfrey:</em> <br/>\n\nHere's the sequence of events during a remote submit that causes the problem:\n\n<p></p><ul>\n<li>Condor_submit sends the job ad to the schedd, containing paths local to condor_submit.\n</li><li>The transaction for the submission is committed, which triggers the schedd to write the submit event to the user log.\n</li><li>Files are spooled from condor_submit to the schedd, including the user log (this is a new network connection).\n</li><li>When the spooling is complete, the schedd rewrites paths in the job ad to point at its spool directory.\n</li></ul>\n\n<p>Since the writing of the submit event occurs before the job ad is rewritten, the schedd attempts to write the submit event using the path that's local to condor_submit. If condor_submit and the schedd are on the same machine, that write and the subsequent spooling of the user log will be successful. Otherwise, both actions will fail.\n\n</p><p></p><hr/>\n<em>2011-Mar-22 16:46:09 by jfrey:</em> <br/>\n\nFor a simple fix for 7.6.0, we can either delay the writing of the submit event until after the job ad is rewritten or move up the ad rewriting to just before the submit event is written. Either way, the schedd needs to know at transaction commit time whether files will be spooled. It can figure this out by looking at the <span class=\"quote\">JobStatus</span> (5, Held) and <span class=\"quote\">HoldReasonCode</span> (16, <span class=\"quote\">SpoolingInput</span>). Also, condor_submit should not spool the user log (unless it's writing the submit event because it's talking to an old schedd).\n\n<p>Some additional work that should be considered:\n\n</p><p></p><ul>\n<li>The schedd should never attempt to run a remote job with unspooled files. Condor_release should not work on such jobs. Should there be a new job status for these jobs? Or should spooling be part of the job submission? I.e., the job doesn't appear in the queue until spooling is complete.\n</li></ul>\n\n<p></p><hr/>\n<em>2011-Mar-23 15:08:45 by jfrey:</em> <br/>\n\nOne minor problem with the proposed solution: if the user log has events from previous jobs, then those events will be lost when condor_transfer_data is run. If we want to retain those events, we would have to delay the submit event logging until after the job's input files are spooled and have condor_submit send the user log as an input file if it exists.\n\n<p></p><hr/>\n<em>2011-Mar-25 10:28:09 by jfrey:</em> <br/>\n\nNew proposed patch for 7.6.0:\n<ul>\n<li>Delay logging of submit event until after input files are spooled, if spooling input files.\n</li><li>Prevent jobs waiting for input files to be spooled from being released.\n</li><li>Suppress logging of abort event when a job waiting for input files to be spooled is removed.\n</li><li>Automatically remove jobs which spend too much time waiting for input files to be spooled.\n</li></ul>\n\n<p>This prevents loss of previous events in the user log when a remote job is submitted. It makes it more likely to have jobs in the queue which don't have any presence in the event log, but now those jobs can't be accidentally released.\n\n</p><p></p><hr/>\n<em>2011-Mar-28 09:28:40 by tstclair:</em> <br/>\n\nso for a user which exits on the schedd it works fine.  But if submitted from a user which does not exist on that schedd you get a shadow error (didn't used to)\n\n<p></p><div class=\"code\">\n<pre class=\"code\">03/28/11 09:27:09 (180.0) (31122): WriteUserLog::initialize: init_user_ids() failed!\n03/28/11 09:27:09 (180.0) (31122): ERROR \"Failed to initialize user log to /home/tstclair/work/personal-condor/spool/180/0/cluster180.proc0.subproc0/mrg_180.0.log\" at line 777 in file /home/tstclair/work/spaces/ref/git/src/condor_shadow.V6.1/baseshadow.cpp\n03/28/11 09:27:09 (180.0) (31122): WriteUserLog: not initialized @ writeEvent()\n</pre></div>\n\n\n<p></p><hr/>\n<em>2011-Mar-28 11:59:32 by tstclair:</em> <br/>\n\nI also found c:\\temp\\mrg_179.0.log in my log directory on my linux schedd.  8o/\n\n<p></p><hr/>\n<em>2011-Mar-28 18:15:45 by jfrey:</em> <br/>\n\nAfter talking with Dan and Zach, I've changed the proposed fix to the following:\n\n<p></p><ul>\n<li>Prevent jobs waiting for input files to be spooled from being released.\n</li><li>Do job ad rewriting in CommitTransaction().\n</li><li>Don't transfer userlog as input file.\n</li></ul>\n\n<p>I have a patch that does these three items, which I will attach.\n\n</p><p>Here are some additional changes that would allow sharing of user logs between multiple spooled jobs and better cleanup of jobs when spooling fails:\n\n</p><p></p><ul>\n<li>Add new file transfer mode for userlog (append with file locking)\n</li><li>For spooled jobs, rename userlog on schedd to _condor_userlog.\n</li><li>Do output remap of userlog from _condor_userlog to original path.\n</li><li>Automatically remove jobs which spend too much time waiting for input\n  files to be spooled.\n</li></ul>\n\n<p>I consider this second set of changes optional for 7.6.0.\n\n</p><p></p><hr/>\n<em>2011-Mar-28 18:48:33 by jfrey:</em> <br/>\n\nThe log file named <code>c:\\temp\\mrg_179.0.log</code> appears to be the fault of getPathToUserLog() and is_relative_to_cwd() in a new callsite I added. They assume the filename in the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=UserLog\" title=\"User Log\">UserLog</a></span> attribute in the job ad is formatted for the local architecture. With my new patch, <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=UserLog\" title=\"User Log\">UserLog</a></span> should have path information stripped before any calls to InitializeUserLog().\n\n<p>As for the shadow error, I found a comment in condor_submit() that says Owner should always be set by the schedd rather than submit. But with the current code, what user is the shadow using as the job owner in this case? Hopefully, my new patch won't break in the same way.\n\n</p><p></p><hr/>\n<em>2011-Mar-29 09:54:00 by tstclair:</em> <br/>\n\nso there doesn't appear to be any error with users that exist, but the afore mentioned error still exists with unrecognized users\n\n<p></p><hr/>\n<em>2011-Mar-30 13:14:03 by cweiss:</em> <br/>\n\nPatch looks good to me. I didn't see anything that worried me.</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2004\" onclick=\"get_ticket_and_populate_wrapper('2004'); return false;\" title=\"condor_submit -remote for unknown user\">#2004</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\ncondor_submit -remote for unknown user</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2069\" onclick=\"get_ticket_and_populate_wrapper('2069'); return false;\" title=\"spool directories are created for all submitted jobs\">#2069</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nspool directories are created for all submitted jobs</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2569\" onclick=\"get_ticket_and_populate_wrapper('2569'); return false;\" title=\"Submit event not written for spooled jobs when running as root\">#2569</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nSubmit event not written for spooled jobs when running as root</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body><blockquote>\n<ul>\n<li><a href=\"../files/299/submit_event_delay.patch\">submit_event_delay.patch</a>\n10204 bytes added by jfrey on 2011-Mar-25 15:29:25 UTC.\n<br/>\nPatch to delay logging of submit event when spooling files. Doesn't suppress abort event or automatically remove jobs that wait too long for spooling.<br/>\n</li><li><a href=\"../files/300/submit_event.patch\">submit_event.patch</a>\n23494 bytes added by jfrey on 2011-Mar-28 23:18:24 UTC.\n<br/>\nPatch to rewrite job ad for remote jobs at submission time instead of at spooling time. Submit and abort events now logged at correct file path. User log will overwrite existing file at stage-out and jobs waiting too long for spooling aren't automatically removed.<br/>\n</li></ul>\n</blockquote></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Apr-18 17:58</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/08961dc80b3616f4c282080b944037e9d058f913\">[21432]</a></span>: Don't create a spool directory for every job. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2069\" onclick=\"get_ticket_and_populate_wrapper('2069'); return false;\" title=\"spool directories are created for all submitted jobs\">#2069</a></span> Code changes for <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span> accidentally caused a spool directory to be created for all jobs that need a submit event log to be written by the schedd (either in the user log or the global event log). Here, we restore the previous behavior of only creating\u00a0[...]\n (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Apr-15 16:07</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/a6f7e9c92bf5d462c22cda4795ad8e25c4b231d2\">[21411]</a></span>: Fix <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=FileTransfer\" title=\"File Transfer\">FileTransfer</a></span> crash when no user log. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span> An earlier commit for this ticket introduced a bug that will crash <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=FileTransfer\" title=\"File Transfer\">FileTransfer</a></span> when transferring input files to an older schedd when there's no user log.  (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-31 20:04</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/cc430135a1937793168fee3fef92819e02fcfecd\">[21216]</a></span>: Fix handling of <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HoldReasonCode\" title=\"Hold Reason Code\">HoldReasonCode</a></span> for file spooling. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span> This is a fix-up of the previous commit for <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span>. The gridmanager now properly sets <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HoldReasonCode\" title=\"Hold Reason Code\">HoldReasonCode</a></span> for Condor-C jobs. The schedd can tolerate older clients that don't set <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HoldReasonCode\" title=\"Hold Reason Code\">HoldReasonCode</a></span>.  (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-30 16:45</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/1fc36303a469660ee586195e5bd252d03fbdb10d\">[25976]</a></span>: Version history for <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1931\" onclick=\"get_ticket_and_populate_wrapper('1931'); return false;\" title=\"Improve cream_gahp command batching\">#1931</a></span> <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span> <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2001\" onclick=\"get_ticket_and_populate_wrapper('2001'); return false;\" title=\"vm_gahp leaks fd on script callout\">#2001</a></span>  (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-28 18:04</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/9ca26b5983250ae0c94ed776e649c76a15a1ee08\">[21191]</a></span>: Fix schedd writing to user log for remote jobs with unspooled files. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span> For remotely submitted jobs, once spooling of input files is complete, the schedd rewrites the job ad so that file paths are relative to the spool directory. One problem with this is that any user log events written before the\u00a0[...]\n (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-28 18:04</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/320cc72ca053b648a1d415a87b453c640fef40e6\">[21190]</a></span>: Make jobs waiting for spooling harder to release. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=1985\" onclick=\"get_ticket_and_populate_wrapper('1985'); return false;\" title=\"condor_submit -remote &lt;fails&gt;\">#1985</a></span> Before input files are spooled for a remotely-submitted job, the job isn't runnable. It should not be releaseable by any means.  (By Jaime Frey )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2011-Mar-31 17:27", "status": "resolved", "created": "2011-Mar-18 13:49", "fixed_version": "2011-Mar-18 13:49", "broken_version": "v070500", "priority": "2", "subsystem": "Tools", "assigned_to": "jfrey", "derived_from": "", "creator": "tstclair", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tstclair@redhat.com, matt@cs.wisc.edu, dan@hep.wisc.edu, zmiller@cs.wisc.edu", "due_date": ""}