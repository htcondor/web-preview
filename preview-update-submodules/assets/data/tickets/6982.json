{"id": 6982, "title": "Ticket #6982: Oddities in job event logging evictions", "description": "<blockquote>\nJosh reports that evicting jobs via the Python wrapper does not (always?) result in a job log eviction event.\n\n<p>My analysis follows: <code>actOnJobs( JA_VACATE_JOBS )</code> in the schedd eventually calls <code>abort_job_myself( JA_VACATE_JOBS )</code>, which calls <code>daemonCore-&gt;Send_Signal_nonblocking()</code> with a <code>DCShadowKillMsg</code> constructed from the shadow's PID and the SIGTERM constant.  This will (eventually) calls kill() with the same pair of arguments.\n\n</p><p>When the shadow receives a SIGTERM, daemon core redirects it to <code>main_shutdown_graceful()</code>, which calls <code>gracefulShutDown()</code>.  This function has two problems:\n\n</p><p>(1) If the job lease has any time remaining, the shadow will immediately exit (without killing the starter and without writing to the job event log).  It appears that the job lease duration variable is only set while we're attempting to reconnect, so I guess the thinking here is that if the shadow is going away and it hasn't reconnected yet, it's OK to let the starter die of old age.\n(2) Otherwise, the shadow attempts to deactivate (and maybe release) the claim... without writing to the job event log.\n\n</p><p>TJ and I speculate that much of this handling was written for the case where the schedd is shutting down for an upgrade, and that we didn't want to log events (like the shadow exiting and restarting) that were implementation details, and the eviction case got lost in the wash.\n\n</p><p>TODO:\n\n</p><p>(1) Reproduce the problem with small test case.\n\n</p><p>(2) It seems like we should log an event when the user evicts a job; otherwise, the log has the job being started twice before exiting once.  Can we reliably distinguish this case from other SIGTERMs?  Should we write some sort of ambiguous job event instead of nothing?</p></blockquote>", "remarks": "<blockquote>\n<em>2019-Apr-08 17:03:33 by tlmiller:</em> <br/>\n\n<a class=\"external\" href=\"https://github.com/htcondor/htmap/blob/master/htmap/maps.py#L738\">https://github.com/htcondor/htmap/blob/master/htmap/maps.py#L738</a>\n\n<p>'htcondor.JobAction.Vacate' is defined to be JA_VACATE_JOBS, as suspected.\n\n</p><p></p><hr/>\n<em>2019-Apr-09 15:26:48 by tlmiller:</em> <br/>\n\nGregT speculates that SIGTERM is also used for condor_rm: maybed the schedd writes the event and the vacate case was overlooked or deliberately left out to avoid writing an evict event before every removed event.\n\n<p></p><hr/>\n<em>2019-Apr-11 15:43:53 by tlmiller:</em> <br/>\n\nUse cases for evicting jobs which checkpoint:\n\n<p>(a) if some of a cluster's jobs start getting booted for exceeding their memory requirement, edit the memory request of all them and vacate the others\n(b) try to match and run on a faster machine (we don't really need to support this)\n(C) if you've submitted a second batch of higher-priority jobs, evict the first batch to the second batch can actually get started (given your user priority).\n\n</p><p>The third case might benefit from condor_now.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "incident", "last_change": "2019-Apr-11 15:43", "status": "new", "created": "2019-Apr-08 16:03", "fixed_version": "2019-Apr-08 16:03", "broken_version": "", "priority": "3", "subsystem": "DaemonsSubmitNode", "assigned_to": "tlmiller", "derived_from": "", "creator": "tlmiller", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tlmiller@cs.wisc.edu, johnkn@cs.wisc.edu, karpel@wisc.edu", "due_date": ""}