{"id": 7, "title": "Ticket #7: Run HDFS services as Condor daemons", "description": "<blockquote>\nFrom Faisal Khan:\n\n<p>I have a working version of a Condor daemon for \"pseudo-daemoncore-ify\"\nthe Hadoop storage. The gist of my implementation\nis to configure Hadoop's storage based on condor_config file and spawn\nappropriate Hadoop's services as Java processes using\nmethods from Daemon Core library.  I tried to provide default values for\nmany of the parameters and there is still possibilities to\nprovide defaults for others as well. The Daemon Core  commands for start,\nstop (graceful/fast) and reconfiguration are handled based\non the hadoop's own installation shell scripts.  Additionally, the log4j\nbased logger of Hadoop is also configured to write a\nrolling log file under the CONDOR_LOCAL/log directory.\n\n</p><p>I  have placed my implementation  along with other necessary files at\n/p/condor/workspaces/faisal/condor_hadoop_v2.\n\n</p><p>Here is a small note on the contents of  above mentioned  directory:\n\n</p><p> condor_hadoop: Directory containing code for hadoop daemon (named as\nHDFS), 'Imakefile' for compilation\n                'libhdfs' folder for an example of using storage client\nwritten in C++\n                using JNI (Java native interface), provided by Hadoop.\n\n</p><p> hadoop: Directory containing hadoop binaries from version 0.17.\n\n</p><p> condor_config: Condor's usual configuration file that contains settings\nfor running HDFS.</p></blockquote>", "remarks": "<blockquote>\n<em>2009-Jan-15 11:25:56 by khahn:</em> <br/>\n\nI found a couple small things when installing the code on CHTC:\n\n<p>* In what appears to be a functioning data service daemon we receive log output indicating:\n\n</p><p>1/14 18:13:27 dup2 of m_std[0] failed: Bad file descriptor (9)\n\n</p><p>* on a node where we are only running the data service we see a file created:\nstderr_namenode\nas defined in HADOOP_NAMENODE_STDOUT\n\n</p><p>*In general, hadoop as applied here is missing any security.\nWe are going to temporarily use some deployed iptables rules to block ports:\n#50010 - this port is assigned in condor configuration for the data node\n#50070 - statically assigned in hadoop conf directly - web server with stats\n#90000 - name node runs on this port (faisal needs to confirm this)\n\n</p><p>Additionally it would be nice to be able to assign all of those ports in the condor configuration (and dictate who could connect to them.. tcp_wrappers style).  (I am also suspicious that other ports are in play..such as 50075. I haven't looked too hard at it yet.. this is what faisal gave me for ports used).\n\n</p><p></p><hr/>\n<em>2009-Jan-23 14:03:47 by gquinn:</em> <br/>\n\nI've completed a code review and sent a list of comments to Faisal.\n\n<p></p><hr/>\n<em>2009-Jan-26 14:02:27 by faisal:</em> <br/>\n\nHeard back from Greg Q. regarding code review of hadoop daemon. Currently looking at few quick fixes. Will probably talk to Greg about the remaining comments.\n\n<p></p><hr/>\n<em>2009-Feb-04 21:49:07 by faisal:</em> <br/>\n\nFinished making changes. I will try to show these changes to Greg to possibly have another look before giving it to Todd for commit.\n\n<p></p><hr/>\n<em>2009-Feb-06 11:57:19 by faisal:</em> <br/>\n\nPlaced new version at /p/condor/workspaces/faisal/condor_hadoop_v3\n\n<p></p><hr/>\n<em>2009-Feb-23 09:38:20 by gquinn:</em> <br/>\n\nI'm assigning this to me again, since I need to give it another code review.\n\n<p></p><hr/>\n<em>2009-Apr-02 17:04:21 by faisal:</em> <br/>\n\nChecked in my code and merged it with the V7_3 development branch few weeks ago. Now, Ken is trying to set it up on chtc cluster. I am checking with him periodically.\n\n<p></p><hr/>\n<em>2011-Mar-08 16:38:35 by tannenba:</em> <br/>\n\nFor v7.5.6, removing HDFS from the default condor_config.generic.local - feeling is users want to enable it explicitly instead of having it on by default upon installation of an RPM.</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=684\" onclick=\"get_ticket_and_populate_wrapper('684'); return false;\" title=\"Port condor_hdfs daemon to Windows\">#684</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nPort condor_hdfs daemon to Windows</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2013-May-14 18:37</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/1554dea225f08c5e7fd5811a5f72245b8a795692\">[46503]</a></span>: Merged <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/8bb9ea6bd35ee260fcd812bff0114b7dd560a906\">[46502]</a></span>, Merge pull request <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=7\" onclick=\"get_ticket_and_populate_wrapper('7'); return false;\" title=\"Run HDFS services as Condor daemons\">#7</a></span> from zhangzhehust/network_namespaces move lark reated python unittest out of contrib (By Brian Bockelman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-08 19:46</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/4f5ee09a90eb55900d86131f406fa336333180ea\">[20995]</a></span>: removed HDFS from default default DAEMON_LIST, see ticket <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=7\" onclick=\"get_ticket_and_populate_wrapper('7'); return false;\" title=\"Run HDFS services as Condor daemons\">#7</a></span>  (By Ozcan ILIKHAN )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-Mar-08 16:46</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/ceee03f7ede9aaa6f9be6e8b1a9a6250cc2bb4c5\">[20990]</a></span>: Removing HDFS from DAEMON_LIST in condor_config.local.generic. Feeling is users want to enable it explicitly instead of having it enabled by default upon installation of an RPM, at least for now at v7.5.6 <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=7\" onclick=\"get_ticket_and_populate_wrapper('7'); return false;\" title=\"Run HDFS services as Condor daemons\">#7</a></span>  (By Todd Tannenbaum )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2010-Jan-20 13:29</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/048746421f832cf7a53ff5ec6281926d8a22bada\">[16932]</a></span>: Hawkeye script for publishing availability of HDFS daemon on a given machine. (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=7\" onclick=\"get_ticket_and_populate_wrapper('7'); return false;\" title=\"Run HDFS services as Condor daemons\">#7</a></span>) This informaiton is useful for co-scheduling Hadoop's <span class=\"wiki\"><a href=\"wiki?p=MapReduce\" title=\"Map Reduce\">MapReduce</a></span> trackers and nodes containing data.  (By faisal )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2012-Oct-16 13:11", "status": "active", "created": "2009-Jan-13 14:48", "fixed_version": "2009-Jan-13 14:48", "broken_version": "", "priority": "2", "subsystem": "Daemons", "assigned_to": "ilikhan", "derived_from": "#4", "creator": "tannenba", "rust": "", "customer_group": "other", "visibility": "public", "notify": "gthain@cs.wisc.edu", "due_date": ""}