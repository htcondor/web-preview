diff --git a/src/condor_schedd.V6/dedicated_scheduler.cpp b/src/condor_schedd.V6/dedicated_scheduler.cpp
index d44cc54..7ad3fc1 100644
--- a/src/condor_schedd.V6/dedicated_scheduler.cpp
+++ b/src/condor_schedd.V6/dedicated_scheduler.cpp
@@ -189,6 +189,32 @@ bool satisfies(ClassAd* job, ClassAd* candidate) {
 }
 
 
+bool is_partitionable(ClassAd* slot) {
+    bool part = false;
+    if (!slot->LookupBool(ATTR_SLOT_PARTITIONABLE, part)) part = false;
+    return part;
+}
+
+bool is_dynamic(ClassAd* slot) {
+    bool dyn = false;
+    if (!slot->LookupBool(ATTR_SLOT_DYNAMIC, dyn)) dyn = false;
+    return dyn;
+}
+
+bool is_claimed(ClassAd* slot) {
+    MyString state;
+    if (!slot->LookupString(ATTR_STATE, state)) return false;
+    state.lower_case();
+    return state == "claimed";
+}
+
+bool is_idle(ClassAd* slot) {
+    MyString activ;
+    if (!slot->LookupString(ATTR_ACTIVITY, activ)) return false;
+    activ.lower_case();
+    return activ == "idle";
+}
+
 // Save for later
 #if 0
 //////////////////////////////////////////////////////////////
@@ -861,7 +887,7 @@ DedicatedScheduler::negotiate( Stream* s, char const* remote_pool )
 
 		req = makeGenericAdFromJobAd(job);
 
-		result = negotiateRequest(req, s, remote_pool,
+		result = negotiateRequest(req, job, s, remote_pool,
 								  reqs_matched, max_reqs);
 
 		delete req;
@@ -1001,7 +1027,7 @@ DedicatedScheduler::negotiate( Stream* s, char const* remote_pool )
   ClassAd.  It returns an enum that describes the results.
 */
 NegotiationResult
-DedicatedScheduler::negotiateRequest( ClassAd* req, Stream* s, 
+DedicatedScheduler::negotiateRequest( ClassAd* req, ClassAd* job, Stream* s, 
 									  char const* remote_pool, 
 									  int reqs_matched, int /*max_reqs*/ )
 {
@@ -1213,8 +1239,14 @@ DedicatedScheduler::negotiateRequest( ClassAd* req, Stream* s,
 			}
 
 				// Next, insert this match_rec into our hashtables
-			all_matches->insert( HashKey(machine_name), mrec );
-			all_matches_by_id->insert( HashKey(mrec->claimId()), mrec );
+            pending_requests[claim_id] = new ClassAd(*job);
+            if (is_partitionable(my_match_ad)) {
+                pending_matches[claim_id] = mrec;
+                pending_claims[mrec->publicClaimId()] = claim_id;
+            } else {
+                all_matches->insert( HashKey(machine_name), mrec );
+                all_matches_by_id->insert( HashKey(mrec->claimId()), mrec );
+            }
 			num_matches++;
 			
 				/* 
@@ -1958,46 +1990,56 @@ DedicatedScheduler::listDedicatedJobs( int debug_level )
 bool
 DedicatedScheduler::getDedicatedResourceInfo( void )
 {
-	StringList config_list;
-	CondorQuery	query(STARTD_AD);
-
-	char constraint[256];
-
-		// First clear out any potentially stale info in the
-		// unclaimed_resources list.
-	clearUnclaimedResources();
-
-		// Now, clear out any old list we might have for the resources
-		// themselves. 
+		// Now, clear out any old list we might have for the resources themselves. 
 	clearResources();
-	
-		// Make a new list to hold our resource classads.
 	resources = new ClassAdList;
 
-	snprintf( constraint, 256, "DedicatedScheduler == \"%s\"", name() ); 
-	query.addORConstraint( constraint );
+        // construct query to obtain our dedicated resources
+	CondorQuery	query(STARTD_AD);
+	MyString constraint;
+    constraint.sprintf("DedicatedScheduler == \"%s\"", name());
+	query.addORConstraint( constraint.Value() );
 
-		// This should fill in resources with all the classads we care
-		// about
+		// This should fill in resources with all the classads we care about
 	CollectorList *collectors = daemonCore->getCollectorList();
-	if (collectors->query (query, *resources) == Q_OK) {
-		dprintf( D_FULLDEBUG, "Found %d potential dedicated resources\n",
-				 resources->Length() );
-		return true;
+	if (collectors->query(query, *resources) != Q_OK) {
+        dprintf (D_ALWAYS, "Unable to run query %s\n",  constraint.Value());
+        return false;
 	}
 
-	dprintf (D_ALWAYS, "Unable to run query %s\n",  constraint);
-	return false;
+	dprintf(D_FULLDEBUG, "Found %d potential dedicated resources\n", resources->Length());
+
+	return true;
+}
+
+
+void duplicate_partitionable_res(ResList*& resources) {
+    // This is a slightly kludgy way to account for partitionable slots offering 
+    // multiple cpus, that avoids the need to make pervasive changes to memory 
+    // management logic for resource ads.
+    ResList* dup_res = new ResList;
+    resources->Rewind();
+    while (ClassAd* res = resources->Next()) {
+        if (!is_partitionable(res)) {
+            dup_res->Append(res);
+            continue;
+        }
+        MyString resname;
+        res->LookupString(ATTR_NAME, resname);
+        int ncpus=0;
+        res->LookupInteger(ATTR_CPUS, ncpus);
+        dprintf(D_FULLDEBUG, "Duplicate x%d partitionable res %s\n", ncpus, resname.Value());
+        for (int j = 0;  j < ncpus;  ++j) dup_res->Append(res);
+    }
+
+    delete resources;
+    resources = dup_res;
 }
 
 
 void
 DedicatedScheduler::sortResources( void )
 {
-	ClassAd* res;
-	match_rec* mrec;
-	char buf[256];
-
 	idle_resources = new ResList;
 	unclaimed_resources = new ResList;
 	limbo_resources = new ResList;
@@ -2006,14 +2048,50 @@ DedicatedScheduler::sortResources( void )
 	scheduling_groups.clearAll();
 
 	resources->Rewind();
-	while( (res = resources->Next()) ) {
+	while (ClassAd* res = resources->Next()) {
 		addToSchedulingGroup(res);
 
-			// getMrec from the dec sched -- won't have matches
-			// for non dedicated jobs
-		if( ! (mrec = getMrec(res, buf)) ) {
-				// We don't have a match_rec for this resource yet, so
-				// put it in our unclaimed_resources list
+        // new dynamic slots may also show up here, which need to have their
+        // match_rec moved from the pending table into the all_matches table
+        if (is_dynamic(res)) {
+            MyString resname;
+            match_rec* dmrec = NULL;
+            res->LookupString(ATTR_NAME, resname);
+            if (all_matches->lookup(HashKey(resname.Value()), dmrec) < 0) {
+                dprintf(D_FULLDEBUG, "New dynamic slot %s\n", resname.Value());
+                if (!(is_claimed(res) && is_idle(res))) {
+                    dprintf(D_ALWAYS, "WARNING: unexpected claim/activity state for new dynamic slot %s -- ignoring this resource\n", resname.Value());
+                    continue;
+                }
+                MyString pub_claim_id;
+                res->LookupString(ATTR_PUBLIC_CLAIM_ID, pub_claim_id);
+                std::map<std::string, std::string>::iterator f(pending_claims.find(pub_claim_id.Value()));
+                if (f != pending_claims.end()) {
+                    char const* claim_id = f->second.c_str();
+                    std::map<std::string, match_rec*>::iterator c(pending_matches.find(claim_id));
+                    if (c != pending_matches.end()) {
+                        dmrec = c->second;
+                        all_matches->insert(HashKey(resname.Value()), dmrec);
+                        all_matches_by_id->insert(HashKey(claim_id), dmrec);
+                        dmrec->setStatus(M_CLAIMED);
+                        pending_matches.erase(c);
+                    } else {
+                        dprintf(D_ALWAYS, "WARNING: match rec not found for new dynamic slot %s -- ignoring this resource\n", resname.Value());
+                        continue;
+                    }
+                    pending_claims.erase(f);
+                } else {
+                    dprintf(D_ALWAYS, "WARNING: claim id not found for new dynamic slot %s -- ignoring this resource\n", resname.Value());
+                    continue;
+                }
+            }
+        }
+
+        // getMrec from the dec sched -- won't have matches for non dedicated jobs
+        match_rec* mrec = NULL;
+        if( ! (mrec = getMrec(res, NULL)) ) {
+			// We don't have a match_rec for this resource yet, so
+			// put it in our unclaimed_resources list
 			unclaimed_resources->Append( res );
 			continue;
 		}
@@ -2052,6 +2130,9 @@ DedicatedScheduler::sortResources( void )
 		}
 		EXCEPT("DedicatedScheduler got unknown status for match %d\n", mrec->status);
 	}
+
+    duplicate_partitionable_res(unclaimed_resources);
+
 	if( DebugFlags & D_FULLDEBUG ) {
 		dprintf(D_FULLDEBUG, "idle resource list\n");
 		idle_resources->display( D_FULLDEBUG );
@@ -2975,7 +3056,6 @@ DedicatedScheduler::createAllocations( CAList *idle_candidates,
 									   bool is_reconnect)
 {
 	AllocationNode *alloc;
-	MRecArray* matches;
 
 		// Debugging hack: allow config file to specify which
 		// ip address we want the master to run on.
@@ -2998,10 +3078,6 @@ DedicatedScheduler::createAllocations( CAList *idle_candidates,
 		// Walk through idle_candidates, the list should
 		// be sorted by proc.  Put each job into
 		// the correct jobs and match ExtArry in our AllocationNode
-
-	ClassAd *machine = NULL;
-	ClassAd *job     = NULL;
-
 	idle_candidates->Rewind();
 	idle_candidates_jobs->Rewind();
 
@@ -3010,12 +3086,13 @@ DedicatedScheduler::createAllocations( CAList *idle_candidates,
 	int node = 0;
 
 		// Foreach machine we've matched
-	while( (machine = idle_candidates->Next()) ) {
+    MRecArray* matches = NULL;
+	while( ClassAd* machine = idle_candidates->Next() ) {
 		match_rec *mrec;
-		char buf[256];
+		char buf[512];
 
 			// Get the job for this machine
-		job = idle_candidates_jobs->Next();
+		ClassAd* job = idle_candidates_jobs->Next();
 
 		    // And the proc for the job
 		int proc;
@@ -3644,16 +3721,6 @@ DedicatedScheduler::printSatisfaction( int cluster, CAList* idle,
 }
 
 
-void
-DedicatedScheduler::clearUnclaimedResources( void )
-{
-	if( unclaimed_resources ) {
-		delete unclaimed_resources;
-		unclaimed_resources = NULL;
-	}
-}
-
-
 bool
 DedicatedScheduler::setScheduler( ClassAd* job_ad )
 {
@@ -3794,8 +3861,7 @@ DedicatedScheduler::getMrec( ClassAd* ad, char* buf )
 	match_name[0] = '\0';
 
 	if( ! ad->LookupString(ATTR_NAME, match_name) ) {
-		dprintf( D_ALWAYS, "ERROR in DedicatedScheduler::getMrec(): "
-				 "No %s in ClassAd!\n", ATTR_NAME );
+		dprintf( D_ALWAYS, "ERROR in DedicatedScheduler::getMrec(): No %s in ClassAd!\n", ATTR_NAME );
 		return NULL;
 	}
 	HashKey key(match_name);
@@ -4234,11 +4300,19 @@ DedicatedScheduler::FindMRecByJobID(PROC_ID job_id) {
 	
 }
 
-match_rec *
+match_rec*
 DedicatedScheduler::FindMrecByClaimID(char const *claim_id) {
-	match_rec *rec = NULL;
-	all_matches_by_id->lookup(claim_id, rec);
-	return rec;
+	match_rec* rec = NULL;
+
+    // look in the traditional place first
+	if (all_matches_by_id->lookup(claim_id, rec) >= 0) return rec;
+
+    // otherwise, may be from a pending dynamic slot request, so check here:
+    std::map<std::string, match_rec*>::iterator f(pending_matches.find(claim_id));
+    if (f == pending_matches.end()) return NULL;
+    rec = f->second;
+
+    return rec;
 }
 
 
@@ -4416,7 +4490,7 @@ clusterSortByPrioAndDate( const void *ptr1, const void* ptr2 )
 
 
 void
-displayResource( ClassAd* ad, char* str, int debug_level )
+displayResource( ClassAd* ad, const char* str, int debug_level )
 {
 	char arch[128], opsys[128], name[128];
 	ad->LookupString( ATTR_NAME, name );
@@ -4473,18 +4547,26 @@ RankSorter(const void *ptr1, const void *ptr2) {
 
 ClassAd *
 DedicatedScheduler::GetMatchRequestAd( match_rec* qmrec ) {
-	ClassAd* ad = new ClassAd(dummy_job);
+    if (NULL == qmrec) {
+        dprintf(D_ALWAYS, "DedicatedScheduler::GetMatchRequestAd -- qmrec was NULL\n");
+        return NULL;
+    }
 
-    if ((NULL == qmrec) || (NULL == qmrec->my_match_ad)) {
-        dprintf(D_ALWAYS, "qmrec or match ad was NULL\n");
-        return ad;
+    std::map<std::string, ClassAd*>::iterator f(pending_requests.find(qmrec->claimId()));
+    if (f == pending_requests.end()) {
+        dprintf(D_ALWAYS, "DedicatedScheduler::GetMatchRequestAd -- failed to find job assigned to claim\n");
+        return NULL;
     }
 
-    // startd looks for and advertises attribute ATTR_CONCURRENCY_LIMITS, so set that:
-    MyString limits;
-    qmrec->my_match_ad->LookupString(ATTR_MATCHED_CONCURRENCY_LIMITS, limits);
-    if (limits != "") ad->Assign(ATTR_CONCURRENCY_LIMITS, limits);
+    ClassAd* job = f->second;
+
+    pending_requests.erase(f);
+
+    if (NULL == job) {
+        dprintf(D_ALWAYS, "DedicatedScheduler::GetMatchRequestAd -- job assigned to claim was NULL\n"); 
+        return NULL;
+    }
 
-    return ad;
+    return job;
 }
 
diff --git a/src/condor_schedd.V6/dedicated_scheduler.h b/src/condor_schedd.V6/dedicated_scheduler.h
index ca95cb3..307b456 100644
--- a/src/condor_schedd.V6/dedicated_scheduler.h
+++ b/src/condor_schedd.V6/dedicated_scheduler.h
@@ -17,6 +17,8 @@
  *
  ***************************************************************/
 
+#include <string>
+#include <map>
 
 #include "condor_classad.h"
 #include "list.h"
@@ -288,7 +290,7 @@ class DedicatedScheduler : public Service {
 		@param max_reqs Total number of requests we're trying to meet. 
 		@return An enum describing the results.
 	*/
-	NegotiationResult negotiateRequest( ClassAd* req, Stream* s, 
+	NegotiationResult negotiateRequest( ClassAd* req, ClassAd* job, Stream* s, 
 										char const *remote_pool, 
 										int reqs_matched, 
 										int max_reqs ); 
@@ -348,8 +350,6 @@ class DedicatedScheduler : public Service {
 		*/
 	void removeAllocation( shadow_rec* srec );
 
-	void clearUnclaimedResources( void );
-
 	void callHandleDedicatedJobs( void );
 
 		/** Do a number of sanity-checks, like releasing resources
@@ -451,6 +451,16 @@ class DedicatedScheduler : public Service {
 		// Queue for resource requests we need to negotiate for. 
 	Queue<PROC_ID>* resource_requests;
 
+        // stores job classads, indexed by each job's pending claim-id
+    std::map<std::string, ClassAd*> pending_requests;
+
+        // stores match recs from partitionable slots, indexed by claim id
+    std::map<std::string, match_rec*> pending_matches;
+
+        // stores pending claim ids against partitionable slots, indexed
+        // by corresponding public claim id
+    std::map<std::string, std::string> pending_claims;
+
 	int		num_matches;	// Total number of matches in all_matches 
 
     static const int MPIShadowSockTimeout;
@@ -490,7 +500,7 @@ int
 RankSorter( const void *ptr1, const void* ptr2 );
 
 // Print out
-void displayResource( ClassAd* ad, char* str, int debug_level );
+void displayResource( ClassAd* ad, const char* str, int debug_level );
 void displayRequest( ClassAd* ad, char* str, int debug_level );
 
 // Clear out all the fields in the match record that have anything to
diff --git a/src/condor_startd.V6/Resource.cpp b/src/condor_startd.V6/Resource.cpp
index 39d0fce..1e74379 100644
--- a/src/condor_startd.V6/Resource.cpp
+++ b/src/condor_startd.V6/Resource.cpp
@@ -1751,6 +1751,7 @@ Resource::publish( ClassAd* cap, amask_t mask )
 		// Update info from the current Claim object, if it exists.
 	if( r_cur ) {
 		r_cur->publish( cap, mask );
+        if (state() == claimed_state)  cap->Assign(ATTR_PUBLIC_CLAIM_ID, r_cur->publicClaimId());
 	}
 	if( r_pre ) {
 		r_pre->publishPreemptingClaim( cap, mask );
