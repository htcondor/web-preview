{"id": 5270, "title": "Ticket #5270: jobs on hold after upgrading condor on htcondor-ce", "description": "<blockquote>\nDan at US CMS T2 reported via RUST:\n\n<p>The UW CMS T2 upgraded its condor from 8.2.7 to 8.2.9 yesterday. After\nthat, many jobs have gone on hold on one of our three HTCondor-CEs.  I\nbelieve all these jobs were running at the time of the upgrade.  The\nproblem shows up as a permission problem in the job's spool directory.\n\n</p><p>The files are owned by condor rather than the owner of the job, so the\nshadow fails to write to the spool when the job finishes.\n\n</p><p>I have a hypothesis about what went wrong.  There are two schedds on an\nHTCondor-CE: the batch system schedd and the CE schedd.  The jobs in the\nCE schedd are copied into the batch system schedd by <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=JobRouter\" title=\"Job Router\">JobRouter</a></span>.  The\n<span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=JobRouter\" title=\"Job Router\">JobRouter</a></span> is being used in the mode where the two jobs share the same\nspool.  We have three HTCondor-CEs.  The one that had this problem\nhappens to have had the upgraded batch system schedd restart before the\nCE schedd restarted.  The other two HTCondor-CEs that did not have the\nproblem both had the batch system schedd restart after the CE schedd.\n\n</p><p>My hypothesis is that the batch system schedd restarts and creates a\nshadow to reconnect to the job.  Then the CE schedd restarts and chowns\nthe job's spool to condor ownership.  Then when the shadow tries to\nwrite to the spool on behalf of the user, it fails.\n\n</p><p>See attached RUST for additional info including logs.</p></blockquote>", "remarks": "<blockquote>\n<em>2015-Sep-22 14:42:54 by bbockelm:</em> <br/>\n\nAh, nifty find!  I think OSG has been hit this by a few times at other sites but haven't been able to figure out the underlying problem.  The way Dan reports it makes it sound quite easy to reproduce.\n\n<p>Has Jaime's patch for not chown'ing user directories landed yet?  Is that something we could test out here?\n\n</p><p></p><hr/>\n<em>2015-Sep-22 16:05:36 by jfrey:</em> <br/>\n\nNot chowning user spool directories (<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=5226\" onclick=\"get_ticket_and_populate_wrapper('5226'); return false;\" title=\"Eliminate chowning of job spool directories\">#5226</a></span>) is in 8.5.0, so we still need a fix for 8.2/8.4.\n\n<p></p><hr/>\n<em>2015-Sep-22 16:08:35 by bbockelm:</em> <br/>\n\nIs the <em>only</em> potential case where this fires the HTCondor-CE?\n\n<p>If so, one approach is backporting the patch and hiding it behind a config var along the line of IS_CONDOR_CE=true.\n\n</p><p></p><hr/>\n<em>2015-Oct-06 10:41:17 by jfrey:</em> <br/>\n\nI've identified the source of this problem. It's a combination of behaviors in the schedd and the job router. The non-CE schedd is writing bogus entries in its job queue log, and the job router is choking on them, causing it to not see the full log and falsely believe jobs have disappeared.\n\n<p>With the newer negotiation protocols that allow a resource request to result in multiple matches returned by the negotiator, the schedd can end up with more matches than it can use. Particularly, the schedd asks for more matches than it ends up being able to use. We saw some of the effects in <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=4554\" onclick=\"get_ticket_and_populate_wrapper('4554'); return false;\" title=\"Exceeds MAX_JOBS_RUNNING\">#4554</a></span>. One effect is that the schedd starts using a job id of -1.-1 as the target job for the extra matches. If the negotiator sends a REJECTED message, then the schedd will happily set attributes <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRejMatchTime\" title=\"Last Rej Match Time\">LastRejMatchTime</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=LastRejMatchReason\" title=\"Last Rej Match Reason\">LastRejMatchReason</a></span> for job -1.-1. This results in entries in the job queue log, even though this is an invalid job id.\n\n</p><p>On restart, the schedd will skip over these nonsense log entries. But the job router chokes on these entries. On startup, it will stop reading the log at this point. So it does not see any activity after this point, like job submissions it performed. Thus, on restart, the job router may conclude that jobs it had previously routed have been orphaned (due to the destination job appearing to be missing), so it yields the source jobs back to the CE schedd. This includes chowning the spool files back to the condor user.\n\n</p><p>If the destination job was already running, then the non-CE schedd/shadow will experience permissions problems. Also, the job router may later claim the job again and submit a new destination job. Then, there can be two jobs running that are using the same sandbox of files.\n\n</p><p>The fix will consist of two changes:\n</p><ul>\n<li>Add a guard to prevent the schedd from writing these specific nonsense job queue entries.\n</li><li>Change the job router to ignore nonsense log entries and continue reading the log.\n</li></ul>\n\n<p>We should also consider adding guards in the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAd\" title=\"Class Ad\">ClassAd</a></span> log code to prevent all bad entries, but that's outside the scope of this bug fix.\n\n</p><p></p><hr/>\n<em>2015-Oct-07 10:50:08 by tannenba:</em> <br/>\n\nThinking about the providence of this bug has raises a few questions -\n\n<p></p><ol>\n<li>What should the router\ndo if the incoming schedd says the job was routed,\nand the source schedd says it does not exist?\nCurrently it gets cleaned up and starts over from\nscratch (re-run). But if the job is a pilot job,\nwould it be better to simply throw it away?\n\n<p></p></li><li>A key observation is the root of the problem is that the schedd and job router ended up with a different view of the system state because the router treated an anomaly in the log as a terminal error and the schedd just ignored it. This begs the implementation question - Do the sched and the job router share the same code\nto read the job_queue.log on recovery??  They should...\n\n<p></p></li><li>How does the router know when the job got routed?\n\n<p></p></li><li>What happens when the job_queue.log rotates in\ndestination B? To get around this, does the router submit to  destination\nschedd with leave_in_queue or?\n</li></ol>\n\n<p></p><hr/>\n<em>2015-Oct-07 11:29:06 by danb:</em> <br/>\n\nRe question 2: The router uses the quill code for reading and following the job queue log.  If I recall correctly, that code is an independent implementation; it does not share code with the schedd's log reader.\n\n<p>Re question 3: The router knows a job got routed when the job's \"<span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=RoutedBy\" title=\"Routed By\">RoutedBy</a></span>\" attribute is equal to the name of the job router daemon.\n\n</p><p>Re question 4: leave_in_queue is used in the routed copy of the job.  In the original copy of the job the router uses the \"Managed\" attribute, similarly to how the gridmanager uses it.\n\n</p><p></p><hr/>\n<em>2015-Oct-21 14:52:01 by tannenba:</em> <br/>\n\n<strong>CODE REVIEW</strong>\n\n<p>Patch looks good, thanks, resolving this ticket and associated RUST ticket.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2015-Oct-06 11:40</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/2f05bfdfe31bd986903912731aa42b29af83db75\">[45947]</a></span>: Docs for job router reading bogus job queue log entries bug fix. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=5270\" onclick=\"get_ticket_and_populate_wrapper('5270'); return false;\" title=\"jobs on hold after upgrading condor on htcondor-ce\">#5270</a></span>  (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2015-Oct-06 11:33</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/b934737db493a17464d82ee0f2f6fdcb44660f24\">[45945]</a></span>: The schedd shouldn't set match diagnostic attributes for bogus job id. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=5270\" onclick=\"get_ticket_and_populate_wrapper('5270'); return false;\" title=\"jobs on hold after upgrading condor on htcondor-ce\">#5270</a></span> If the schedd asks for matches for jobs that subsequently can't use them (e.g. MAX_JOBS_RUNNING would be exceeded), the negotiation code will use a job id of -1.-1 as the candidate job for the extra matches. If the negotiator\u00a0[...]\n (By Jaime Frey )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2015-Oct-06 11:33</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/1d4846e77bc169d0ba817b6af2d39de74ccd8c53\">[45944]</a></span>: The job router should ignore bad job queue log entries. <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=5270\" onclick=\"get_ticket_and_populate_wrapper('5270'); return false;\" title=\"jobs on hold after upgrading condor on htcondor-ce\">#5270</a></span> The schedd can write bogus job queue log entries, which it ignores on restart. The job router should likewise ignore them (though it will still complain in its daemon log). Before, it would stop reading the job queue log. This resulted in\u00a0[...]\n (By Jaime Frey )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2015-Oct-21 14:52", "status": "resolved", "created": "2015-Sep-22 13:58", "fixed_version": "2015-Sep-22 13:58", "broken_version": "v080209", "priority": "1", "subsystem": "DaemonsSubmitNode", "assigned_to": "tannenba", "derived_from": "#4555", "creator": "tannenba", "rust": "a28779", "customer_group": "osg", "visibility": "public", "notify": "bbockelm@cse.unl.edu, tannenba@cs.wisc.edu jfrey@cs.wisc.edu blin@cs.wisc.edu dan@hep.wisc.edu tapas@hep.wisc.edu", "due_date": ""}