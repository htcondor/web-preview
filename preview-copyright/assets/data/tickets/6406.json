{"id": 6406, "title": "Ticket #6406: Vanilla-universe multicommand jobs", "description": "<blockquote>\nTicket <span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=2746\" onclick=\"get_ticket_and_populate_wrapper('2746'); return false;\" title=\"Remote, no-DAGMan POST scripts (and maybe PRE)\">#2746</a></span> details much of the desired user interface to this feature, with the exception that the exit code/exit signal should be specifiable as in ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=6367\" onclick=\"get_ticket_and_populate_wrapper('6367'); return false;\" title=\"+PreCmd exit code ignored\">#6367</a></span>, and that <code>success_exit_code</code> for the \"main\" job should be joined by <code>success_exit_signal</code> and <code>success_exit_by_signal</code>.\n\n<p>Ticket <span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=6372\" onclick=\"get_ticket_and_populate_wrapper('6372'); return false;\" title='\"first-class\" names for \"+pre\" or \"+post\" and company'>#6372</a></span> alludes to the question of naming the submit file commands for this feature, particularly with respect to usability.  The current plan is to restrict the interface to this feature to pre-, main-, and post-, since explaining parallel arrays is a pain.\n(This suggests an obvious way around the problem for the Python bindings, where we write a utility function that converts a list of command objects into a job <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAd\" title=\"Class Ad\">ClassAd</a></span>.)\n\n</p><p>Ticket <span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=5419\" onclick=\"get_ticket_and_populate_wrapper('5419'); return false;\" title=\"PreCmd / PostCmd should behave more like condor_dagman\">#5419</a></span> is a duplicate from LIGO.  It makes explicit the requirement that the extra command's executables need to be transferred automatically, with the same semantics as the 'main' executable.\n\n</p><p></p><hr/>\nThe idea of this ticket is that we currently have an n = 1 case for executables started by the vanilla universe.  User requests have wanted to make this n = 3, but the domain of n in software design is {0, 1, many}.  The hoped-for advantage is two-fold:\n\n<p></p><ul>\n<li>Move \"shish kebab\" (linear) DAG (subgraph)s out of DAGMan and (almost entirely) into the starter.\n</li><li>Allow for automatic/programmatic job re/de-composition.  This will be necessary to automatically convert from a linear DAG subgraph to a single job.\n</li></ul>\n\n<p>The basic observation is that, since we have vanilla-universe checkpointing, we know that we can stop, do intermediate file transfer, and restart an executable entirely within the starter and not have anything too terrible happen.  It seems like a conceptually straight-forward extension to change to stop, do final and first file-transfer, and start another executable.  (Accounting is currently kind of terrible with vanilla-universe checkpointing, and will get harder with this idea.  At the very least, since we can't autocompose jobs from different owners anyway -- who knows how file access would work -- we have a sane place to start.)\n\n</p><p>Since we'd be transferring files (or not -- there's some obvious opportunities for optimizations here) between different executables, we'd have (coarse-grained) checkpoints for free; this could even allow the schedd to run multi-command jobs on older starters, if we wanted that to happen.  (Write the 'current' executable in as the old-style single executable; if the job comes back without any new-style completion attributes, synthesize them and move the next executable in the list to the old-style.)\n\n</p><p>I suppose a strictly \"script\" approach could be simplified by doing file transfer only once, and indeed this may be the expected behavior -- that the prescript will be run once for each job start.  (Would that make application-level checkpointing harder or easier?)  This implies the need to be able to specify if a command is check-pointed...\n\n</p><p>but that isn't enough, because everybody will want the pre and post scripts to run after and before file transfer in and out.  It would be possible (with new code) to transform the job such that the main command's i/o happens as the pre-script's input and the post-script's output -- which would simultaneously indicate that the pre- and post- scripts aren't checkpointable, since there's no filetransfer in between -- but then the question of what to do about vanilla universe checkpointing for the main command arises... the answer may be to ignore the problem, since the only thing your pre-script could do would be input validation (everything else is rolled into the checkpoint), and you'd need to modify your program or script to do that for checkpoints anyway.\n\n</p><p>On the other hand, because of file transfer / checkpointing, maybe it would make more sense to have pre- and post- commands be their own first-class things, which would be a little disappointing.\n\n</p><p></p><hr/>\nA first pass might then implement the <span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=2746\" onclick=\"get_ticket_and_populate_wrapper('2746'); return false;\" title=\"Remote, no-DAGMan POST scripts (and maybe PRE)\">#2746</a></span> interface (with the addition of the success_* commands as noted above) without backwards compatibility and without file transfer / checkpointing.  The key task here would be to transform the friendly submit-file UI to a job-ad syntax that is designed to support all the features we want (even if it the implementation doesn't initially, it'd be nice for the implementation to recognize that and fail).  As implied above, we can specify the Python UI in much the same way as necessary (that is, without any particular reference to the job ad attributes).  If these commands ran in a fully spun-up vanilla universe environment, this first pass would meet real-world needs and have a lot of users.\n\n<p></p><hr/>\nAfter a discussion with GregT and TJ, it appears that fine-grained control over whose file transfer in or out runs when has no use-cases aside from implementing pre- and post- scripts.  However, there is a use case for multiple pre- and post- commands, including cases where an administrator wants to run a pre- or post- command without displacing the user's pre- and post- commands.  Additionally, having multiple pre- and post- commands simplifies certain types of job construction or modification (because you can just provide an additional pre- or post- command, rather than incorporating it into an existing one or adding a(nother) wrapper).</blockquote>", "remarks": "<blockquote>\n<em>2017-Sep-25 13:26:54 by tlmiller:</em> <br/>\n\nI began a design doc: <a class=\"external\" href=\"https://docs.google.com/document/d/1bHyT0ilSd3ie7hJYwvAefy8ISxt0PJZ6kZe6tO-RSWQ\">https://docs.google.com/document/d/1bHyT0ilSd3ie7hJYwvAefy8ISxt0PJZ6kZe6tO-RSWQ</a></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2017-Sep-25 13:26", "status": "new", "created": "2017-Sep-15 11:06", "fixed_version": "2017-Sep-15 11:06", "broken_version": "", "priority": "4", "subsystem": "DaemonsExecNode", "assigned_to": "", "derived_from": "", "creator": "tlmiller", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tlmiller@cs.wisc.edu", "due_date": ""}