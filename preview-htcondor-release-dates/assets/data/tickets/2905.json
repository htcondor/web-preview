{"id": 2905, "title": "Ticket #2905: RFE: adding local resource limits to partionable slots", "description": "<blockquote>\nAdd local resource limits to partionable slots.\n\n<p>A config example of that for a 2-GPU system might look like:\n\n</p><p></p><div class=\"verbatim\">\n<pre># including a custom \"gpu\" limit that can also be partitioned:\nSLOT_TYPE_1 = cpus=100%,disk=100%,swap=100%,gpu=2\nSLOT_TYPE_1_PARTITIONABLE = TRUE\nNUM_SLOTS = 1\nNUM_SLOTS_TYPE_1 = 1\n</pre></div>\n\n\n<p>Where in a job aside from:\n</p><div class=\"verbatim\">\n<pre>request_mem = &lt;int&gt;\nrequest_cpu = &lt;int&gt;\nrequest_disk = &lt;int&gt;\n</pre></div>\n\n\n<p>we could then also use:\n\n</p><p></p><div class=\"verbatim\">\n<pre>request_gpu = 1\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2012-Mar-26 15:21:03 by adesmet:</em> <br/>\n\nIf understand correctly, I add anything, without a care for Condor?  Thus, I could equally say:\n\n<p>SLOT_TYPE_1 = cpus=100%,disk=100%,swap=100%,coffee_machines=2,booster_rockets=1\n\n</p><p>and now coffee_machines and booster_rockets become things I can request_*?\n\n</p><p>Sounds good to me.\n\n</p><p>I do suspect that to be useful, we'll need to have some sort of plugin/hook to handle assignment, setup, and cleanup.  To take the original GPU example, if I have multiple GPUs, I need to pass in to the actual job some sort of information so that job tries to use the correct GPU.  For my coffee_machine, I might need to ensure that the cleaning cycle runs when a job using it finishes or is evicted.\n\n</p><p></p><hr/>\n<em>2012-Mar-26 15:34:56 by eje:</em> <br/>\n\nYes, it would be entirely arbitrary.   My concept for this was as a purely accounting enhancement (no hooks), however Tim also has a recommendation for hook support.\n\n<p></p><hr/>\n<em>2012-Mar-26 15:40:27 by tstclair:</em> <br/>\n\nOn the submit side I kind of see it like the following:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">#########################################\nrequest_keywords = gpus, booster_rockets\nrequest_gpus = 2\nrequest_booster_rockets = 99\n#########################################\n</pre></div>\n\n\n<p>On the startd side I kind of envisioned this as:\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\">\nRESOURCE_KEYWORDS=gpus,booster_rockets\ngpus_SCRIPT=/some/sciprt/which/yields/a/classad/output\nbooster_rockets_SCRIPT = /some/sciprt/which/yields/a/classad/output\n\n##############################################\n# e.g. - output might look like\n# gpus = 3\n# booster_rockets = 1200\n###############################################\n\nSLOT_TYPE_1 = cpus=100%,disk=100%,swap=100%,gpus=100%,booster_rockets=100%\n\n</pre></div>\n\n\n<p></p><hr/>\n<em>2012-Mar-26 15:45:33 by matt:</em> <br/>\n\nFYI, request_keywords is not necessary, follow the ec2_tag example.\n\n<p></p><hr/>\n<em>2012-Mar-26 17:33:29 by eje:</em> <br/>\n\nThis is also not strictly necessary:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">RESOURCE_KEYWORDS = gpus,booster_rockets</pre></div>\n\n\n<p>Although not having it would require union-ing over SLOT_TYPE_X lists.\n\n</p><p></p><hr/>\n<em>2012-Mar-26 19:56:17 by tstclair:</em> <br/>\n\nThe main purpose of:\n\n<p></p><div class=\"code\">\n<pre class=\"code\">RESOURCE_KEYWORDS = gpus,booster_rockets</pre></div>\n\n\n<p>is to allow a breakout of per resource parameters, like _SCRIPT.  I'm not really certain at this point what the namespace could entail, but I'm pretty sure some type of \"discovery\" will be one of them.  E.g. how many gpus and booster_rockets does this swanky machine have ;-).\n\n</p><p></p><hr/>\n<em>2012-Mar-26 19:58:05 by tstclair:</em> <br/>\n\nThe ref to ec2_tag can be found here: <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2742\" onclick=\"get_ticket_and_populate_wrapper('2742'); return false;\" title=\"Add support for EC2 Instance Resource Tagging\">#2742</a></span>\n\n<p></p><hr/>\n<em>2012-Apr-04 22:55:57 by eje:</em> <br/>\n\nTEST:\n\n<p>Using the following configuration:\n</p><div class=\"code\">\n<pre class=\"code\">NEGOTIATOR_DEBUG = D_FULLDEBUG\nNEGOTIATOR_USE_SLOT_WEIGHTS = FALSE\nNEGOTIATOR_INTERVAL = 30\nSCHEDD_INTERVAL\t= 15\n\n# turn off preemption, set claim worklife to zero\nCLAIM_WORKLIFE=0\nMAXJOBRETIREMENTTIME = 3600\nPREEMPT = False\nRANK = 0\nPREEMPTION_REQUIREMENTS = False\nNEGOTIATOR_CONSIDER_PREEMPTION = False\n\nNEGOTIATOR_MATCHLIST_CACHING = False\n\nNUM_CPUS = 8\n\n# declare the local resource names\n# comment this out to test auto-construction of name list\nMACHINE_RESOURCE_NAMES = gpu, railgun\n\n# declare a local resource quantity directly in config\nMACHINE_RESOURCE_gpu = 16\n\n# specify a script/app to run that returns local resource inventory with\n# other optional attributes to be advertised in slot ads\nMACHINE_RESOURCE_INVENTORY_railgun = /home/eje/condor/scripts/railgun_inventory.sh 8 0.95c\n\n# test standard slot behavior: evenly divide any leftovers\nSLOT_TYPE_1 = auto\nSLOT_TYPE_1_PARTITIONABLE = FALSE\nNUM_SLOTS_TYPE_1 = 2\n\n# test partitionable slot with a single machine resource fraction\n# (25% of all resources)\nSLOT_TYPE_2 = 25%\nSLOT_TYPE_2_PARTITIONABLE = TRUE\nNUM_SLOTS_TYPE_2 = 1\n\n# test resource specific slot types (nonpartitionable)\nSLOT_TYPE_3 = cpu=2,gpu=25%,railgun=2,25%\nSLOT_TYPE_3_PARTITIONABLE = FALSE\nNUM_SLOTS_TYPE_3 = 1\n\n# test resource specific slot types (partitionable)\nSLOT_TYPE_4 = cpu=2,gpu=6,railgun=25%,25%\nSLOT_TYPE_4_PARTITIONABLE = TRUE\nNUM_SLOTS_TYPE_4 = 1\n</pre></div>\n\n\n<p>the script railgun_inventory.sh looks like:\n</p><div class=\"code\">\n<pre class=\"code\">#!/bin/sh\necho \"DetectedRailgun = $1\"\necho -e \"RailgunMuzzleVelocity = \\\"$2\\\"\"\n</pre></div>\n\n\n<p>Start the pool, let slots spin up.  Expected slot configuration:\n</p><div class=\"code\">\n<pre class=\"code\">$ svhist SlotTypeID Gpu Railgun TotalSlotGpu TotalSlotRailgun TotalGpu TotalRailgun DetectedGpu DetectedRailgun SlotType State Activity\n      2 1 | 1 | 1 | 1 | 1 | 16 | 8 | 16 | 8 | Static | Unclaimed | Idle\n      1 2 | 4 | 2 | 4 | 2 | 16 | 8 | 16 | 8 | Partitionable | Unclaimed | Idle\n      1 3 | 4 | 2 | 4 | 2 | 16 | 8 | 16 | 8 | Static | Unclaimed | Idle\n      1 4 | 6 | 2 | 6 | 2 | 16 | 8 | 16 | 8 | Partitionable | Unclaimed | Idle\n      5 total\n</pre></div>\n\n\n<p>Check new <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=MachineResources\" title=\"Machine Resources\">MachineResources</a></span> attribute:\n</p><div class=\"code\">\n<pre class=\"code\">$ svhist SlotTypeID MachineResources\n      2 1 | cpus memory disk swap gpu railgun\n      1 2 | cpus memory disk swap gpu railgun\n      1 3 | cpus memory disk swap gpu railgun\n      1 4 | cpus memory disk swap gpu railgun\n      5 total\n</pre></div>\n\n\n<p>Also check slot attributes from resources.  Note that resource 'railgun' advertises extra attribute 'railgun_muzzle_velocity = \"0.95c\"'\n</p><div class=\"code\">\n<pre class=\"code\">$ condor_status -l | grep Gpu\nTotalGpu = 16\nTotalSlotGpu = 1\nGpu = 1\nDetectedGpu = 16\nTotalGpu = 16\nTotalSlotGpu = 1\nGpu = 1\nDetectedGpu = 16\nTotalGpu = 16\nTotalSlotGpu = 4\nGpu = 4\nDetectedGpu = 16\nTotalGpu = 16\nTotalSlotGpu = 4\nGpu = 4\nDetectedGpu = 16\nTotalGpu = 16\nTotalSlotGpu = 6\nGpu = 6\nDetectedGpu = 16\n\n$ condor_status -l | grep Railgun\nTotalRailgun = 8\nRailgun = 1\nDetectedRailgun = 8\nTotalSlotRailgun = 1\nRailgunMuzzleVelocity = \"0.95c\"\nTotalRailgun = 8\nRailgun = 1\nDetectedRailgun = 8\nTotalSlotRailgun = 1\nRailgunMuzzleVelocity = \"0.95c\"\nTotalRailgun = 8\nRailgun = 2\nDetectedRailgun = 8\nTotalSlotRailgun = 2\nRailgunMuzzleVelocity = \"0.95c\"\nTotalRailgun = 8\nRailgun = 2\nDetectedRailgun = 8\nTotalSlotRailgun = 2\nRailgunMuzzleVelocity = \"0.95c\"\nTotalRailgun = 8\nRailgun = 2\nDetectedRailgun = 8\nTotalSlotRailgun = 2\nRailgunMuzzleVelocity = \"0.95c\"\n</pre></div>\n\n\n<p>Now submit the following jobs, all of which should run:\n</p><div class=\"code\">\n<pre class=\"code\">universe = vanilla\ncmd = /bin/sleep\nargs = 300\nshould_transfer_files = if_needed\nwhen_to_transfer_output = on_exit\nrequest_memory = 1\n\n# submit a job against Slot Type 1\n+AccountingGroup = \"SlotType1.succ1\"\nrequirements = (SlotTypeID==1)\nrequest_railgun = 1\nrequest_gpu = 1\nqueue 1\n\n# submit job against Slot Type 2\n+AccountingGroup = \"SlotType2.succ1\"\nrequirements = (SlotTypeID==2 || SlotTypeID==-2)\nrequest_railgun = 2\nrequest_gpu = 1\nqueue 1\n\n# submit job against Slot Type 2\n+AccountingGroup = \"SlotType2.succ2\"\nrequirements = (SlotTypeID==2 || SlotTypeID==-2)\nrequest_railgun = 0\nrequest_gpu = 2\nqueue 1\n\n# submit job against Slot Type 3\n+AccountingGroup = \"SlotType3.succ1\"\nrequirements = (SlotTypeID==3)\nrequest_railgun = 1\nrequest_gpu = 3\nqueue 1\n\n# submit job against Slot Type 4\n+AccountingGroup = \"SlotType4.succ1\"\nrequirements = (SlotTypeID==4 || SlotTypeID==-4)\nrequest_railgun = 1\nrequest_gpu = 3\nqueue 1\n\n# submit job against Slot Type 4\n+AccountingGroup = \"SlotType4.succ2\"\nrequirements = (SlotTypeID==4 || SlotTypeID==-4)\nrequest_railgun = 0\nrequest_gpu = 2\nqueue 1\n</pre></div>\n\n\n<p>Give the jobs a couple negotiator cycles to spin up, and you should see the following:\n</p><div class=\"code\">\n<pre class=\"code\">$ svhist SlotTypeID Gpu Railgun TotalSlotGpu TotalSlotRailgun TotalGpu TotalRailgun DetectedGpu DetectedRailgun SlotType State Activity\n      1 1 | 1 | 1 | 1 | 1 | 16 | 8 | 16 | 8 | Static | Claimed | Busy\n      1 1 | 1 | 1 | 1 | 1 | 16 | 8 | 16 | 8 | Static | Unclaimed | Idle\n      1 2 | 1 | 0 | 4 | 2 | 16 | 8 | 16 | 8 | Partitionable | Unclaimed | Idle\n      1 -2 | 1 | 2 | 0 | 0 | 16 | 8 | 16 | 8 | Dynamic | Claimed | Busy\n      1 -2 | 2 | 0 | 0 | 0 | 16 | 8 | 16 | 8 | Dynamic | Claimed | Busy\n      1 3 | 4 | 2 | 4 | 2 | 16 | 8 | 16 | 8 | Static | Claimed | Busy\n      1 4 | 1 | 1 | 6 | 2 | 16 | 8 | 16 | 8 | Partitionable | Unclaimed | Idle\n      1 -4 | 2 | 0 | 0 | 0 | 16 | 8 | 16 | 8 | Dynamic | Claimed | Busy\n      1 -4 | 3 | 1 | 0 | 0 | 16 | 8 | 16 | 8 | Dynamic | Claimed | Busy\n      9 total\n\n$ qvsort ClusterID ProcID AccountingGroup JobStatus\n1 | 0 | SlotType1.succ1 | 2\n1 | 1 | SlotType2.succ1 | 2\n1 | 2 | SlotType2.succ2 | 2\n1 | 3 | SlotType3.succ1 | 2\n1 | 4 | SlotType4.succ1 | 2\n1 | 5 | SlotType4.succ2 | 2\n</pre></div>\n\n\n<p>Now submit the following jobs (which should fail to run due to local resource constraints):\n</p><div class=\"code\">\n<pre class=\"code\">universe = vanilla\ncmd = /bin/sleep\nargs = 300\nshould_transfer_files = if_needed\nwhen_to_transfer_output = on_exit\nrequest_memory = 1\n\n# submit job against Slot Type 1, should fail for too much railgun\n+AccountingGroup = \"SlotType1.fail1\"\nrequirements = (SlotTypeID==1)\nrequest_railgun = 2\nrequest_gpu = 1\nqueue 1\n\n# submit job against Slot Type 2, should fail\n+AccountingGroup = \"SlotType2.fail1\"\nrequirements = (SlotTypeID==2 || SlotTypeID==-2)\nrequest_railgun = 0\nrequest_gpu = 2\nqueue 1\n\n# submit job against Slot Type 3, should fail\n+AccountingGroup = \"SlotType3.fail1\"\nrequirements = (SlotTypeID==3)\nrequest_railgun = 1\nrequest_gpu = 5\nqueue 1\n\n# submit job against Slot Type 4, should fail\n+AccountingGroup = \"SlotType4.fail1\"\nrequirements = (SlotTypeID==4 || SlotTypeID==-4)\nrequest_railgun = 1\nrequest_gpu = 2\nqueue 1\n</pre></div>\n\n\n<p>Allow a negotiator cycle or two to pass.  you should see that none of the new jobs run:\n</p><div class=\"code\">\n<pre class=\"code\">$ qvsort ClusterID ProcID AccountingGroup JobStatus1 | 0 | SlotType1.succ1 | 2\n1 | 1 | SlotType2.succ1 | 2\n1 | 2 | SlotType2.succ2 | 2\n1 | 3 | SlotType3.succ1 | 2\n1 | 4 | SlotType4.succ1 | 2\n1 | 5 | SlotType4.succ2 | 2\n2 | 0 | SlotType1.fail1 | 1\n2 | 1 | SlotType2.fail1 | 1\n2 | 2 | SlotType3.fail1 | 1\n2 | 3 | SlotType4.fail1 | 1\n</pre></div>\n\n\n<p>Finally, remove all the jobs from the que.   You should see the original slot configuration restore:\n</p><div class=\"code\">\n<pre class=\"code\">$ condor_rm -all\nAll jobs marked for removal.\n\n$ svhist SlotTypeID Gpu Railgun TotalSlotGpu TotalSlotRailgun TotalGpu TotalRailgun DetectedGpu DetectedRailgun SlotType State Activity\n      2 1 | 1 | 1 | 1 | 1 | 16 | 8 | 16 | 8 | Static | Unclaimed | Idle\n      1 2 | 4 | 2 | 4 | 2 | 16 | 8 | 16 | 8 | Partitionable | Unclaimed | Idle\n      1 3 | 4 | 2 | 4 | 2 | 16 | 8 | 16 | 8 | Static | Unclaimed | Idle\n      1 4 | 6 | 2 | 6 | 2 | 16 | 8 | 16 | 8 | Partitionable | Unclaimed | Idle\n      5 total\n</pre></div>\n\n\n<p></p><hr/>\n<em>2012-Apr-05 08:29:24 by tstclair:</em> <br/>\n\nAwesome, 1 question though:\n\n<p>What does the Requirements expression on the submit side translate to be?\n\n</p><p></p><hr/>\n<em>2012-Apr-05 09:43:09 by eje:</em> <br/>\n\nOn the job ad reqs side, local resource requests look like this:\n<div class=\"code\">\n<pre class=\"code\">$ condor_q -l -const 'AccountingGroup==\"SlotType1.succ1\"' | grep -e Railgun -e Gpu\nRequestRailgun = 1\nAutoClusterAttrs = \"JobUniverse,LastCheckpointPlatform,NumCkpts,_condor_RequestCpus,_condor_RequestDisk,_condor_RequestMemory,RequestCpus,RequestDisk,RequestMemory,FileSystemDomain,DiskUsage,RequestGpu,RequestRailgun,Requirements,NiceUser,ConcurrencyLimits\"\nRequirements = ( ( SlotTypeID == 1 ) ) &amp;&amp; ( TARGET.Arch == \"X86_64\" ) &amp;&amp; ( TARGET.OpSys == \"LINUX\" ) &amp;&amp; ( TARGET.Disk &gt;= RequestDisk ) &amp;&amp; ( TARGET.Memory &gt;= RequestMemory ) &amp;&amp; ( TARGET.Railgun &gt;= RequestRailgun ) &amp;&amp; ( TARGET.Gpu &gt;= RequestGpu ) &amp;&amp; ( ( TARGET.HasFileTransfer ) || ( TARGET.FileSystemDomain == MY.FileSystemDomain ) )\nRequestGpu = 1\n</pre></div>\n\n\n<p></p><hr/>\n<em>2012-Apr-05 11:50:14 by tannenba:</em> <br/>\n\nCool!  Erik, we need to coordinate as I was on a similar path as you for adding better first-class GPU support into Condor.\n\n<p>Couple quick thoughts from looking at above (didn't look at the patch itself yet):\n\n</p><p>We need to clean-up and make consistent the naming convention for partitionable resources. If we look at what we already have for partitionable resource Foo, we have in the machine ad:\n\n</p><p></p><pre>   TotalFoo = &lt;total on the physical machine useable by Condor?&gt;\n   DetectedFoo = &lt;total detected on the physical machine?&gt;\n   TotalSlotFoo = &lt;total allocated to this slot&gt;\n   Foo = &lt;amount currently provisioned on this slot&gt;\n</pre>\n\n<p>and in the job ad:\n\n</p><p></p><pre>   RequestFoo = &lt;required number of Foos&gt;\n   FooUsage = &lt;amount of Foo being used&gt;\n</pre>\n\n<p><em>Side question: In the above, when will =TotalFoo= and =DetectedFoo= ever be different?</em>\n\n</p><p>Now this patch starts up yet another naming convention with <code>LocalResource_Foo</code> and <code>SlotResource_Foo</code>.  We should think about if this is needed, and how to better reconcile it with what we have.\n\n</p><p>I like the idea of the <code>LOCAL_RESOURCE_INVENTORY_</code> plugin script to return inventory, but want to think about if/how this integrates with hawkeye.\n\n</p><p>Re <code>LOCAL_RESOURCE_NAMES</code>, it would be good to have the startd create that list itself instead of requiring the admin to supply it.  My thinking is imagine if Condor simply shipped with a sub-directory of local_resource plugins that got invoked on startup that included a GPU one (I'll have this part soon!).  If the machine had a GPU, the resource plugin would return resource inventory about it.  Similarly, the admin could append a local config file that declared info about a resource without having to mess around with resource_names = $(resource_name) new_resource silliness.\n\n</p><p>I assume the SlotTypeID stuff in the job requirements is just for ease of testing purposes, right?\n\n</p><p>Anyhow, lets talk more soon...\n\n</p><p></p><hr/>\n<em>2012-Apr-05 12:08:45 by eje:</em> <br/>\n\n<span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=TotalFoo\" title=\"Total Foo\">TotalFoo</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DetectedFoo\" title=\"Detected Foo\">DetectedFoo</a></span> could be different if you were advertising multiple slot types on the same machine, or exposing &gt;= 2 partitionable slots, etc.\n\n<p>I went with a new naming convention because I felt like these \"local resources\" aren't quite the same thing as mem/disk/swap, in the sense that they aren't guaranteed to exist on any machine, may be completely different from machine to machine etc.\n\n</p><p>Also, I employed the \"_foo\" suffix as opposed to the more traditional camel-case \"Foo\" suffix, because these represent things that appear on the SLOT_TYPE_N = disk,ram,foo  config line.   So \"Foo\" seemed not quite to correspond with \"foo\".\n\n</p><p>However, I suppose we could alter the naming algorithm to camel-case it on the slot attributes.\n\n</p><p>I think <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DetectedFoo\" title=\"Detected Foo\">DetectedFoo</a></span> is a reasonable substitution for what I was calling LocalResource_foo.  Or Detected_foo.\n\n</p><p>SlotTypeID was a thing I came up with as a testing aid, but I also think it might be useful as a config hook for policies based on slot type (e.g. Matt mentioned START exprs).  The testing config in my example above is sort of exaggerated that way, but I believe configurations with multiple slot types do exist in the wild.  At any rate, we support them.\n\n</p><p></p><hr/>\n<em>2012-Apr-05 12:11:19 by eje:</em> <br/>\n\nAnother naming related issue on my mind is, using \"AttrName_foo\" seemed like a convention that would minimize any possible naming collisions, which I want to give some thought to because we don't have much control over what a user declares for names on LOCAL_RESOURCE_NAMES, beyond making sure it's not disk/mem/swap/etc\n\n<p></p><hr/>\n<em>2012-Apr-05 12:16:58 by eje:</em> <br/>\n\nA 3rd naming issue, code related is, by using \"AttrName_foo\", it allows the local resource name \"foo\" to be used everywhere, exactly the same, no case alterations, etc.  Introducing some kind of \"foo\" &lt;==&gt; \"Foo\" logic might be a bug factory.\n\n<p>I considered <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=AttrNamefoo\" title=\"Attr Namefoo\">AttrNamefoo</a></span>, but that looked funny and harder to read.  And also, the name collision thing.\n\n</p><p></p><hr/>\n<em>2012-Apr-13 18:58:35 by eje:</em> <br/>\n\nOn the machine/startd side, we agreed that we'd adhere to the current convention, as in for a resource \"foo\":\n\n<p></p><ul>\n<li><span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DetectedFoo\" title=\"Detected Foo\">DetectedFoo</a></span> = total detected on the physical machine\n</li><li><span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=TotalFoo\" title=\"Total Foo\">TotalFoo</a></span> = total defined via configuration (e.g. NUM_CPUS = 100)\n</li><li><span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=TotalSlotFoo\" title=\"Total Slot Foo\">TotalSlotFoo</a></span> = total allocated to this slot\n</li><li>Foo = amount currently available to be used on this slot\n</li></ul>\n\n<p>I'm not sure that the semantic difference between <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DetectedFoo\" title=\"Detected Foo\">DetectedFoo</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=TotalFoo\" title=\"Total Foo\">TotalFoo</a></span> applies very well to these new configured machine resources.  With the current patch, we might reasonably define <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=TotalFoo\" title=\"Total Foo\">TotalFoo</a></span> as the value from MACHINE_RESOURCE_foo, and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DetectedFoo\" title=\"Detected Foo\">DetectedFoo</a></span> as whatever comes from MACHINE_RESOURCE_INVENTORY_foo.\n\n</p><p>However, we're planning on deprecating MACHINE_RESOURCE_INVENTORY_foo, and replacing it with the \"|\" config facility, which would essentially be just a scriptable way of defining MACHINE_RESOURCE_foo, and so the distinction between detected/configured would no longer be operative.\n\n</p><p>For the moment, I'm going to move forward by advertising <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DetectedFoo\" title=\"Detected Foo\">DetectedFoo</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=TotalFoo\" title=\"Total Foo\">TotalFoo</a></span> as just synonyms.  It would leave the door open to future developments where the two values could meaningfully differ (e.g. if gpus got baked deeper into the code someday, etc).\n\n</p><p>Questions/Feedback/Flaming solicited\n\n</p><p></p><hr/>\n<em>2012-May-23 13:50:35 by tstclair:</em> <br/>\n\n<strong>NOTE:</strong> The \"|\" config ref, is not meant to be an extension to a param, but to extend discovery on startup.  The current restriction is that piped configs only allow one script.\n\n<p>So in the future it might be:\n\n</p><p></p><div class=\"code\">\n<pre class=\"code\">CONDOR_CONFIG Normal_Script.sh | Discovery1_script.sh | Discovery2_script.sh ...\n</pre></div>\n\n\n<p></p><hr/>\n<em>2012-Jul-19 09:32:12 by smoler:</em> <br/>\n\nKaren is taking responsibility for completing the documentation on this ticket.\n\n<p></p><hr/>\n<em>2013-Jul-16 12:34:03 by smoler:</em> <br/>\n\nManual definition of configuration variable <code>MACHINE_RESOURCE_INVENTORY_&lt;name&gt;</code> went into the HTCondor 8.0.1 release.\n\n<p></p><hr/>\n<em>2013-Aug-19 14:56:20 by pfc:</em> <br/>\n\nShould we make new tickets for the development and release-inclusion of the inventory-detection scripts for specific GPUs (e.g., Nvidia) and/or Intel MIC boards?  Or should that be bolted onto this ticket?\n\n<p>As GPUs proliferate on the LDG, and we acquire MIC machines, I'm less and less happy relying on our fully-manual static configuration at each site...\n\n</p><p></p><hr/>\n<em>2013-Aug-20 09:03:02 by pfc:</em> <br/>\n\n<span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=3861\" onclick=\"get_ticket_and_populate_wrapper('3861'); return false;\" title=\"automatically detect NVIDIA/CUDA GPU resources\">#3861</a></span>: automatically detect NVIDIA/CUDA GPU resources\n<span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=3862\" onclick=\"get_ticket_and_populate_wrapper('3862'); return false;\" title=\"automatically detect Intel MIC resources\">#3862</a></span>: automatically detect Intel MIC resources</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=3861\" onclick=\"get_ticket_and_populate_wrapper('3861'); return false;\" title=\"automatically detect NVIDIA/CUDA GPU resources\">#3861</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nautomatically detect NVIDIA/CUDA GPU resources</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=3862\" onclick=\"get_ticket_and_populate_wrapper('3862'); return false;\" title=\"automatically detect Intel MIC resources\">#3862</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nautomatically detect Intel MIC resources</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body><blockquote>\n<ul>\n<li><a href=\"../files/550/gt2905-local-slot-resources.patch\">gt2905-local-slot-resources.patch</a>\n32525 bytes added by eje on 2012-Apr-05 03:42:00 UTC.\n<br/>\npatch against 7.7 branch that implements local resources for slots<br/>\n</li><li><a href=\"../files/552/gt2905-local-slot-resources.patch2\">gt2905-local-slot-resources.patch2</a>\n36620 bytes added by eje on 2012-Apr-18 21:51:11 UTC.\n<br/>\nUpdated patch to address feedback.  Also on branch V7_7-gt2905-local-slot-resources\n<br/>\n</li></ul>\n</blockquote></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Jul-16 12:27</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/4c0cbeed7b426a3d324c70fca139d91e60fe2ee5\">[36913]</a></span>: added defn of knob MACHINE_RESOURCE_INVENTORY_&lt;name&gt;, which was omitted from the documentation going back to version 7.9.0. ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Jul-24 13:15</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/6196fe194b7f29bbe76ab8dc16a3dc4aad446755\">[32898]</a></span>: completion of documentation for custom machine resource specification ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Jul-23 09:54</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/47d560600e03edfabbf1dd62d6a7bf814f95dbcd\">[32886]</a></span>: more changes for the large edit of subsection on configuration of slots and allocation of resources to those slots ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Jul-20 12:30</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/d074254a3e2fc581f09b21480185ce5014ca175c\">[32873]</a></span>: further edits for configuration of slots ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Jul-20 10:18</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/37385f82a0150db856c67102c413333e0e122b47\">[32867]</a></span>: Just the start of a full edit of section 3.12.8 on configuring the usage of slots, also towards documenting the ability to partition customizable machine resources ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Jul-17 22:52</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/f4e9bedf3ccce1dbf394d8d0a233637019b7267c\">[32836]</a></span>: ===VersionHistory:Completed=== ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Erik Erlandson )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Jul-17 22:52</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/ad15d73ca328c04f196d0693eb2fb14821753af0\">[32835]</a></span>: Documented the new customizable local machine resources feature ===GT=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Erik Erlandson )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2012-Apr-19 17:10</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/fa0214447a9dbbab4a52b3126e8532e659f148c1\">[31762]</a></span>: Added support for configuring local resources for slots ===GT:Fixed=== <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>  (By Erik Erlandson )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2013-Aug-20 09:03", "status": "defer", "created": "2012-Mar-26 14:53", "fixed_version": "2012-Mar-26 14:53", "broken_version": "", "priority": "5", "subsystem": "Daemons", "assigned_to": "eje", "derived_from": "#2011", "creator": "eje", "rust": "", "customer_group": "ligo", "visibility": "public", "notify": "adesmet@cs.wisc.edu, tstclair@cs.wisc.edu, eje@cs.wisc.edu, tannenba@cs.wisc.edu,pcouvare@caltech.edu", "due_date": ""}