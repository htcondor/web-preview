{"id": 4821, "title": "Ticket #4821: Only fork collector for a few ad types", "description": "<blockquote>\nDoing a detailed analysis of collector system CPU, a major contributor is forking the collector for very small queries.\n\n<p>The large majority of queries are along the lines of:\n\n</p><p></p><div class=\"verbatim\">\n<pre>01/09/15 20:21:32 Query info: matched=1; skipped=21; query_time=0.069206; send_time=0.001027; type=Scheduler; requirements={( ( Name =?= \"cmssrv219.fnal.gov\" ) )}; peer=&lt;1.2.3.4:54935&gt;; projection={ScheddIpAddr SPOOL_DIR_STRING LOCAL_DIR_STRING Name}\n</pre></div>\n\n\n<p>Note the query time is 69ms -- measurements on this node indicate that clone takes around 55-70ms.  In other words, it seems likely that &gt;90% of the query response time for the collector is forking for response.\n\n</p><p>Considering the average TCP write buffer size (64KB) and the number of non-machine, non-master ads (small handful?), it seems like it would be a simple speedup to just not fork in the cases where there's a large number of possible responses.  For example:\n\n</p><p></p><div class=\"verbatim\">\n<pre>--- a/src/condor_collector.V6/collector.cpp\n+++ b/src/condor_collector.V6/collector.cpp\n@@ -352,13 +352,14 @@ int CollectorDaemon::receive_query_cedar(Service* /*s*/,\n        ForkStatus      fork_status = FORK_FAILED;\n        int                     return_status = 0;\n     if (whichAds != (AdTypes) -1) {\n-               fork_status = forkQuery.NewJob( );\n-               if ( FORK_PARENT == fork_status ) {\n-                       return 1;\n-               } else {\n-                       // Child / Fork failed / busy\n-                       process_query_public (whichAds, &amp;cad, &amp;results);\n+               if ((whichAds == QUERY_GENERIC_ADS) || (whichAds == QUERY_ANY_ADS) || (whichAds == QUERY_STARTD_PVT_ADS) || (whichAds == QUERY_STARTD_ADS) || (whichAds == QUERY_MASTER_ADS)) {\n+                       fork_status = forkQuery.NewJob( );\n+                       if ( FORK_PARENT == fork_status ) {\n+                               return 1;\n+                       }\n                }\n+               // Child / Fork failed / busy\n+               process_query_public (whichAds, &amp;cad, &amp;results);\n        }\n\n        UtcTime end_write, end_query(true);\n</pre></div>\n</blockquote>", "remarks": "<blockquote>\n<em>2015-Jan-12 16:00:31 by gthain:</em> <br/>\n\nHow about once we have -limit-matches in the collector query, to only fork if limit matches is less than some threshold?\n\n<p>Or, we could always do the query in the parent (How long does that take in the 250k connections case?), and only fork if we have more than, say, 16 results.\n\n</p><p></p><hr/>\n<em>2015-Jan-12 16:07:51 by bbockelm:</em> <br/>\n\nHi Greg,\n\n<p>At least on the node I examined, the queue iteration does take &gt;1s when iterating through the workers.  So, in that case, it would be worth forking.\n\n</p><p>What about only forking if the hash table we walk through is above size X?\n\n</p><p>Brian\n\n</p><p></p><hr/>\n<em>2015-Jan-12 16:21:58 by gthain:</em> <br/>\n\nCan we get requirements for \"big result set\" query Hz and \"small result set\" query Hz?\n\n<p></p><hr/>\n<em>2015-Jan-12 19:55:34 by bbockelm:</em> <br/>\n\nHm - I'm not sure how to quantify requirements here.  However, I can share anecdotes from CollectorLog.old on the current collector:\n<ul>\n<li>Over a period of 10 minutes (log was rotated), there was approximately 2Hz of \"small queries\" - specifically, scheduler or negotiator queries.  These all seemed to be dominated by the cost of fork().\n<ul>\n<li>I can confirm that the query time of the small queries went from 300ms to &lt;1ms when query workers were disabled.\n</li></ul>\n</li><li>The rate of \"large queries\" was 1/12 Hz.  The queries were serviced in .6-1.0s; send time varied from 1ms to 3s (.6s query and 1ms send was for cases where there were no matching ads).\n</li></ul>\n\n<p>When I looked, the collector had about 30k startds and 30k master ads.\n\n</p><p><strong>ANECDOTE:</strong> In my experience with the V3 query protocol, it usually takes about 100 job ads to fill a TCP socket buffer.  Why not have the cutoff be based on the size of the underlying hash map(s)?  Basically, have a variable, <code>COLLECTOR_SMALL_QUERY_CUTOFF</code> (defaults to 60).  If there's more than <code>COLLECTOR_SMALL_QUERY_CUTOFF</code> ads of the given type, fork; otherwise, respond in-process.\n\n</p><p>Given the way the code is currently structured, this should be relatively straightforward to implement.</p></blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2015-Jan-23 15:03</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/ea0311de7f2b36ef25bb380ce475706ac61bd8bf\">[42358]</a></span>: edit 8.3.3 version history item <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=4821\" onclick=\"get_ticket_and_populate_wrapper('4821'); return false;\" title=\"Only fork collector for a few ad types\">#4821</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2015-Jan-23 11:23</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/81af7c4906b7092353db2a4ad0cf509c9915c4c3\">[42347]</a></span>: Document <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=4821\" onclick=\"get_ticket_and_populate_wrapper('4821'); return false;\" title=\"Only fork collector for a few ad types\">#4821</a></span>  (By Greg Thain )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2015-Jan-23 10:46</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/be01a291d7cfed61d13f1317467d66e51c9a2ebf\">[42344]</a></span>: Only fork the collector to handle queries to large tables <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=4821\" onclick=\"get_ticket_and_populate_wrapper('4821'); return false;\" title=\"Only fork collector for a few ad types\">#4821</a></span> Committer: Greg Thain  (By Brian Bockelman )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2015-Apr-27 16:42", "status": "resolved", "created": "2015-Jan-09 14:07", "fixed_version": "2015-Jan-09 14:07", "broken_version": "", "priority": "3", "subsystem": "DaemonsCM", "assigned_to": "gthain", "derived_from": "#4490", "creator": "bbockelm", "rust": "", "customer_group": "cms", "visibility": "public", "notify": "bbockelm@cse.unl.edu", "due_date": ""}