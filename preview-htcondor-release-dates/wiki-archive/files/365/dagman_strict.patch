diff --git a/src/condor_dagman/dag.cpp b/src/condor_dagman/dag.cpp
index bf11a6f..62ca378 100644
--- a/src/condor_dagman/dag.cpp
+++ b/src/condor_dagman/dag.cpp
@@ -819,7 +819,7 @@ Dag::RemoveBatchJob(Job *node) {
 	MyString display;
 	args.GetArgsStringForDisplay( &display );
 	debug_printf( DEBUG_VERBOSE, "Executing: %s\n", display.Value() );
-	if ( util_popen( args ) ) {
+	if ( util_popen( args ) != 0 ) {
 			// Note: error here can't be fatal because there's a
 			// race condition where you could do a condor_rm on
 			// a job that already terminated.  wenger 2006-02-08.
@@ -1297,6 +1297,7 @@ Job * Dag::FindNodeByEventID (int logsource, const CondorID condorID) const {
 				debug_printf( DEBUG_QUIET, "Warning: searched for node for "
 							"cluster %d; got %d!!\n", condorID._cluster,
 							node->_CondorID._cluster );
+				check_warning_strictness( DAG_STRICT_3 );
 			}
 		}
 		ASSERT( isNoop == node->GetNoop() );
@@ -1732,7 +1733,7 @@ void Dag::RemoveRunningJobs ( const Dagman &dm) const {
 		constraint.sprintf( "%s == %d", ATTR_DAGMAN_JOB_ID,
 					dm.DAGManJobId._cluster );
 		args.AppendArg( constraint.Value() );
-		if ( util_popen( args ) ) {
+		if ( util_popen( args ) != 0 ) {
 			debug_printf( DEBUG_NORMAL, "Error removing DAGMan jobs\n");
 		}
 	}
@@ -1751,7 +1752,7 @@ void Dag::RemoveRunningJobs ( const Dagman &dm) const {
 			args.Clear();
 			args.AppendArg( dm.storkRmExe );
 			args.AppendArg( job->_CondorID._cluster );
-			if ( util_popen( args ) ) {
+			if ( util_popen( args ) != 0 ) {
 				debug_printf( DEBUG_NORMAL, "Error removing Stork job\n");
 			}
         }
@@ -2486,6 +2487,7 @@ Dag::DumpNodeStatus( bool held, bool removed )
 		debug_printf( DEBUG_NORMAL,
 					  "Warning: can't create node status file '%s': %s\n", 
 					  tmpStatusFile.Value(), strerror( errno ) );
+		check_warning_strictness( DAG_STRICT_1 );
 		return;
 	}
 
@@ -2591,6 +2593,7 @@ Dag::DumpNodeStatus( bool held, bool removed )
 					  "file (%s) to permanent file (%s): %s\n",
 					  tmpStatusFile.Value(), _statusFileName,
 					  strerror( errno ) );
+		check_warning_strictness( DAG_STRICT_1 );
 		return;
 	}
 
@@ -2656,6 +2659,7 @@ Dag::CheckAllJobs()
 				result == CheckEvents::EVENT_WARNING ) {
 		debug_printf( DEBUG_NORMAL, "Warning checking Condor job events: %s\n",
 				jobError.Value() );
+		check_warning_strictness( DAG_STRICT_3 );
 	} else {
 		debug_printf( DEBUG_DEBUG_1, "All Condor job events okay\n");
 	}
@@ -2669,6 +2673,7 @@ Dag::CheckAllJobs()
 				result == CheckEvents::EVENT_WARNING ) {
 		debug_printf( DEBUG_NORMAL, "Warning checking Stork job events: %s\n",
 				jobError.Value() );
+		check_warning_strictness( DAG_STRICT_3 );
 	} else {
 		debug_printf( DEBUG_DEBUG_1, "All Stork job events okay\n");
 	}
@@ -2760,19 +2765,17 @@ Dag::CheckThrottleCats()
 					info->_totalJobs, info->_maxJobs );
 		ASSERT( info->_totalJobs >= 0 );
 		if ( info->_totalJobs < 1 ) {
-				// When we implement the -strict flag (see gittrac #1755)
-				// this should be a fatal error.
 			debug_printf( DEBUG_NORMAL, "Warning: category %s has no "
 						"assigned nodes, so the throttle setting (%d) "
 						"will have no effect\n", info->_category->Value(),
 						info->_maxJobs );
+			check_warning_strictness( DAG_STRICT_2 );
 		}
 
 		if ( !info->isSet() ) {
-				// When we implement the -strict flag (see gittrac #1755)
-				// this should be a fatal error.
 			debug_printf( DEBUG_NORMAL, "Warning: category %s has no "
 						"throttle value set\n", info->_category->Value() );
+			check_warning_strictness( DAG_STRICT_2 );
 		}
 	}
 }
@@ -3886,6 +3889,7 @@ Dag::AssumeOwnershipofNodes(const MyString &spliceName, OwnedMaterials *om)
 						mainThrottle->_maxJobs,
 						mainThrottle->_category->Value(),
 						spliceName.Value(), spliceThrottle->_maxJobs );
+			check_warning_strictness( DAG_STRICT_2 );
 		} else {
 			_catThrottles.SetThrottle( spliceThrottle->_category,
 						spliceThrottle->_maxJobs );
diff --git a/src/condor_dagman/dagman_main.cpp b/src/condor_dagman/dagman_main.cpp
index f77a194..67a8677 100644
--- a/src/condor_dagman/dagman_main.cpp
+++ b/src/condor_dagman/dagman_main.cpp
@@ -55,6 +55,8 @@ static char* lockFileName = NULL;
 
 static Dagman dagman;
 
+strict_level_t Dagman::_strict = DAG_STRICT_0;
+
 //---------------------------------------------------------------------------
 static void Usage() {
     debug_printf( DEBUG_SILENT, "\nUsage: condor_dagman -f -t -l .\n"
@@ -180,6 +182,11 @@ Dagman::Config()
 					NULL, true );
 	}
 
+	_strict = (strict_level_t)param_integer( "DAGMAN_USE_STRICT",
+				_strict, DAG_STRICT_0, DAG_STRICT_3 );
+	debug_printf( DEBUG_NORMAL, "DAGMAN_USE_STRICT setting: %d\n",
+				_strict );
+
 	debug_level = (debug_level_t)param_integer( "DAGMAN_VERBOSITY",
 				debug_level, DEBUG_SILENT, DEBUG_DEBUG_4 );
 	debug_printf( DEBUG_NORMAL, "DAGMAN_VERBOSITY setting: %d\n",
@@ -249,6 +256,7 @@ Dagman::Config()
 		debug_printf( DEBUG_NORMAL, "Warning: "
 				"DAGMAN_IGNORE_DUPLICATE_JOB_EXECUTION "
 				"is deprecated -- used DAGMAN_ALLOW_EVENTS instead\n" );
+		check_warning_strictness( DAG_STRICT_1 );
 	}
 
 		// Now get the new DAGMAN_ALLOW_EVENTS value -- that can override
@@ -429,6 +437,12 @@ void main_shutdown_graceful() {
 }
 
 void main_shutdown_rescue( int exitVal ) {
+		// Avoid possible infinite recursion if you hit a fatal error
+		// while writing a rescue DAG.
+	static bool inShutdownRescue = false;
+	if ( inShutdownRescue) return;
+	inShutdownRescue = true;
+
 	debug_printf( DEBUG_QUIET, "Aborting DAG...\n" );
 	if( dagman.dag ) {
 			// we write the rescue DAG *before* removing jobs because
@@ -462,11 +476,12 @@ void main_shutdown_rescue( int exitVal ) {
 			dagman.dag->RemoveRunningScripts();
 		}
 		dagman.dag->PrintDeferrals( DEBUG_NORMAL, true );
+		dagman.dag->DumpNodeStatus( false, true );
+		dagman.dag->GetJobstateLog().WriteDagmanFinished( exitVal );
 	}
-	dagman.dag->DumpNodeStatus( false, true );
-	dagman.dag->GetJobstateLog().WriteDagmanFinished( exitVal );
 	unlink( lockFileName ); 
     dagman.CleanUp();
+	inShutdownRescue = false;
 	DC_Exit( exitVal );
 }
 
@@ -639,6 +654,7 @@ void main_init (int argc, char ** const argv) {
 			debug_printf( DEBUG_SILENT, "Warning: -NoEventChecks is "
 						"ignored; please use the DAGMAN_ALLOW_EVENTS "
 						"config parameter instead\n");
+			check_warning_strictness( DAG_STRICT_1 );
 
         } else if( !strcasecmp( "-AllowLogError", argv[i] ) ) {
 			dagman.allowLogError = true;
@@ -808,6 +824,7 @@ void main_init (int argc, char ** const argv) {
         	debug_printf( DEBUG_NORMAL, "Warning: %s is newer than "
 						"condor_dagman version (%s)\n", versionMsg.Value(),
 						CondorVersion() );
+			check_warning_strictness( DAG_STRICT_3 );
 		} else {
         	debug_printf( DEBUG_NORMAL, "Note: %s differs from "
 						"condor_dagman version (%s), but the "
@@ -1241,6 +1258,7 @@ void condor_event_timer () {
 			debug_printf( DEBUG_NORMAL, "Warning:  DAGMan thinks there "
 						"are %d idle jobs, even though the DAG is "
 						"completed!\n", dagman.dag->NumIdleJobProcs() );
+			check_warning_strictness( DAG_STRICT_1 );
 		}
 		ExitSuccess();
 		return;
diff --git a/src/condor_dagman/dagman_main.h b/src/condor_dagman/dagman_main.h
index 686aff3..b1ab94e 100644
--- a/src/condor_dagman/dagman_main.h
+++ b/src/condor_dagman/dagman_main.h
@@ -193,6 +193,8 @@ class Dagman {
 		// The maximum number of times a node job can go on hold before
 		// we declare it a failure and remove it; 0 means no limit.
 	int _maxJobHolds;
+
+	static strict_level_t _strict;
 };
 
 #endif	// ifndef DAGMAN_MAIN_H
diff --git a/src/condor_dagman/dagman_multi_dag.cpp b/src/condor_dagman/dagman_multi_dag.cpp
index 2b708d1..b0e1b23 100644
--- a/src/condor_dagman/dagman_multi_dag.cpp
+++ b/src/condor_dagman/dagman_multi_dag.cpp
@@ -155,6 +155,11 @@ FindLastRescueDagNum( const char *primaryDagFile, bool multiDags,
 					test );
 		if ( access( testName.Value(), F_OK ) == 0 ) {
 			if ( test > lastRescue + 1 ) {
+					// This should probably be a fatal error if
+					// DAGMAN_USE_STRICT is set, but I'm avoiding
+					// that for now because the fact that this code
+					// is used in both condor_dagman and condor_submit_dag
+					// makes that harder to implement. wenger 2011-01-28
 				dprintf( D_ALWAYS, "Warning: found rescue DAG "
 							"number %d, but not rescue DAG number %d\n",
 							test, test - 1);
diff --git a/src/condor_dagman/dagman_submit.cpp b/src/condor_dagman/dagman_submit.cpp
index 062f11c..40fc14b 100644
--- a/src/condor_dagman/dagman_submit.cpp
+++ b/src/condor_dagman/dagman_submit.cpp
@@ -321,9 +321,10 @@ condor_submit( const Dagman &dm, const char* cmdFile, CondorID& condorID,
 
 		// if we don't have room for DAGParentNodeNames, leave it unset
 	if( cmdLineSize + reserveNeeded + DAGParentNodeNamesLen > maxCmdLine ) {
-		debug_printf( DEBUG_NORMAL, "WARNING: node %s has too many parents "
+		debug_printf( DEBUG_NORMAL, "Warning: node %s has too many parents "
 					  "to list in its classad; leaving its DAGParentNodeNames "
 					  "attribute undefined\n", DAGNodeName );
+		check_warning_strictness( DAG_STRICT_3 );
 	} else {
 		args.AppendArgsFromArgList( parentNameArgs );
 	}
diff --git a/src/condor_dagman/dagman_util.cpp b/src/condor_dagman/dagman_util.cpp
index 917fbf4..8177633 100644
--- a/src/condor_dagman/dagman_util.cpp
+++ b/src/condor_dagman/dagman_util.cpp
@@ -28,6 +28,7 @@
 #include "my_popen.h"
 #include "../condor_procapi/processid.h"
 #include "../condor_procapi/procapi.h"
+#include "dagman_main.h"
 
 //-----------------------------------------------------------------------------
 int util_popen (ArgList &args) {
@@ -39,11 +40,18 @@ int util_popen (ArgList &args) {
 
     int r = 0;
     if (fp == NULL || (r = my_pclose(fp) & 0xff) != 0) {
-		debug_printf( DEBUG_QUIET, "WARNING: failure: %s\n", cmd.Value() );
+		debug_printf( DEBUG_QUIET, "Warning: failure: %s\n", cmd.Value() );
 		if( fp != NULL ) {
-			debug_printf ( DEBUG_QUIET, "\t(my_pclose() returned %d (errno %d, %s)\n",
-			r, errno, strerror( errno ) );
+			debug_printf ( DEBUG_QUIET,
+						"\t(my_pclose() returned %d (errno %d, %s))\n",
+						r, errno, strerror( errno ) );
+		} else {
+			debug_printf ( DEBUG_QUIET,
+						"\t(my_popen() returned NULL (errno %d, %s))\n",
+						errno, strerror( errno ) );
+			r = -1;
 		}
+		check_warning_strictness( DAG_STRICT_1 );
     }
     return r;
 }
@@ -93,9 +101,10 @@ int util_create_lock_file(const char *lockFileName, bool abortDuplicates) {
 		int sleepTime = procId->computeWaitTime();
 
 		if ( sleepTime > maxSleepTime ) {
-			debug_printf( DEBUG_NORMAL, "WARNING: ProcessId computed sleep "
+			debug_printf( DEBUG_QUIET, "Warning: ProcessId computed sleep "
 						"time (%d) exceeds maximum (%d); skipping sleep/"
 						"confirm step\n", sleepTime, maxSleepTime );
+			check_warning_strictness( DAG_STRICT_3 );
 		} else {
 			debug_printf( DEBUG_NORMAL, "Sleeping for %d seconds to "
 						"ensure ProcessId uniqueness\n", sleepTime );
@@ -112,12 +121,14 @@ int util_create_lock_file(const char *lockFileName, bool abortDuplicates) {
 			int status;
 			if ( ProcAPI::confirmProcessId( *procId, status ) !=
 						PROCAPI_SUCCESS ) {
-				debug_printf( DEBUG_QUIET, "WARNING: ProcAPI::"
+				debug_printf( DEBUG_QUIET, "Warning: ProcAPI::"
 							"confirmProcessId() failed; %d\n", status );
+				check_warning_strictness( DAG_STRICT_3 );
 			} else {
 				if ( !procId->isConfirmed() ) {
-					debug_printf( DEBUG_QUIET, "WARNING: ProcessId not "
+					debug_printf( DEBUG_QUIET, "Warning: ProcessId not "
 								"confirmed unique\n" );
+					check_warning_strictness( DAG_STRICT_3 );
 				} else {
 
 						//
diff --git a/src/condor_dagman/debug.cpp b/src/condor_dagman/debug.cpp
index fdfb4fc..ae22c29 100644
--- a/src/condor_dagman/debug.cpp
+++ b/src/condor_dagman/debug.cpp
@@ -23,6 +23,7 @@
 #include "debug.h"
 #include "condor_daemon_core.h"
 #include "MyString.h"
+#include "dagman_main.h"
 
 debug_level_t debug_level    = DEBUG_NORMAL;
 const char *        debug_progname = NULL;
@@ -258,6 +259,12 @@ void debug_cache_set_size(int size)
 	cache_size = size;
 }
 
-
-
-
+/*--------------------------------------------------------------------------*/
+void check_warning_strictness( strict_level_t strictness )
+{
+	if ( Dagman::_strict >= strictness ) {
+		debug_printf( DEBUG_QUIET, "ERROR: Warning is fatal "
+					"error because of DAGMAN_USE_STRICT setting\n" );
+		main_shutdown_rescue( EXIT_ERROR );
+	}
+}
diff --git a/src/condor_dagman/debug.h b/src/condor_dagman/debug.h
index b36575b..779195d 100644
--- a/src/condor_dagman/debug.h
+++ b/src/condor_dagman/debug.h
@@ -150,6 +150,20 @@ void debug_cache_stop_caching(void);
 void debug_cache_flush(void);
 void debug_cache_set_size(int size);
 
+/**
+ * The level of strictness in turning warnings into fatal errors.
+ */
+enum strict_level {
+	DAG_STRICT_0 = 0,	// No warnings are errors
+	DAG_STRICT_1 = 1,	// Most severe warnings are errors
+	DAG_STRICT_2 = 2,	// Medium-severity warnings are errors
+	DAG_STRICT_3 = 3	// Almost all warnings are errors
+};
+
+typedef enum strict_level strict_level_t;
+
+void check_warning_strictness( strict_level_t strictness );
+
 END_C_DECLS /* from condor_header_features.h */
 
 #endif /* ifndef DAGMAN_DEBUG_H */
diff --git a/src/condor_dagman/job.cpp b/src/condor_dagman/job.cpp
index d3cd817..627610c 100644
--- a/src/condor_dagman/job.cpp
+++ b/src/condor_dagman/job.cpp
@@ -381,6 +381,7 @@ Job::AddParent( Job* parent, MyString &whynot )
 		debug_printf( DEBUG_QUIET,
 					"Warning: child %s already has parent %s\n",
 					GetJobName(), parent->GetJobName() );
+		check_warning_strictness( DAG_STRICT_3 );
 		return true;
 	}
 
@@ -453,6 +454,7 @@ Job::AddChild( Job* child, MyString &whynot )
 		debug_printf( DEBUG_NORMAL,
 					"Warning: parent %s already has child %s\n",
 					GetJobName(), child->GetJobName() );
+		check_warning_strictness( DAG_STRICT_3 );
 		return true;
 	}
 
@@ -708,11 +710,10 @@ Job::SetCategory( const char *categoryName, ThrottleByCategory &catThrottles )
 
 	if ( (_throttleInfo != NULL) &&
 				(tmpName != *(_throttleInfo->_category)) ) {
-			// When we implement the -strict flag (see gittrac # 1755),
-			// should this be a fatal error?
 		debug_printf( DEBUG_NORMAL, "Warning: new category %s for node %s "
 					"overrides old value %s\n", categoryName, GetJobName(),
 					_throttleInfo->_category->Value() );
+		check_warning_strictness( DAG_STRICT_3 );
 	}
 
 		// Note: we must assign a ThrottleInfo here even if the name
diff --git a/src/condor_dagman/jobstate_log.cpp b/src/condor_dagman/jobstate_log.cpp
index 57b0fb9..5e34c54 100644
--- a/src/condor_dagman/jobstate_log.cpp
+++ b/src/condor_dagman/jobstate_log.cpp
@@ -316,6 +316,7 @@ JobstateLog::WriteEvent( const ULogEvent *event, Job *node )
 	if ( strstr( eventName, prefix ) != eventName ) {
        	debug_printf( DEBUG_QUIET, "Warning: didn't find expected prefix "
 					"%s in event name %s\n", prefix, eventName );
+		check_warning_strictness( DAG_STRICT_1 );
 	} else {
 		eventName = eventName + strlen( prefix );
 	}
@@ -512,6 +513,7 @@ JobstateLog::ParseLine( MyString &line, time_t &timestamp,
 	if ( (timestampTok == NULL) || (nodeNameTok == NULL) ) {
 		debug_printf( DEBUG_QUIET, "Warning: error parsing "
 					"jobstate.log file line <%s>\n", line.Value() );
+		check_warning_strictness( DAG_STRICT_1 );
 		return false;
 	}
 
@@ -520,6 +522,7 @@ JobstateLog::ParseLine( MyString &line, time_t &timestamp,
 		debug_printf( DEBUG_QUIET, "Warning: error reading "
 					"timestamp in jobstate.log file line <%s>\n",
 					line.Value() );
+		check_warning_strictness( DAG_STRICT_1 );
 		return false;
 	}
 
@@ -532,6 +535,7 @@ JobstateLog::ParseLine( MyString &line, time_t &timestamp,
 			debug_printf( DEBUG_QUIET, "Warning: error reading "
 						"sequence number in jobstate.log file line <%s>\n",
 						line.Value() );
+			check_warning_strictness( DAG_STRICT_1 );
 			return false;
 		}
 	}
diff --git a/src/condor_dagman/parse.cpp b/src/condor_dagman/parse.cpp
index 6851a89..2633752 100644
--- a/src/condor_dagman/parse.cpp
+++ b/src/condor_dagman/parse.cpp
@@ -223,6 +223,7 @@ bool parse (Dag *dag, const char *filename, bool useDagDir) {
 				"Warning: the DAP token is deprecated and may be unsupported "
 				"in a future release.  Use the DATA token\n",
 				filename, lineNumber );
+			check_warning_strictness( DAG_STRICT_2 );
 		}
 
 		else if	(strcasecmp(token, "DATA") == 0) {
@@ -516,6 +517,7 @@ parse_node( Dag *dag, Job::job_type_t nodeType,
 		debug_printf( DEBUG_NORMAL, "Warning: the use of the JOB "
 					"keyword for nested DAGs is deprecated; please "
 					"use SUBDAG EXTERNAL instead" );
+		check_warning_strictness( DAG_STRICT_3 );
 	}
 
 	// looks ok, so add it
@@ -1318,6 +1320,7 @@ parse_priority(
 		debug_printf( DEBUG_NORMAL, "Warning: new priority %d for node %s "
 					"overrides old value %d\n", priorityVal,
 					job->GetJobName(), job->_nodePriority );
+		check_warning_strictness( DAG_STRICT_2 );
 	}
 	job->_hasNodePriority = true;
 	job->_nodePriority = priorityVal;
diff --git a/src/condor_dagman/script.cpp b/src/condor_dagman/script.cpp
index f9d4360..064554f 100644
--- a/src/condor_dagman/script.cpp
+++ b/src/condor_dagman/script.cpp
@@ -25,6 +25,7 @@
 #include "util.h"
 #include "job.h"
 #include "tmp_dir.h"
+#include "dagman_main.h"
 
 #include "env.h"
 #include "condor_daemon_core.h"
@@ -96,7 +97,8 @@ Script::BackgroundRun( int reaperId )
         } else if ( !strcasecmp( token, "$JOBID" ) ) {
 			if ( !_post ) {
 				debug_printf( DEBUG_QUIET, "Warning: $JOBID macro should "
-							"not be used as a PRE script argument!" );
+							"not be used as a PRE script argument!\n" );
+				check_warning_strictness( DAG_STRICT_1 );
 				arg += token;
 			} else {
             	arg += _node->_CondorID._cluster;
@@ -107,7 +109,8 @@ Script::BackgroundRun( int reaperId )
         } else if (!strcasecmp(token, "$RETURN")) {
 			if ( !_post ) {
 				debug_printf( DEBUG_QUIET, "Warning: $RETURN macro should "
-							"not be used as a PRE script argument!" );
+							"not be used as a PRE script argument!\n" );
+				check_warning_strictness( DAG_STRICT_1 );
 			}
 			arg += _retValJob;
 
@@ -117,6 +120,7 @@ Script::BackgroundRun( int reaperId )
 			debug_printf( DEBUG_QUIET, "Warning: unrecognized macro %s "
 						"in node %s %s script arguments\n", token,
 						_node->GetJobName(), _post ? "POST" : "PRE" );
+			check_warning_strictness( DAG_STRICT_1 );
 			arg += token;
         } else {
 			arg += token;
diff --git a/src/condor_dagman/throttle_by_category.cpp b/src/condor_dagman/throttle_by_category.cpp
index 03f76e6..4b93578 100644
--- a/src/condor_dagman/throttle_by_category.cpp
+++ b/src/condor_dagman/throttle_by_category.cpp
@@ -21,6 +21,7 @@
 #include "condor_common.h"
 #include "condor_string.h"  /* for strnewp() */
 #include "throttle_by_category.h"
+#include "dagman_main.h"
 #include "debug.h"
 #include "MyString.h"
 
@@ -79,6 +80,7 @@ ThrottleByCategory::SetThrottle( const MyString *category, int maxJobs )
 			debug_printf( DEBUG_NORMAL, "Warning: new maxjobs value %d "
 						"for category %s overrides old value %d\n",
 						maxJobs, category->Value(), info->_maxJobs );
+			check_warning_strictness( DAG_STRICT_3 );
 		}
 		info->_maxJobs = maxJobs;
 	}
