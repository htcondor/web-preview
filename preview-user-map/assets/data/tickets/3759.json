{"id": 3759, "title": "Ticket #3759: Fix total_job_time in DAGMan metrics", "description": "<blockquote>\nRight now the total_job_time calculation in the DAGMan metrics is disabled, because it really consumed large amounts of CPU when running the really large DAG test.  I think the problem is in the way the Job code deals with NOOP nodes -- I'll bet I'm ending up with huge vectors of _gotEvents, because for NOOP nodes proc is essentially the equivalent of cluster for a \"normal\" node.\n\n<p>I think I might be able to solve this by just setting proc to 0 for NOOP nodes in Job::ExecMetrics() and Job::TermAbortMetrics().  I need to do a bunch of checking, though, that that really will fix the problem, and make sure everything runs without excessive CPU usage.</p></blockquote>", "remarks": "<blockquote>\n<em>2015-May-21 11:52:21 by wenger:</em> <br/>\n\nHmm -- should metrics for node jobs include information like whether the job was condor_rm'ed?  (Thinking about this as a result of PeterC's HTCondor Week talk.)\n\n<p></p><hr/>\n<em>2015-May-21 11:57:18 by wenger:</em> <br/>\n\nAnd maybe the total job run time could also be split out into run time of jobs that got completed and run time of jobs that got removed or failed.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "", "type": "enhance", "last_change": "2016-Jun-08 12:47", "status": "new", "created": "2013-Jul-09 20:25", "fixed_version": "2013-Jul-09 20:25", "broken_version": "v080100", "priority": "4", "subsystem": "Dag", "assigned_to": "wenger", "derived_from": "#3532", "creator": "wenger", "rust": "", "customer_group": "other", "visibility": "public", "notify": "wenger@cs.wisc.edu, tannenba@cs.wisc,edu, vahi@isi.edu,wedell@bmrb.wisc.edu", "due_date": ""}