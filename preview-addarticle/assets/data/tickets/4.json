{"id": 4, "title": "Ticket #4: Integrate Condor with the Hadoop File System", "description": "<blockquote>\nWe want to explore integration of the Hadoop File System (HDFS) into Condor.\n\n<p>The main person doing the work is <a class=\"external\" href=\"mailto:faisal@cs.wisc.edu\">Faisal Khan</a>, a grad student at UW.\n\n</p><p>In brief, we want to:\n</p><ol>\n<li>Run HDFS services as Condor daemons under the Condor Master.\n</li><li>Install HDFS across the CHTC cluster at UW.\n</li><li>Gain experience: Test the performance and fault tolerance of HDFS (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=124\" onclick=\"get_ticket_and_populate_wrapper('124'); return false;\" title=\"Perform some HDFS testing\">#124</a></span>).  What happens when the block space is filled up?  What is the performance of using HDFS via the JNI interface? Is a new JVM spawned for every JNI session?\n</li><li>Explore ways in which running an integrated HDFS + Condor together can be more powerful than running HDFS and Condor separately. (e.g. <span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=245\" onclick=\"get_ticket_and_populate_wrapper('245'); return false;\" title=\"Failover of HDFS file server node\">#245</a></span>)\n</li><li>Once Condor File Transfer plugins are working (<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=241\" onclick=\"get_ticket_and_populate_wrapper('241'); return false;\" title=\"File Transfer plugins\">#241</a></span>), write a HDFS plugin for the file transfer object</li></ol>\n</blockquote>", "remarks": "<blockquote>\n<em>2009-Mar-31 13:28:48 by dhruba:</em> <br/>\n\n1. is there a condor UI page that can be integrated with the HDFS UI?\n\n<p>2. HDFS has APIs to expose the names of machines that have a replica of blocks in a hdfs file. Can this be exposed through any Condor resource advertisement API? (or something similar to the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=FileTrasferPlugin\" title=\"File Trasfer Plugin\">FileTrasferPlugin</a></span> that exposes various properties associated with the File URI)\n</p><hr/>\n<em>2010-Oct-20 15:59:08 by jfrey:</em> <br/>\n\nBulk change of target version from v070504 to v070505 using ./ticket-target-mover.\n<hr/>\n<em>2011-Jan-27 14:21:33 by danb:</em> <br/>\n\nBulk change of target version from v070505 to v070506 using ./ticket-target-mover.\n<hr/>\n<em>2011-Feb-01 14:49:30 by tannenba:</em> <br/>\n\nBulk change of target version from v070506 to NULL using ./ticket-target-mover.</blockquote>", "derived_tickets": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=7\" onclick=\"get_ticket_and_populate_wrapper('7'); return false;\" title=\"Run HDFS services as Condor daemons\">#7</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nRun HDFS services as Condor daemons</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=124\" onclick=\"get_ticket_and_populate_wrapper('124'); return false;\" title=\"Perform some HDFS testing\">#124</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nPerform some HDFS testing</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=245\" onclick=\"get_ticket_and_populate_wrapper('245'); return false;\" title=\"Failover of HDFS file server node\">#245</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nFailover of HDFS file server node</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">\n<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span></td>\n<td align=\"center\" valign=\"center\" width=\"30\">\n<span class=\"icon ptr1\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\">\nCondor HDFS daemons should publish info to the collector</td></tr>\n</tbody></table>", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2021-Apr-06 11:39</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/6e98ca9aa70dcf89746ee7978fad2ae9bcf202ca\">[62874]</a></span>: Merged <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/8612fe31ed1e9417e3aa9d1d0848a0263d088dc0\">[62873]</a></span>, Merge pull request <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span> from jasoncpatton/remove-json-token Add option to local credmon to (not) write access tokens as JSON (HTCONDOR-367) Committer: <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=GitHub\" title=\"Git Hub\">GitHub</a></span>  (By Derek Weitzel )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-09 20:12</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/a7abbc32ba0ba0ce6bb2242feddb0b23b7d1ed88\">[46489]</a></span>: Merged <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/66736919ede7bb869c62058e206db5c3ab6e9eec\">[46483]</a></span>, <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/a85c1b6aa9d5d3e671cd88cd91cb961ca6c23be9\">[46484]</a></span>, <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/56fa151e090d2c1790973b236eba145028f20f7a\">[46485]</a></span>, <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/3d3e2c9ef72dee783c14e71a0c843c9204874a31\">[46486]</a></span>, <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/f96e2f0c19b398696a01b8f9a47e309b4a4c93e1\">[46487]</a></span>, <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/555e84cb004d8ba5ec49cee0b91a143d021b1483\">[46488]</a></span>, Merge pull request <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span> from zhangzhehust/network_namespaces Unittest for Lark Code &amp; Implementation of invoking network policy script using Hook mechanism (By Brian Bockelman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-19 17:02</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/ce4f0326fe479c5043ee69faed924a920c17f934\">[15408]</a></span>: Added recursive copy target for installing hadoop jars under libexec. (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-19 15:26</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/204cd45e74aea1be8fe87e75bbfc7f2e17d918ee\">[15402]</a></span>: Added an extra statement to remove previously installed hdfs folder under exteranls_install_dir (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-19 15:19</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/d3fcf95b722bcea28122af8fe6c8dfa140ef9974\">[15401]</a></span>: Added hadoop software as an external. (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-14 12:25</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/3ff13e466560b7395ec7fb317d76576794fc9455\">[15347]</a></span>: Log files created by log4j of HDFS goes under a subdir under log folder. (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) This avoids exposing of log directory.  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-14 12:04</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/04c47c7f96235ea132ba648b89f2a7fe6e0ce259\">[15345]</a></span>: Added example configuration file for HDFS daemon. Removed an old README file. (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-11 16:02</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/25329c9306a6b04a408f21753f6c4f9898cc353f\">[15301]</a></span>: Merge of hadoop code from V7_hadoop-branch including Visual Studios project file for condor_hdfs (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Aug-11 13:21</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/f693701c300c7739923528e7f6558a8d45ccc5f4\">[15297]</a></span>: Added a param to specify hadoop's log4j debug string (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jul-24 12:57</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/506b1de453c13ce4734ad8da3daae91beb855bb8\">[15152]</a></span>: Fix: Pipe redirection passed to Create_Process had missing entries for stderr/stdin. (related <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jul-16 13:01</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/5b65f8ef53f009e25bce2138f8f3d943f01ad0d0\">[15105]</a></span>: Use libexec as default location for hadoop jar file. Use condor's log dir for site.xml file (related <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jul-08 11:10</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/6ab1078dc936e573c56378d9ef7fdd816b8b991d\">[15037]</a></span>: Added ability to run secondary namenode (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>). May be helpful in doing (<span class=\"ticket\"><a class=\"new\" href=\"/wiki-archive/tickets/?ticket=245\" onclick=\"get_ticket_and_populate_wrapper('245'); return false;\" title=\"Failover of HDFS file server node\">#245</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Jun-03 14:35</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/d039ff9fe3aa3cd4196d5a665830651a1bf06859\">[14828]</a></span>: Handle data types when publishing <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> (<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>) in hdfs daemon (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>).  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 19:41</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/9ec60142b0bde2034e33fb28bb933958d63a977c\">[14755]</a></span>: Merged <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/e8075d6852a4fd5316fe93d28dfdaac0455ebe28\">[14754]</a></span>, Merge branch (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) Merge branch 'V7_3-hadoop-branch'  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-May-22 19:39</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/e8075d6852a4fd5316fe93d28dfdaac0455ebe28\">[14754]</a></span>: (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>) Cleanly handled termination code from hadoop process. A basic substrate to publish <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ClassAds\" title=\"Class Ads\">ClassAds</a></span> from Hadoop (<span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=363\" onclick=\"get_ticket_and_populate_wrapper('363'); return false;\" title=\"Condor HDFS daemons should publish info to the collector\">#363</a></span>). This commit also handles upgrading hadoop jar files to a newer version.  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Mar-20 13:45</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/78105470ec0c90e7eae60907df017aadf60770a0\">[14270]</a></span>: Merged <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/65b3df904fd7edd7100264e7c60bb08d74960a25\">[14216]</a></span>, Merge branch 'V7_3-hadoop-branch' (<span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>)  (By faisal )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2009-Mar-11 15:26</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/65b3df904fd7edd7100264e7c60bb08d74960a25\">[14216]</a></span>: Initial revision of hadoop file system daemon (see <span class=\"ticket\"><a class=\"active\" href=\"/wiki-archive/tickets/?ticket=4\" onclick=\"get_ticket_and_populate_wrapper('4'); return false;\" title=\"Integrate Condor with the Hadoop File System\">#4</a></span>). Code reviewed by Greg Quinn.  (By faisal )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2012-Oct-16 13:10", "status": "active", "created": "2009-Jan-13 13:39", "fixed_version": "2009-Jan-13 13:39", "broken_version": "", "priority": "3", "subsystem": "Unknown", "assigned_to": "ilikhan", "derived_from": "", "creator": "gthain", "rust": "", "customer_group": "other", "visibility": "public", "notify": "gthain@cs.wisc.edu,tannenba@cs.wisc.edu", "due_date": "PARENT"}