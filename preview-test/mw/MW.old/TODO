MW TODO List
------------

Jeff recently added a couple and categorized them.
Also, Mike had a number of things he wanted to add to the TODO list.
( I don't think he's done this yet).


MWNiceUser
----------
-- A "max_time" option.    :-)

-- Be able to "release" workers if we don't need them anymore

-- Be able to make host requests with a lower priority.


MWMiscellaneous
---------------
-- I'd like to be able to "get" the current task key function (address), so I 
   could set it, perform some actions, and then set it back to what it was 
   before.

   (Jeff note -- I can't remember why I wanted this now).  :-(

-- Return values from the worker's virtual functions?

-- Probably many of the constants and such should be put in a
   namespace to avoid conflicts.


MWStatistics
------------

-- MW should keep some statistics about the level of "congestion" at
   the master.  Max length of PVM message queue?  Others?  Total bytes
   packed/unpacked?  The computer science types can suggest things here.

   Perhaps we can call gettimeofday() before and after pvm_recv()...

-- Pretty picture output.  Either SLOG or the Wisconcin variation thereof.
   See MWWorkerID::lprintf().


MWList
------

   -- We're going with the templated link list idea.  In addition...

   -- Keep track of the largest the task pool ever was.

   -- What if I want access to the tasks in my task list.
      For example, I may get a "result" back that says, you no longer
      need to do any tasks with property "A".  There's no good way to
      implement this in MW right now.

   -- Need to make the whole structure object oriented, so that 
      users won't have to write dummy mains.

   -- Need we completely mask RMC from application??????

MWMajorProjects
---------------
-- Intelligent (or user guided) task scheduling.

-- Let MW support "data parallel" jobs in a nice fashion.

-- Port MW to Globus and other CommRM software, like a thread based
   one for SMPs.


MWBugs
------

1) (Condor-PVM) -- Why do we hang in pvm_exit() sometimes?      

2) Can we figure out why the data intensive jobs (read Jeff's big
   jobs) crash with "broken pipe" error messages?

3) MW-File cannot handle NaN on all archs.
 
   It was a while ago, so I don't even know if I could reproduce it.

4) MW-File has to care of which arch to submit. There are two specs to set
	target_num_workers()


MWUseIt
-------
1) More people need to start using MW.  Especially if we could find
some users in the non-optimization community.  

2) I'd also like to try some super-scalability study where we got a
   few hundred workers.  

  -- If Condor/PVM was ported to NT, we could run MW jobs there too.
     Or maybe "NT"ize our file based jobs once we get those running.

  -- "Personal condor" and Glide in as a means to get more resources
