12/01/14 10:21:56 ******************************************************
12/01/14 10:21:56 ** condor_scheduniv_exec.2.0 (CONDOR_DAGMAN) STARTING UP
12/01/14 10:21:56 ** C:\condor\bin\condor_dagman.exe
12/01/14 10:21:56 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
12/01/14 10:21:56 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
12/01/14 10:21:56 ** $CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $
12/01/14 10:21:56 ** $CondorPlatform: x86_64_Windows7 $
12/01/14 10:21:56 ** PID = 114752
12/01/14 10:21:56 ** Log last touched time unavailable (No such file or directory)
12/01/14 10:21:56 ******************************************************
12/01/14 10:21:56 Using config source: c:\condor\condor_config
12/01/14 10:21:56 Using local config sources: 
12/01/14 10:21:56    C:\condor\condor_config.local
12/01/14 10:21:56 config Macros = 51, Sorted = 50, StringBytes = 1227, TablesBytes = 1452
12/01/14 10:21:56 CLASSAD_CACHING is OFF
12/01/14 10:21:56 Daemon Log is logging: D_ALWAYS D_ERROR
12/01/14 10:21:56 DaemonCore: command socket at <128.105.34.183:54271>
12/01/14 10:21:56 DaemonCore: private command socket at <128.105.34.183:54271>
12/01/14 10:21:56 Using DAGMan config file: C:\condor_tests\job_dagman_abort-B.cfg
12/01/14 10:21:56 DAGMAN_USE_STRICT setting: 1
12/01/14 10:21:56 DAGMAN_VERBOSITY setting: 3
12/01/14 10:21:56 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
12/01/14 10:21:56 DAGMAN_DEBUG_CACHE_ENABLE setting: False
12/01/14 10:21:56 DAGMAN_SUBMIT_DELAY setting: 0
12/01/14 10:21:56 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
12/01/14 10:21:56 DAGMAN_STARTUP_CYCLE_DETECT setting: False
12/01/14 10:21:56 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
12/01/14 10:21:56 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
12/01/14 10:21:56 DAGMAN_DEFAULT_PRIORITY setting: 0
12/01/14 10:21:56 DAGMAN_ALWAYS_USE_NODE_LOG setting: True
12/01/14 10:21:56 DAGMAN_SUPPRESS_NOTIFICATION setting: True
12/01/14 10:21:56 allow_events (DAGMAN_IGNORE_DUPLICATE_JOB_EXECUTION, DAGMAN_ALLOW_EVENTS) setting: 114
12/01/14 10:21:56 DAGMAN_RETRY_SUBMIT_FIRST setting: True
12/01/14 10:21:56 DAGMAN_RETRY_NODE_FIRST setting: False
12/01/14 10:21:56 DAGMAN_MAX_JOBS_IDLE setting: 0
12/01/14 10:21:56 DAGMAN_MAX_JOBS_SUBMITTED setting: 1
12/01/14 10:21:56 DAGMAN_MAX_PRE_SCRIPTS setting: 0
12/01/14 10:21:56 DAGMAN_MAX_POST_SCRIPTS setting: 0
12/01/14 10:21:56 DAGMAN_ALLOW_LOG_ERROR setting: False
12/01/14 10:21:56 DAGMAN_MUNGE_NODE_NAMES setting: True
12/01/14 10:21:56 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
12/01/14 10:21:56 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
12/01/14 10:21:56 DAGMAN_ALWAYS_RUN_POST setting: True
12/01/14 10:21:56 DAGMAN_ABORT_DUPLICATES setting: True
12/01/14 10:21:56 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
12/01/14 10:21:56 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
12/01/14 10:21:56 DAGMAN_AUTO_RESCUE setting: True
12/01/14 10:21:56 DAGMAN_MAX_RESCUE_NUM setting: 100
12/01/14 10:21:56 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
12/01/14 10:21:56 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
12/01/14 10:21:56 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
12/01/14 10:21:56 DAGMAN_MAX_JOB_HOLDS setting: 100
12/01/14 10:21:56 DAGMAN_HOLD_CLAIM_TIME setting: 20
12/01/14 10:21:56 ALL_DEBUG setting: 
12/01/14 10:21:56 DAGMAN_DEBUG setting: 
12/01/14 10:21:56 argv[0] == "condor_scheduniv_exec.2.0"
12/01/14 10:21:56 argv[1] == "-Lockfile"
12/01/14 10:21:56 argv[2] == "job_dagman_abort-B.dag.lock"
12/01/14 10:21:56 argv[3] == "-AutoRescue"
12/01/14 10:21:56 argv[4] == "1"
12/01/14 10:21:56 argv[5] == "-DoRescueFrom"
12/01/14 10:21:56 argv[6] == "0"
12/01/14 10:21:56 argv[7] == "-Dag"
12/01/14 10:21:56 argv[8] == "job_dagman_abort-B.dag"
12/01/14 10:21:56 argv[9] == "-Suppress_notification"
12/01/14 10:21:56 argv[10] == "-CsdVersion"
12/01/14 10:21:56 argv[11] == "$CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $"
12/01/14 10:21:56 argv[12] == "-Verbose"
12/01/14 10:21:56 argv[13] == "-Force"
12/01/14 10:21:56 argv[14] == "-Notification"
12/01/14 10:21:56 argv[15] == "never"
12/01/14 10:21:56 argv[16] == "-Dagman"
12/01/14 10:21:56 argv[17] == "C:\condor\bin\condor_dagman.exe"
12/01/14 10:21:56 Default node log file is: <C:\condor_tests\./job_dagman_abort-B.dag.nodes.log>
12/01/14 10:21:56 DAG Lockfile will be written to job_dagman_abort-B.dag.lock
12/01/14 10:21:56 DAG Input file is job_dagman_abort-B.dag
12/01/14 10:21:56 Ignoring value of DAGMAN_LOG_ON_NFS_IS_ERROR.
12/01/14 10:21:56 Parsing 1 dagfiles
12/01/14 10:21:56 Parsing job_dagman_abort-B.dag ...
12/01/14 10:21:56 Dag contains 4 total jobs
12/01/14 10:21:56 Sleeping for 12 seconds to ensure ProcessId uniqueness
12/01/14 10:22:08 Warning: ProcessId not confirmed unique
12/01/14 10:22:08 Bootstrapping...
12/01/14 10:22:08 Number of pre-completed nodes: 0
12/01/14 10:22:08 Of 4 nodes total:
12/01/14 10:22:08  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:22:08   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:22:08     0       0        0       0       1          3        0
12/01/14 10:22:08 0 job proc(s) currently held
12/01/14 10:22:08 Registering condor_event_timer...
12/01/14 10:22:09 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:22:09 MultiLogFiles: truncating log file C:\condor_tests\./job_dagman_abort-B.dag.nodes.log
12/01/14 10:22:09 Submitting Condor Node A job(s)...
12/01/14 10:22:09 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:09 From submit: Submitting job(s)
12/01/14 10:22:09 From submit: ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:09 failed while reading from pipe.
12/01/14 10:22:09 Read so far: Submitting job(s)ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:09 ERROR: submit attempt failed
12/01/14 10:22:09 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:09 Job submit try 1/6 failed, will try again in >= 1 second.
12/01/14 10:22:09 Of 4 nodes total:
12/01/14 10:22:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:22:09   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:22:09     0       0        0       0       1          3        0
12/01/14 10:22:09 0 job proc(s) currently held
12/01/14 10:22:14 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:22:14 Submitting Condor Node A job(s)...
12/01/14 10:22:14 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:14 From submit: Submitting job(s)
12/01/14 10:22:14 From submit: ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:14 failed while reading from pipe.
12/01/14 10:22:14 Read so far: Submitting job(s)ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:14 ERROR: submit attempt failed
12/01/14 10:22:14 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:14 Job submit try 2/6 failed, will try again in >= 2 seconds.
12/01/14 10:22:19 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:22:19 Submitting Condor Node A job(s)...
12/01/14 10:22:19 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:19 From submit: Submitting job(s)
12/01/14 10:22:19 From submit: ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:19 failed while reading from pipe.
12/01/14 10:22:19 Read so far: Submitting job(s)ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:19 ERROR: submit attempt failed
12/01/14 10:22:19 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:19 Job submit try 3/6 failed, will try again in >= 4 seconds.
12/01/14 10:22:24 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:22:24 Submitting Condor Node A job(s)...
12/01/14 10:22:24 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:24 From submit: Submitting job(s)
12/01/14 10:22:24 From submit: ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:24 failed while reading from pipe.
12/01/14 10:22:24 Read so far: Submitting job(s)ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:24 ERROR: submit attempt failed
12/01/14 10:22:24 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:24 Job submit try 4/6 failed, will try again in >= 8 seconds.
12/01/14 10:22:35 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:22:35 Submitting Condor Node A job(s)...
12/01/14 10:22:35 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:35 From submit: Submitting job(s)
12/01/14 10:22:35 From submit: ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:35 failed while reading from pipe.
12/01/14 10:22:35 Read so far: Submitting job(s)ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:35 ERROR: submit attempt failed
12/01/14 10:22:35 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:35 Job submit try 5/6 failed, will try again in >= 16 seconds.
12/01/14 10:22:52 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:22:52 Submitting Condor Node A job(s)...
12/01/14 10:22:52 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:52 From submit: Submitting job(s)
12/01/14 10:22:52 From submit: ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:52 failed while reading from pipe.
12/01/14 10:22:52 Read so far: Submitting job(s)ERROR: Executable file /bin/echo does not exist
12/01/14 10:22:52 ERROR: submit attempt failed
12/01/14 10:22:52 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '2 -a DAGManJobId' '=' '2 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:22:52 Job submit failed after 6 tries.
12/01/14 10:22:52 Shortcutting node A retries because of submit failure(s)
12/01/14 10:22:52 Of 4 nodes total:
12/01/14 10:22:52  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:22:52   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:22:52     0       0        0       0       0          3        1
12/01/14 10:22:52 0 job proc(s) currently held
12/01/14 10:22:52 Aborting DAG...
12/01/14 10:22:52 Writing Rescue DAG to job_dagman_abort-B.dag.rescue001...
12/01/14 10:22:52 Note: 0 total job deferrals because of -MaxJobs limit (1)
12/01/14 10:22:52 Note: 0 total job deferrals because of -MaxIdle limit (0)
12/01/14 10:22:52 Note: 0 total job deferrals because of node category throttles
12/01/14 10:22:52 Note: 0 total PRE script deferrals because of -MaxPre limit (0)
12/01/14 10:22:52 Note: 0 total POST script deferrals because of -MaxPost limit (0)
12/01/14 10:22:52 Of 4 nodes total:
12/01/14 10:22:52  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:22:52   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:22:52     0       0        0       0       0          3        1
12/01/14 10:22:52 0 job proc(s) currently held
12/01/14 10:22:52 Wrote metrics file job_dagman_abort-B.dag.metrics.
12/01/14 10:22:52 Metrics reporting is not available on this platform.
12/01/14 10:22:52 **** condor_scheduniv_exec.2.0 (condor_DAGMAN) pid 114752 EXITING WITH STATUS 1
12/01/14 10:28:27 ******************************************************
12/01/14 10:28:27 ** condor_scheduniv_exec.9.0 (CONDOR_DAGMAN) STARTING UP
12/01/14 10:28:27 ** C:\condor\bin\condor_dagman.exe
12/01/14 10:28:27 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
12/01/14 10:28:27 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
12/01/14 10:28:27 ** $CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $
12/01/14 10:28:27 ** $CondorPlatform: x86_64_Windows7 $
12/01/14 10:28:27 ** PID = 155628
12/01/14 10:28:27 ** Log last touched 12/1 10:22:52
12/01/14 10:28:27 ******************************************************
12/01/14 10:28:27 Using config source: c:\condor\condor_config
12/01/14 10:28:27 Using local config sources: 
12/01/14 10:28:27    C:\condor\condor_config.local
12/01/14 10:28:27 config Macros = 51, Sorted = 50, StringBytes = 1227, TablesBytes = 1452
12/01/14 10:28:27 CLASSAD_CACHING is OFF
12/01/14 10:28:27 Daemon Log is logging: D_ALWAYS D_ERROR
12/01/14 10:28:27 DaemonCore: command socket at <128.105.34.183:54407>
12/01/14 10:28:27 DaemonCore: private command socket at <128.105.34.183:54407>
12/01/14 10:28:27 Using DAGMan config file: C:\condor_tests\job_dagman_abort-B.cfg
12/01/14 10:28:27 DAGMAN_USE_STRICT setting: 1
12/01/14 10:28:27 DAGMAN_VERBOSITY setting: 3
12/01/14 10:28:27 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
12/01/14 10:28:27 DAGMAN_DEBUG_CACHE_ENABLE setting: False
12/01/14 10:28:27 DAGMAN_SUBMIT_DELAY setting: 0
12/01/14 10:28:27 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
12/01/14 10:28:27 DAGMAN_STARTUP_CYCLE_DETECT setting: False
12/01/14 10:28:27 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
12/01/14 10:28:27 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
12/01/14 10:28:27 DAGMAN_DEFAULT_PRIORITY setting: 0
12/01/14 10:28:27 DAGMAN_ALWAYS_USE_NODE_LOG setting: True
12/01/14 10:28:27 DAGMAN_SUPPRESS_NOTIFICATION setting: True
12/01/14 10:28:27 allow_events (DAGMAN_IGNORE_DUPLICATE_JOB_EXECUTION, DAGMAN_ALLOW_EVENTS) setting: 114
12/01/14 10:28:27 DAGMAN_RETRY_SUBMIT_FIRST setting: True
12/01/14 10:28:27 DAGMAN_RETRY_NODE_FIRST setting: False
12/01/14 10:28:27 DAGMAN_MAX_JOBS_IDLE setting: 0
12/01/14 10:28:27 DAGMAN_MAX_JOBS_SUBMITTED setting: 1
12/01/14 10:28:27 DAGMAN_MAX_PRE_SCRIPTS setting: 0
12/01/14 10:28:27 DAGMAN_MAX_POST_SCRIPTS setting: 0
12/01/14 10:28:27 DAGMAN_ALLOW_LOG_ERROR setting: False
12/01/14 10:28:27 DAGMAN_MUNGE_NODE_NAMES setting: True
12/01/14 10:28:27 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
12/01/14 10:28:27 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
12/01/14 10:28:27 DAGMAN_ALWAYS_RUN_POST setting: True
12/01/14 10:28:27 DAGMAN_ABORT_DUPLICATES setting: True
12/01/14 10:28:27 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
12/01/14 10:28:27 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
12/01/14 10:28:27 DAGMAN_AUTO_RESCUE setting: True
12/01/14 10:28:27 DAGMAN_MAX_RESCUE_NUM setting: 100
12/01/14 10:28:27 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
12/01/14 10:28:27 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
12/01/14 10:28:27 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
12/01/14 10:28:27 DAGMAN_MAX_JOB_HOLDS setting: 100
12/01/14 10:28:27 DAGMAN_HOLD_CLAIM_TIME setting: 20
12/01/14 10:28:27 ALL_DEBUG setting: 
12/01/14 10:28:27 DAGMAN_DEBUG setting: 
12/01/14 10:28:27 argv[0] == "condor_scheduniv_exec.9.0"
12/01/14 10:28:27 argv[1] == "-Lockfile"
12/01/14 10:28:27 argv[2] == "job_dagman_abort-B.dag.lock"
12/01/14 10:28:27 argv[3] == "-AutoRescue"
12/01/14 10:28:27 argv[4] == "1"
12/01/14 10:28:27 argv[5] == "-DoRescueFrom"
12/01/14 10:28:27 argv[6] == "0"
12/01/14 10:28:27 argv[7] == "-Dag"
12/01/14 10:28:27 argv[8] == "job_dagman_abort-B.dag"
12/01/14 10:28:27 argv[9] == "-Suppress_notification"
12/01/14 10:28:27 argv[10] == "-CsdVersion"
12/01/14 10:28:27 argv[11] == "$CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $"
12/01/14 10:28:27 argv[12] == "-Verbose"
12/01/14 10:28:27 argv[13] == "-Force"
12/01/14 10:28:27 argv[14] == "-Notification"
12/01/14 10:28:27 argv[15] == "never"
12/01/14 10:28:27 argv[16] == "-Dagman"
12/01/14 10:28:27 argv[17] == "C:\condor\bin\condor_dagman.exe"
12/01/14 10:28:27 Default node log file is: <C:\condor_tests\./job_dagman_abort-B.dag.nodes.log>
12/01/14 10:28:27 DAG Lockfile will be written to job_dagman_abort-B.dag.lock
12/01/14 10:28:27 DAG Input file is job_dagman_abort-B.dag
12/01/14 10:28:27 Ignoring value of DAGMAN_LOG_ON_NFS_IS_ERROR.
12/01/14 10:28:27 Parsing 1 dagfiles
12/01/14 10:28:27 Parsing job_dagman_abort-B.dag ...
12/01/14 10:28:27 Dag contains 4 total jobs
12/01/14 10:28:27 Sleeping for 12 seconds to ensure ProcessId uniqueness
12/01/14 10:28:39 Warning: ProcessId not confirmed unique
12/01/14 10:28:39 Bootstrapping...
12/01/14 10:28:39 Number of pre-completed nodes: 0
12/01/14 10:28:39 Of 4 nodes total:
12/01/14 10:28:39  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:28:39   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:28:39     0       0        0       0       1          3        0
12/01/14 10:28:39 0 job proc(s) currently held
12/01/14 10:28:39 Registering condor_event_timer...
12/01/14 10:28:40 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:28:40 MultiLogFiles: truncating log file C:\condor_tests\./job_dagman_abort-B.dag.nodes.log
12/01/14 10:28:40 Submitting Condor Node A job(s)...
12/01/14 10:28:40 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:40 From submit: Submitting job(s)
12/01/14 10:28:40 From submit: ERROR: Executable file echo does not exist
12/01/14 10:28:40 failed while reading from pipe.
12/01/14 10:28:40 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:28:40 ERROR: submit attempt failed
12/01/14 10:28:40 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:40 Job submit try 1/6 failed, will try again in >= 1 second.
12/01/14 10:28:40 Of 4 nodes total:
12/01/14 10:28:40  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:28:40   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:28:40     0       0        0       0       1          3        0
12/01/14 10:28:40 0 job proc(s) currently held
12/01/14 10:28:45 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:28:45 Submitting Condor Node A job(s)...
12/01/14 10:28:45 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:45 From submit: Submitting job(s)
12/01/14 10:28:45 From submit: ERROR: Executable file echo does not exist
12/01/14 10:28:45 failed while reading from pipe.
12/01/14 10:28:45 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:28:45 ERROR: submit attempt failed
12/01/14 10:28:45 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:45 Job submit try 2/6 failed, will try again in >= 2 seconds.
12/01/14 10:28:50 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:28:50 Submitting Condor Node A job(s)...
12/01/14 10:28:50 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:50 From submit: Submitting job(s)
12/01/14 10:28:50 From submit: ERROR: Executable file echo does not exist
12/01/14 10:28:50 failed while reading from pipe.
12/01/14 10:28:50 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:28:50 ERROR: submit attempt failed
12/01/14 10:28:50 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:50 Job submit try 3/6 failed, will try again in >= 4 seconds.
12/01/14 10:28:55 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:28:55 Submitting Condor Node A job(s)...
12/01/14 10:28:55 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:55 From submit: Submitting job(s)
12/01/14 10:28:55 From submit: ERROR: Executable file echo does not exist
12/01/14 10:28:55 failed while reading from pipe.
12/01/14 10:28:55 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:28:55 ERROR: submit attempt failed
12/01/14 10:28:55 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:28:55 Job submit try 4/6 failed, will try again in >= 8 seconds.
12/01/14 10:29:06 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:29:06 Submitting Condor Node A job(s)...
12/01/14 10:29:06 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:29:06 From submit: Submitting job(s)
12/01/14 10:29:06 From submit: ERROR: Executable file echo does not exist
12/01/14 10:29:06 failed while reading from pipe.
12/01/14 10:29:06 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:29:06 ERROR: submit attempt failed
12/01/14 10:29:06 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:29:06 Job submit try 5/6 failed, will try again in >= 16 seconds.
12/01/14 10:29:23 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:29:23 Submitting Condor Node A job(s)...
12/01/14 10:29:23 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:29:23 From submit: Submitting job(s)
12/01/14 10:29:23 From submit: ERROR: Executable file echo does not exist
12/01/14 10:29:23 failed while reading from pipe.
12/01/14 10:29:23 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:29:23 ERROR: submit attempt failed
12/01/14 10:29:23 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '9 -a DAGManJobId' '=' '9 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:29:23 Job submit failed after 6 tries.
12/01/14 10:29:23 Shortcutting node A retries because of submit failure(s)
12/01/14 10:29:23 Of 4 nodes total:
12/01/14 10:29:23  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:29:23   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:29:23     0       0        0       0       0          3        1
12/01/14 10:29:23 0 job proc(s) currently held
12/01/14 10:29:23 Aborting DAG...
12/01/14 10:29:23 Writing Rescue DAG to job_dagman_abort-B.dag.rescue001...
12/01/14 10:29:23 Note: 0 total job deferrals because of -MaxJobs limit (1)
12/01/14 10:29:23 Note: 0 total job deferrals because of -MaxIdle limit (0)
12/01/14 10:29:23 Note: 0 total job deferrals because of node category throttles
12/01/14 10:29:23 Note: 0 total PRE script deferrals because of -MaxPre limit (0)
12/01/14 10:29:23 Note: 0 total POST script deferrals because of -MaxPost limit (0)
12/01/14 10:29:23 Of 4 nodes total:
12/01/14 10:29:23  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:29:23   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:29:23     0       0        0       0       0          3        1
12/01/14 10:29:23 0 job proc(s) currently held
12/01/14 10:29:23 Wrote metrics file job_dagman_abort-B.dag.metrics.
12/01/14 10:29:23 Metrics reporting is not available on this platform.
12/01/14 10:29:23 **** condor_scheduniv_exec.9.0 (condor_DAGMAN) pid 155628 EXITING WITH STATUS 1
12/01/14 10:56:37 ******************************************************
12/01/14 10:56:37 ** condor_scheduniv_exec.16.0 (CONDOR_DAGMAN) STARTING UP
12/01/14 10:56:37 ** C:\condor\bin\condor_dagman.exe
12/01/14 10:56:37 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
12/01/14 10:56:37 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
12/01/14 10:56:37 ** $CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $
12/01/14 10:56:37 ** $CondorPlatform: x86_64_Windows7 $
12/01/14 10:56:37 ** PID = 157416
12/01/14 10:56:37 ** Log last touched 12/1 10:29:23
12/01/14 10:56:37 ******************************************************
12/01/14 10:56:37 Using config source: c:\condor\condor_config
12/01/14 10:56:37 Using local config sources: 
12/01/14 10:56:37    C:\condor\condor_config.local
12/01/14 10:56:37 config Macros = 51, Sorted = 50, StringBytes = 1227, TablesBytes = 1452
12/01/14 10:56:37 CLASSAD_CACHING is OFF
12/01/14 10:56:37 Daemon Log is logging: D_ALWAYS D_ERROR
12/01/14 10:56:37 DaemonCore: command socket at <128.105.34.183:54869>
12/01/14 10:56:37 DaemonCore: private command socket at <128.105.34.183:54869>
12/01/14 10:56:37 Using DAGMan config file: C:\condor_tests\job_dagman_abort-B.cfg
12/01/14 10:56:37 DAGMAN_USE_STRICT setting: 1
12/01/14 10:56:37 DAGMAN_VERBOSITY setting: 3
12/01/14 10:56:37 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
12/01/14 10:56:37 DAGMAN_DEBUG_CACHE_ENABLE setting: False
12/01/14 10:56:37 DAGMAN_SUBMIT_DELAY setting: 0
12/01/14 10:56:37 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
12/01/14 10:56:37 DAGMAN_STARTUP_CYCLE_DETECT setting: False
12/01/14 10:56:37 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
12/01/14 10:56:37 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
12/01/14 10:56:37 DAGMAN_DEFAULT_PRIORITY setting: 0
12/01/14 10:56:37 DAGMAN_ALWAYS_USE_NODE_LOG setting: True
12/01/14 10:56:37 DAGMAN_SUPPRESS_NOTIFICATION setting: True
12/01/14 10:56:37 allow_events (DAGMAN_IGNORE_DUPLICATE_JOB_EXECUTION, DAGMAN_ALLOW_EVENTS) setting: 114
12/01/14 10:56:37 DAGMAN_RETRY_SUBMIT_FIRST setting: True
12/01/14 10:56:37 DAGMAN_RETRY_NODE_FIRST setting: False
12/01/14 10:56:37 DAGMAN_MAX_JOBS_IDLE setting: 0
12/01/14 10:56:37 DAGMAN_MAX_JOBS_SUBMITTED setting: 1
12/01/14 10:56:37 DAGMAN_MAX_PRE_SCRIPTS setting: 0
12/01/14 10:56:37 DAGMAN_MAX_POST_SCRIPTS setting: 0
12/01/14 10:56:37 DAGMAN_ALLOW_LOG_ERROR setting: False
12/01/14 10:56:37 DAGMAN_MUNGE_NODE_NAMES setting: True
12/01/14 10:56:37 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
12/01/14 10:56:37 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
12/01/14 10:56:37 DAGMAN_ALWAYS_RUN_POST setting: True
12/01/14 10:56:37 DAGMAN_ABORT_DUPLICATES setting: True
12/01/14 10:56:37 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
12/01/14 10:56:37 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
12/01/14 10:56:37 DAGMAN_AUTO_RESCUE setting: True
12/01/14 10:56:37 DAGMAN_MAX_RESCUE_NUM setting: 100
12/01/14 10:56:37 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
12/01/14 10:56:37 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
12/01/14 10:56:37 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
12/01/14 10:56:37 DAGMAN_MAX_JOB_HOLDS setting: 100
12/01/14 10:56:37 DAGMAN_HOLD_CLAIM_TIME setting: 20
12/01/14 10:56:37 ALL_DEBUG setting: 
12/01/14 10:56:37 DAGMAN_DEBUG setting: 
12/01/14 10:56:37 argv[0] == "condor_scheduniv_exec.16.0"
12/01/14 10:56:37 argv[1] == "-Lockfile"
12/01/14 10:56:37 argv[2] == "job_dagman_abort-B.dag.lock"
12/01/14 10:56:37 argv[3] == "-AutoRescue"
12/01/14 10:56:37 argv[4] == "1"
12/01/14 10:56:37 argv[5] == "-DoRescueFrom"
12/01/14 10:56:37 argv[6] == "0"
12/01/14 10:56:37 argv[7] == "-Dag"
12/01/14 10:56:37 argv[8] == "job_dagman_abort-B.dag"
12/01/14 10:56:37 argv[9] == "-Suppress_notification"
12/01/14 10:56:37 argv[10] == "-CsdVersion"
12/01/14 10:56:37 argv[11] == "$CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $"
12/01/14 10:56:37 argv[12] == "-Verbose"
12/01/14 10:56:37 argv[13] == "-Force"
12/01/14 10:56:37 argv[14] == "-Notification"
12/01/14 10:56:37 argv[15] == "never"
12/01/14 10:56:37 argv[16] == "-Dagman"
12/01/14 10:56:37 argv[17] == "C:\condor\bin\condor_dagman.exe"
12/01/14 10:56:37 Default node log file is: <C:\condor_tests\./job_dagman_abort-B.dag.nodes.log>
12/01/14 10:56:37 DAG Lockfile will be written to job_dagman_abort-B.dag.lock
12/01/14 10:56:37 DAG Input file is job_dagman_abort-B.dag
12/01/14 10:56:37 Ignoring value of DAGMAN_LOG_ON_NFS_IS_ERROR.
12/01/14 10:56:37 Parsing 1 dagfiles
12/01/14 10:56:37 Parsing job_dagman_abort-B.dag ...
12/01/14 10:56:37 Dag contains 4 total jobs
12/01/14 10:56:38 Sleeping for 12 seconds to ensure ProcessId uniqueness
12/01/14 10:56:50 Warning: ProcessId not confirmed unique
12/01/14 10:56:50 Bootstrapping...
12/01/14 10:56:50 Number of pre-completed nodes: 0
12/01/14 10:56:50 Of 4 nodes total:
12/01/14 10:56:50  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:56:50   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:56:50     0       0        0       0       1          3        0
12/01/14 10:56:50 0 job proc(s) currently held
12/01/14 10:56:50 Registering condor_event_timer...
12/01/14 10:56:51 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:56:51 MultiLogFiles: truncating log file C:\condor_tests\./job_dagman_abort-B.dag.nodes.log
12/01/14 10:56:51 Submitting Condor Node A job(s)...
12/01/14 10:56:51 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:56:51 From submit: Submitting job(s)
12/01/14 10:56:51 From submit: ERROR: Executable file echo does not exist
12/01/14 10:56:51 failed while reading from pipe.
12/01/14 10:56:51 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:56:51 ERROR: submit attempt failed
12/01/14 10:56:51 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:56:51 Job submit try 1/6 failed, will try again in >= 1 second.
12/01/14 10:56:51 Of 4 nodes total:
12/01/14 10:56:51  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:56:51   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:56:51     0       0        0       0       1          3        0
12/01/14 10:56:51 0 job proc(s) currently held
12/01/14 10:56:56 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:56:56 Submitting Condor Node A job(s)...
12/01/14 10:56:56 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:56:56 From submit: Submitting job(s)
12/01/14 10:56:56 From submit: ERROR: Executable file echo does not exist
12/01/14 10:56:56 failed while reading from pipe.
12/01/14 10:56:56 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:56:56 ERROR: submit attempt failed
12/01/14 10:56:56 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:56:56 Job submit try 2/6 failed, will try again in >= 2 seconds.
12/01/14 10:57:01 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:57:01 Submitting Condor Node A job(s)...
12/01/14 10:57:01 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:01 From submit: Submitting job(s)
12/01/14 10:57:01 From submit: ERROR: Executable file echo does not exist
12/01/14 10:57:01 failed while reading from pipe.
12/01/14 10:57:01 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:57:01 ERROR: submit attempt failed
12/01/14 10:57:01 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:01 Job submit try 3/6 failed, will try again in >= 4 seconds.
12/01/14 10:57:06 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:57:06 Submitting Condor Node A job(s)...
12/01/14 10:57:06 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:06 From submit: Submitting job(s)
12/01/14 10:57:06 From submit: ERROR: Executable file echo does not exist
12/01/14 10:57:06 failed while reading from pipe.
12/01/14 10:57:06 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:57:06 ERROR: submit attempt failed
12/01/14 10:57:06 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:06 Job submit try 4/6 failed, will try again in >= 8 seconds.
12/01/14 10:57:17 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:57:17 Submitting Condor Node A job(s)...
12/01/14 10:57:17 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:17 From submit: Submitting job(s)
12/01/14 10:57:17 From submit: ERROR: Executable file echo does not exist
12/01/14 10:57:17 failed while reading from pipe.
12/01/14 10:57:17 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:57:17 ERROR: submit attempt failed
12/01/14 10:57:17 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:17 Job submit try 5/6 failed, will try again in >= 16 seconds.
12/01/14 10:57:34 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 10:57:34 Submitting Condor Node A job(s)...
12/01/14 10:57:34 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:34 From submit: Submitting job(s)
12/01/14 10:57:34 From submit: ERROR: Executable file echo does not exist
12/01/14 10:57:34 failed while reading from pipe.
12/01/14 10:57:34 Read so far: Submitting job(s)ERROR: Executable file echo does not exist
12/01/14 10:57:34 ERROR: submit attempt failed
12/01/14 10:57:34 submit command was: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 10:57:34 Job submit failed after 6 tries.
12/01/14 10:57:34 Shortcutting node A retries because of submit failure(s)
12/01/14 10:57:34 Of 4 nodes total:
12/01/14 10:57:34  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:57:34   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:57:34     0       0        0       0       0          3        1
12/01/14 10:57:34 0 job proc(s) currently held
12/01/14 10:57:34 Aborting DAG...
12/01/14 10:57:34 Writing Rescue DAG to job_dagman_abort-B.dag.rescue001...
12/01/14 10:57:34 Note: 0 total job deferrals because of -MaxJobs limit (1)
12/01/14 10:57:34 Note: 0 total job deferrals because of -MaxIdle limit (0)
12/01/14 10:57:34 Note: 0 total job deferrals because of node category throttles
12/01/14 10:57:34 Note: 0 total PRE script deferrals because of -MaxPre limit (0)
12/01/14 10:57:34 Note: 0 total POST script deferrals because of -MaxPost limit (0)
12/01/14 10:57:34 Of 4 nodes total:
12/01/14 10:57:34  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 10:57:34   ===     ===      ===     ===     ===        ===      ===
12/01/14 10:57:34     0       0        0       0       0          3        1
12/01/14 10:57:34 0 job proc(s) currently held
12/01/14 10:57:34 Wrote metrics file job_dagman_abort-B.dag.metrics.
12/01/14 10:57:34 Metrics reporting is not available on this platform.
12/01/14 10:57:34 **** condor_scheduniv_exec.16.0 (condor_DAGMAN) pid 157416 EXITING WITH STATUS 1
12/01/14 11:03:25 ******************************************************
12/01/14 11:03:25 ** condor_scheduniv_exec.23.0 (CONDOR_DAGMAN) STARTING UP
12/01/14 11:03:25 ** C:\condor\bin\condor_dagman.exe
12/01/14 11:03:25 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
12/01/14 11:03:25 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
12/01/14 11:03:25 ** $CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $
12/01/14 11:03:25 ** $CondorPlatform: x86_64_Windows7 $
12/01/14 11:03:25 ** PID = 86308
12/01/14 11:03:25 ** Log last touched 12/1 10:57:34
12/01/14 11:03:25 ******************************************************
12/01/14 11:03:25 Using config source: c:\condor\condor_config
12/01/14 11:03:25 Using local config sources: 
12/01/14 11:03:25    C:\condor\condor_config.local
12/01/14 11:03:25 config Macros = 51, Sorted = 50, StringBytes = 1226, TablesBytes = 1452
12/01/14 11:03:25 CLASSAD_CACHING is OFF
12/01/14 11:03:25 Daemon Log is logging: D_ALWAYS D_ERROR
12/01/14 11:03:25 DaemonCore: command socket at <128.105.34.183:55001>
12/01/14 11:03:25 DaemonCore: private command socket at <128.105.34.183:55001>
12/01/14 11:03:25 Using DAGMan config file: C:\condor_tests\job_dagman_abort-B.cfg
12/01/14 11:03:25 DAGMAN_USE_STRICT setting: 1
12/01/14 11:03:25 DAGMAN_VERBOSITY setting: 3
12/01/14 11:03:25 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
12/01/14 11:03:25 DAGMAN_DEBUG_CACHE_ENABLE setting: False
12/01/14 11:03:25 DAGMAN_SUBMIT_DELAY setting: 0
12/01/14 11:03:25 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
12/01/14 11:03:25 DAGMAN_STARTUP_CYCLE_DETECT setting: False
12/01/14 11:03:25 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
12/01/14 11:03:25 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
12/01/14 11:03:25 DAGMAN_DEFAULT_PRIORITY setting: 0
12/01/14 11:03:25 DAGMAN_ALWAYS_USE_NODE_LOG setting: True
12/01/14 11:03:25 DAGMAN_SUPPRESS_NOTIFICATION setting: True
12/01/14 11:03:25 allow_events (DAGMAN_IGNORE_DUPLICATE_JOB_EXECUTION, DAGMAN_ALLOW_EVENTS) setting: 114
12/01/14 11:03:25 DAGMAN_RETRY_SUBMIT_FIRST setting: True
12/01/14 11:03:25 DAGMAN_RETRY_NODE_FIRST setting: False
12/01/14 11:03:25 DAGMAN_MAX_JOBS_IDLE setting: 0
12/01/14 11:03:25 DAGMAN_MAX_JOBS_SUBMITTED setting: 1
12/01/14 11:03:25 DAGMAN_MAX_PRE_SCRIPTS setting: 0
12/01/14 11:03:25 DAGMAN_MAX_POST_SCRIPTS setting: 0
12/01/14 11:03:25 DAGMAN_ALLOW_LOG_ERROR setting: False
12/01/14 11:03:25 DAGMAN_MUNGE_NODE_NAMES setting: True
12/01/14 11:03:25 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
12/01/14 11:03:25 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
12/01/14 11:03:25 DAGMAN_ALWAYS_RUN_POST setting: True
12/01/14 11:03:25 DAGMAN_ABORT_DUPLICATES setting: True
12/01/14 11:03:25 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
12/01/14 11:03:25 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
12/01/14 11:03:25 DAGMAN_AUTO_RESCUE setting: True
12/01/14 11:03:25 DAGMAN_MAX_RESCUE_NUM setting: 100
12/01/14 11:03:25 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
12/01/14 11:03:25 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
12/01/14 11:03:25 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
12/01/14 11:03:25 DAGMAN_MAX_JOB_HOLDS setting: 100
12/01/14 11:03:25 DAGMAN_HOLD_CLAIM_TIME setting: 20
12/01/14 11:03:25 ALL_DEBUG setting: 
12/01/14 11:03:25 DAGMAN_DEBUG setting: 
12/01/14 11:03:25 argv[0] == "condor_scheduniv_exec.23.0"
12/01/14 11:03:25 argv[1] == "-Lockfile"
12/01/14 11:03:25 argv[2] == "job_dagman_abort-B.dag.lock"
12/01/14 11:03:25 argv[3] == "-AutoRescue"
12/01/14 11:03:25 argv[4] == "1"
12/01/14 11:03:25 argv[5] == "-DoRescueFrom"
12/01/14 11:03:25 argv[6] == "0"
12/01/14 11:03:25 argv[7] == "-Dag"
12/01/14 11:03:25 argv[8] == "job_dagman_abort-B.dag"
12/01/14 11:03:25 argv[9] == "-Suppress_notification"
12/01/14 11:03:25 argv[10] == "-CsdVersion"
12/01/14 11:03:25 argv[11] == "$CondorVersion: 8.2.3 Aug 08 2014 BuildID: 266162 PRE-RELEASE-UWCS $"
12/01/14 11:03:25 argv[12] == "-Verbose"
12/01/14 11:03:25 argv[13] == "-Force"
12/01/14 11:03:25 argv[14] == "-Notification"
12/01/14 11:03:25 argv[15] == "never"
12/01/14 11:03:25 argv[16] == "-Dagman"
12/01/14 11:03:25 argv[17] == "C:\condor\bin\condor_dagman.exe"
12/01/14 11:03:25 Default node log file is: <C:\condor_tests\./job_dagman_abort-B.dag.nodes.log>
12/01/14 11:03:25 DAG Lockfile will be written to job_dagman_abort-B.dag.lock
12/01/14 11:03:25 DAG Input file is job_dagman_abort-B.dag
12/01/14 11:03:25 Ignoring value of DAGMAN_LOG_ON_NFS_IS_ERROR.
12/01/14 11:03:25 Parsing 1 dagfiles
12/01/14 11:03:25 Parsing job_dagman_abort-B.dag ...
12/01/14 11:03:25 Dag contains 4 total jobs
12/01/14 11:03:26 Sleeping for 12 seconds to ensure ProcessId uniqueness
12/01/14 11:03:38 Warning: ProcessId not confirmed unique
12/01/14 11:03:38 Bootstrapping...
12/01/14 11:03:38 Number of pre-completed nodes: 0
12/01/14 11:03:38 Of 4 nodes total:
12/01/14 11:03:38  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:03:38   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:03:38     0       0        0       0       1          3        0
12/01/14 11:03:38 0 job proc(s) currently held
12/01/14 11:03:38 Registering condor_event_timer...
12/01/14 11:03:39 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node A); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 11:03:39 MultiLogFiles: truncating log file C:\condor_tests\./job_dagman_abort-B.dag.nodes.log
12/01/14 11:03:39 Submitting Condor Node A job(s)...
12/01/14 11:03:39 submitting: condor_submit -a dag_node_name' '=' 'A -a +DAGManJobId' '=' '23 -a DAGManJobId' '=' '23 -a submit_event_notes' '=' 'DAG' 'Node:' 'A -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'A -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 11:03:39 From submit: Submitting job(s).
12/01/14 11:03:39 From submit: 1 job(s) submitted to cluster 24.
12/01/14 11:03:39 	assigned Condor ID (24.0.0)
12/01/14 11:03:39 Just submitted 1 job this cycle...
12/01/14 11:03:39 Currently monitoring 1 Condor log file(s)
12/01/14 11:03:39 Reassigning the id of job A from (24.0.0) to (24.0.0)
12/01/14 11:03:39 Event: ULOG_SUBMIT for Condor Node A (24.0.0)
12/01/14 11:03:39 Number of idle job procs: 1
12/01/14 11:03:39 Of 4 nodes total:
12/01/14 11:03:39  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:03:39   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:03:39     0       0        1       0       0          3        0
12/01/14 11:03:39 0 job proc(s) currently held
12/01/14 11:03:44 Currently monitoring 1 Condor log file(s)
12/01/14 11:03:44 Event: ULOG_EXECUTE for Condor Node A (24.0.0)
12/01/14 11:03:44 Number of idle job procs: 0
12/01/14 11:03:44 Event: ULOG_JOB_TERMINATED for Condor Node A (24.0.0)
12/01/14 11:03:44 Number of idle job procs: 0
12/01/14 11:03:44 Node A job proc (24.0.0) completed successfully.
12/01/14 11:03:44 Node A job completed
12/01/14 11:03:44 Of 4 nodes total:
12/01/14 11:03:44  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:03:44   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:03:44     1       0        0       0       1          2        0
12/01/14 11:03:44 0 job proc(s) currently held
12/01/14 11:03:49 Unable to get log file from submit file job_dagman_abort-B-node-succeed.cmd (node B); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 11:03:49 Submitting Condor Node B job(s)...
12/01/14 11:03:49 submitting: condor_submit -a dag_node_name' '=' 'B -a +DAGManJobId' '=' '23 -a DAGManJobId' '=' '23 -a submit_event_notes' '=' 'DAG' 'Node:' 'B -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'B -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"A" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never job_dagman_abort-B-node-succeed.cmd
12/01/14 11:03:49 From submit: Submitting job(s).
12/01/14 11:03:49 From submit: 1 job(s) submitted to cluster 25.
12/01/14 11:03:49 	assigned Condor ID (25.0.0)
12/01/14 11:03:49 Just submitted 1 job this cycle...
12/01/14 11:03:49 Currently monitoring 1 Condor log file(s)
12/01/14 11:03:49 Reassigning the id of job B from (25.0.0) to (25.0.0)
12/01/14 11:03:49 Event: ULOG_SUBMIT for Condor Node B (25.0.0)
12/01/14 11:03:49 Number of idle job procs: 1
12/01/14 11:03:49 Of 4 nodes total:
12/01/14 11:03:49  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:03:49   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:03:49     1       0        1       0       0          2        0
12/01/14 11:03:49 0 job proc(s) currently held
12/01/14 11:03:54 Currently monitoring 1 Condor log file(s)
12/01/14 11:03:54 Event: ULOG_EXECUTE for Condor Node B (25.0.0)
12/01/14 11:03:54 Number of idle job procs: 0
12/01/14 11:03:54 Event: ULOG_JOB_TERMINATED for Condor Node B (25.0.0)
12/01/14 11:03:54 Number of idle job procs: 0
12/01/14 11:03:54 Node B job proc (25.0.0) completed successfully.
12/01/14 11:03:54 Node B job completed
12/01/14 11:03:54 Of 4 nodes total:
12/01/14 11:03:54  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:03:54   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:03:54     2       0        0       0       2          0        0
12/01/14 11:03:54 0 job proc(s) currently held
12/01/14 11:03:59 Unable to get log file from submit file job_dagman_abort-B-node-fail.cmd (node C); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 11:03:59 Submitting Condor Node C job(s)...
12/01/14 11:03:59 submitting: condor_submit -a dag_node_name' '=' 'C -a +DAGManJobId' '=' '23 -a DAGManJobId' '=' '23 -a submit_event_notes' '=' 'DAG' 'Node:' 'C -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'C -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"B" -a notification' '=' 'never job_dagman_abort-B-node-fail.cmd
12/01/14 11:03:59 From submit: Submitting job(s).
12/01/14 11:03:59 From submit: 1 job(s) submitted to cluster 26.
12/01/14 11:03:59 	assigned Condor ID (26.0.0)
12/01/14 11:03:59 Just submitted 1 job this cycle...
12/01/14 11:03:59 Currently monitoring 1 Condor log file(s)
12/01/14 11:03:59 Reassigning the id of job C from (26.0.0) to (26.0.0)
12/01/14 11:03:59 Event: ULOG_SUBMIT for Condor Node C (26.0.0)
12/01/14 11:03:59 Number of idle job procs: 1
12/01/14 11:03:59 Of 4 nodes total:
12/01/14 11:03:59  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:03:59   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:03:59     2       0        1       0       1          0        0
12/01/14 11:03:59 0 job proc(s) currently held
12/01/14 11:03:59 Note: 1 total job deferrals because of -MaxJobs limit (1)
12/01/14 11:04:04 Currently monitoring 1 Condor log file(s)
12/01/14 11:04:04 Event: ULOG_EXECUTE for Condor Node C (26.0.0)
12/01/14 11:04:04 Number of idle job procs: 0
12/01/14 11:04:04 Event: ULOG_JOB_TERMINATED for Condor Node C (26.0.0)
12/01/14 11:04:04 Number of idle job procs: 0
12/01/14 11:04:04 Node C job proc (26.0.0) failed with status 5.
12/01/14 11:04:04 Node C job completed
12/01/14 11:04:04 Unable to get log file from submit file job_dagman_abort-B-node-fail.cmd (node C); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 11:04:04 Running POST script of Node C...
12/01/14 11:04:04 Of 4 nodes total:
12/01/14 11:04:04  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:04:04   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:04:04     2       0        0       1       1          0        0
12/01/14 11:04:04 0 job proc(s) currently held
12/01/14 11:04:04 Note: 2 total job deferrals because of -MaxJobs limit (1)
12/01/14 11:04:04 Initializing logfile C:\condor_tests\./job_dagman_abort-B.dag.nodes.log, 26, 0, 0
12/01/14 11:04:09 Unable to get log file from submit file job_dagman_abort-B-node-fail.cmd (node D); using default (C:\condor_tests\./job_dagman_abort-B.dag.nodes.log)
12/01/14 11:04:09 Submitting Condor Node D job(s)...
12/01/14 11:04:09 submitting: condor_submit -a dag_node_name' '=' 'D -a +DAGManJobId' '=' '23 -a DAGManJobId' '=' '23 -a submit_event_notes' '=' 'DAG' 'Node:' 'D -a log' '=' 'C:\condor_tests\./job_dagman_abort-B.dag.nodes.log -a log_xml' '=' 'False -a nodename' '=' 'D -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"B" -a notification' '=' 'never job_dagman_abort-B-node-fail.cmd
12/01/14 11:04:09 From submit: Submitting job(s).
12/01/14 11:04:09 From submit: 1 job(s) submitted to cluster 27.
12/01/14 11:04:09 	assigned Condor ID (27.0.0)
12/01/14 11:04:09 Just submitted 1 job this cycle...
12/01/14 11:04:09 Currently monitoring 1 Condor log file(s)
12/01/14 11:04:09 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node C (26.0.0)
12/01/14 11:04:09 POST Script of Node C failed with status 5
12/01/14 11:04:09 POST for Node C returned 5
12/01/14 11:04:09 Aborting DAG because we got the ABORT exit value from a POST script
12/01/14 11:04:09 Aborting DAG...
12/01/14 11:04:09 Writing Rescue DAG to job_dagman_abort-B.dag.rescue001...
12/01/14 11:04:09 Removing submitted jobs...
12/01/14 11:04:09 Removing any/all submitted Condor/Stork jobs...
12/01/14 11:04:09 Running: condor_rm -const DAGManJobId' '=?=' '23
12/01/14 11:04:09 Warning: failure: condor_rm -const DAGManJobId' '=?=' '23
12/01/14 11:04:09 	(my_pclose() returned 1 (errno 2, No such file or directory))
12/01/14 11:04:09 ERROR: Warning is fatal error because of DAGMAN_USE_STRICT setting
12/01/14 11:04:09 Error removing DAGMan jobs
12/01/14 11:04:09 Note: 2 total job deferrals because of -MaxJobs limit (1)
12/01/14 11:04:09 Note: 0 total job deferrals because of -MaxIdle limit (0)
12/01/14 11:04:09 Note: 0 total job deferrals because of node category throttles
12/01/14 11:04:09 Note: 0 total PRE script deferrals because of -MaxPre limit (0)
12/01/14 11:04:09 Note: 0 total POST script deferrals because of -MaxPost limit (0)
12/01/14 11:04:09 Of 4 nodes total:
12/01/14 11:04:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
12/01/14 11:04:09   ===     ===      ===     ===     ===        ===      ===
12/01/14 11:04:09     2       0        1       0       0          0        1
12/01/14 11:04:09 0 job proc(s) currently held
12/01/14 11:04:09 Note: 2 total job deferrals because of -MaxJobs limit (1)
12/01/14 11:04:09 Wrote metrics file job_dagman_abort-B.dag.metrics.
12/01/14 11:04:09 Metrics reporting is not available on this platform.
12/01/14 11:04:09 Warning: ReadMultipleUserLogs destructor called, but still monitoring 1 log(s)!
12/01/14 11:04:09 **** condor_scheduniv_exec.23.0 (condor_DAGMAN) pid 86308 EXITING WITH STATUS 1
