{"id": 2159, "title": "Ticket #2159: Various daemons are bypassing dprintf for access to the log file", "description": "<blockquote>\nDagman and the amazon/ec2 gahp are directly manipulating the FILE pointer for the log file, bypassing dprintf.  With the change that allows daemons to keep their log files open instead of opening and closing on every write, there does not exist a singular FILE pointer.  There is instead an array, due to the fact that dprintf needs to support the ability to route its output to multiple files.  As such, dagman and gahp both need a solution to achieve whatever it is they needed direct access to the FILE pointer for in the first case.</blockquote>", "remarks": "<blockquote>\n<em>2011-May-18 10:48:26 by ziliang:</em> <br/>\n\ncondor_amazon and EC2 gahp implementation of redirecting output had a broken design.  They attempted to change the file pointer out from under dprintf, except dprintf would go and reopen the file every time regardless, so it would overwrite the file pointer the gahp tried to sneak in.  The gahp also tried to default output to stderr, which was already happening in dprintf itself if it did not find a file to output to.  I can conceivably think of a way to do this correctly, but will refrain from implementing it until such time as someone actually wants it, since passing a log file to the gahp never worked in the first place.\n\n<p></p><hr/>\n<em>2011-Jun-01 11:39:34 by jfrey:</em> <br/>\n\nI believe the situation in the amazon_gahp and ec2_gahp resulted from a half-successful attempt to remove all dependencies on Condor libraries. Calls to param() are done in the gridmanager passed to the gahps via the environment or command line. But dprintf() is still used to write to a log file. As long as they are using dprintf(), I see no reason from them not to consult the config file for the value of AMAZON_GAHP_LOG to determine which, if any, log file to write to. Since the subsystem is set to 'amazon_gahp' already, I don't think any special calls are required.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2011-May-19 10:10</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/5d8197c107d1c9b8e3d1efe33a7f966c4fc8ed32\">[21913]</a></span>: Enable enough of the broken functionality in the gahp to pass tests but not interfere with dprintf rewrite. Ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2159\" onclick=\"get_ticket_and_populate_wrapper('2159'); return false;\" title=\"Various daemons are bypassing dprintf for access to the log file\">#2159</a></span>.  (By Ziliang Guo )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2011-May-18 10:43</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/f048dc789eac4f29e1f06e0453b70215744ae76e\">[21886]</a></span>: Remove ability to redirect log file in EC2 and condor_amazon gahp. It never worked in the first place. Ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=2159\" onclick=\"get_ticket_and_populate_wrapper('2159'); return false;\" title=\"Various daemons are bypassing dprintf for access to the log file\">#2159</a></span>.  (By Ziliang Guo )</td></tr>\n</tbody></table>", "type": "defect", "last_change": "2011-Jun-01 11:39", "status": "resolved", "created": "2011-May-13 16:37", "fixed_version": "2011-May-13 16:37", "broken_version": "v070400", "priority": "3", "subsystem": "Daemons", "assigned_to": "ziliang", "derived_from": "#2064", "creator": "ziliang", "rust": "", "customer_group": "other", "visibility": "public", "notify": "tstclair@redhat.com", "due_date": ""}