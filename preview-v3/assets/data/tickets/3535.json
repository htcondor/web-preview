{"id": 3535, "title": "Ticket #3535: Fetching user priorities from negotiator takes a long time", "description": "<blockquote>\n<strong>Resolved/abandoned as user priorities are now fetched from the collector</strong>\n\n<p>Fetching user priorities from negotiator takes a long time; at times it has appeared that the negotiator waits for the end of a (potentially long) negotiation cycle until responding to a request to fetch user priority information.  The end result to the user is often <code>condor_userprio</code> or <code>condor_q -analyze:priority</code> commands take a really long time to respond, or on a busy pool could timeout.\n\n</p><p>SamF will investigate what is going on here and report back to ToddT, since ToddT's recollection is at least at one point in the past the negotiator invoked daemon core's <code>ServiceCommandSocket()</code> method periodically while doing negotiation specifically to avoid the above situation.\n\n</p><p><em>Please refrain from remarks/comments on this ticket for a few days until SamF's initial investigation is done.  Thanks! -ToddT</em></p></blockquote>", "remarks": "<blockquote>\n<em>2013-Mar-21 14:01:12 by samf:</em> <br/>\n\n<code>condor_userprio</code> (or possibly <code>condor_q -analyze:priority</code>) takes a long time to run. We found that it hangs when the listening socket corresponding to the initial command socket (<code>initial_command_socket</code> or DC Command Handler) finds that there is an incoming command, spawns a new socket to read data, and then there is no data to read on the new socket. When there is data to read from the new socket, the data is read and the initial command finishes. In the case where the command hangs, the command <code>DaemonCommandProtocol::WaitForSocketData</code> gets called, the socket gets registered, and the socket is not listened to by the negotiator until after the end of the negotiation cycle; therefore, the command will not be run until after the end of a negotiation cycle. Currently, <code>DaemonCore::ServiceCommandSocket</code> does not listen to any socket other than the initial command socket. If the command for some reason does not finish, it will not finish until after the negotiation cycle.\n\n<p>I also have a design document that I will probably post soon.\n\n</p><p></p><hr/>\n<em>2013-Mar-22 16:11:16 by samf:</em> <br/>\n\nI've attached a patch. Some differences from the design doc are that I need to call <code>CallSocketHandler_worker</code> instead of calling <code>HandleReq</code> directly. This will then call the handlers for a registered socket. Also, if the socket needs to be removed from <code>sockTable</code>, <code>CallSocketHandler_worker</code> will do that. One caveat is that I also need to make sure to exit the do/while loop in <code>ServiceCommandSocket</code> prematurely if the socket has been removed as otherwise an <code>EXCEPT</code> will be thrown unnecessarily.\n\n<p></p><hr/>\n<em>2013-Mar-22 23:38:53 by bbockelm:</em> <br/>\n\nHi,\n\n<p>Did you ever get the chance to attached the design doc?\n\n</p><p>Brian\n\n</p><p></p><hr/>\n<em>2013-Mar-25 09:04:09 by samf:</em> <br/>\n\nHow I reproduced the problem. First, I submitted a larger number (10000) jobs to make the negotiator take a long time.\n\n<p>Submit File:\n</p><div class=\"code\">\n<pre class=\"code\">universe = vanilla\nexecutable = /bin/sleep\ngetenv=true\narguments = 30\n\nshould_transfer_files = yes\nwhen_to_transfer_output = on_exit_or_evict\n\noutput = o\nerror  = e\nlog    = l\n\n+NEGOTIATE_ALL_JOBS_IN_CLUSTER = True\n\nqueue 10000\n</pre></div>\n\n\n<p>I think <code>+NEGOTIATE_ALL_JOBS_IN_CLUSTER = True</code> in the submit file didn't do the trick. So I changed my local condor config file. Settings that I have in my <code>condor_config.local</code> file:\n</p><div class=\"code\">\n<pre class=\"code\">######################################################################\n# Testing long times for fetching user priorities from negotiatior\n######################################################################\nNEGOTIATE_ALL_JOBS_IN_CLUSTER = True\nNEG_SLEEP = 0\nMAX_NEGOTIATOR_LOG = 1000000000\n</pre></div>\n\nI needed to up the size of my negotiator log for debugging purposes. <code>NEG_SLEEP</code> can be set to a non-zero integer to have the negotiator sleep for that many seconds after each negotiation. I found that when <code>NEG_SLEEP = 1</code> caused the problem to sometimes go away, so I did my testing with <code>NEG_SLEEP = 0</code>.\n\n<p>Initially, I just called <code>condor_userprio</code> many times from the command line. I did see that I would get <code>codnor_userprio</code> to hang doing this. This would happen during the negotiation cycle. When the cycle finished, <code>condor_userprio</code> would finish. In order to call <code>condor_userprio</code> more times and faster than I could do so manually, I created a shell script to call <code>condor_userprio</code>:\n</p><div class=\"code\">\n<pre class=\"code\">#!/bin/sh\nwhile true\ndo\n    date +\"%D %T:%N\"\n    condor_userprio\ndone\n</pre></div>\n\n<code>date</code> will spit out the date and time with nanoseconds. I found I needed about 1/100th of a second resolution to distinguish clearly if <code>condor_userprio</code> was hanging.\n\n<p>I would pipe the result of this script into a file and examine the output of that file continuously to see the freeze.\n\n</p><p>Once the negotiation cycle finished, <code>condor_userprio</code> would not hanging again until another negotiation cycle started.\n\n</p><p></p><hr/>\n<em>2013-Mar-25 09:28:18 by samf:</em> <br/>\n\nTwo problems I ran into when implementing my solution:\n\n<p></p><ol>\n<li>Making sure that I didn't do an infinite loop with the do/while loop in <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ServiceCommandSocket\" title=\"Service Command Socket\">ServiceCommandSocket</a></span>. <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HandleReq\" title=\"Handle Req\">HandleReq</a></span> can return a result not equal to <code>KEEP_STREAM</code>. With the original code when <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HandleReq\" title=\"Handle Req\">HandleReq</a></span> ran working on the socket that had been waiting for data, it would set its variable always_keep_stream to false. Since the stream is supposed to close in this case and we don't close it, the <code>Selector</code> for that stream will keep indicating that there is data to be read. Consequently, <code>selector.has_ready()</code> always returns true and we get an infinite loop. My initial work around was to reset the selector when <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HandleReq\" title=\"Handle Req\">HandleReq</a></span> returned a value not equal to <code>KEEP_STREAM</code>. That would cause the loop to break.\n\n<p></p></li><li>As indicated in the previous point, the steam/socket should be closed under some circumstances. To reduced code duplication and also to use the handlers associated with <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=WaitForSocketData\" title=\"Wait For Socket Data\">WaitForSocketData</a></span>, I switched from <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HandleReq\" title=\"Handle Req\">HandleReq</a></span> to <code>DaemonCore::CallSocketHandler_worker</code> which calls both <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HandleReq\" title=\"Handle Req\">HandleReq</a></span> and <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=CheckPrivState\" title=\"Check Priv State\">CheckPrivState</a></span>. It also calls Cancel_Socket appropriately. I just need to give CallSocketHandler_worker the correct parameters to emulate the original call to <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=HandleReq\" title=\"Handle Req\">HandleReq</a></span>. In the case where a socket has been cancelled, I need a way to exit the loop so that an EXCEPT is called (causing the negotiator to crash) when evaluating <code>selector.failed()</code>. We do expect a failure to occur when <code>select</code> is called while examining the recently closed socket. To exit the loop, I used the conditions that <code>Register_Socket</code> uses to check to see if a slot is empty or available; if those conditions returned ture, then I call <code>selector.execute()</code> to change the state of the <code>selector</code> to exit the loop.\n</li></ol>\n\n<p></p><hr/>\n<em>2013-Apr-10 14:16:13 by tannenba:</em> <br/>\n\n<strong>Code Review</strong>\n\n<p></p><ol>\n<li>Calling <code>selector.execute()</code> on a potentially undefined descriptor (or even worse, on a descriptor that has been reused) to break out of loop seems dangerous. Break out of the loop a different way, ie. use another variable.\n\n<p></p></li><li>Doing a string compare on the handler.descrip as a string constant is not a great idea, since someone could change the descrip elsewhere in the code and surprisingly break something.  Either make this string a constant defined in one place, or even better, add a data member to the sockTable entry that says if DC is waiting for data.\n\n<p></p></li><li>Confirm that the socket is not waiting for an outgoing connect when deciding to select on it or not.  I.e., make sure <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=SockEnt\" title=\"Sock Ent\">SockEnt</a></span> <code>is_connect_pending</code> is false.\n\n<p></p></li><li>Add a comment explaining why you are iterating with one socket being passed to select() vs placing lots of sockets into the select fd set and calling select once.  Perhaps it is because the set of fds could change every time you call a handler?\n\n<p></p></li><li>Why invoke <code>CallSocketHandler_worker()</code> vs <code>CallSocketHandler()</code> ? please place a comment telling future hackers why this choice was made.  Perhaps because you want the handler to be called in this same thread?\n\n<p></p></li><li>Add a knob (no need to document it) to disable <code>ServiceCommandSocket()</code> all together.  By default, <code>ServiceCommandSocket()</code> should do its thing, but having this knob will give us a safety net in the field (since it is a bit dangerous thing at least until the Future Work happens).\n</li></ol>\n\n<p><strong>Test Plan</strong>\n\n</p><p>Please confirm (via remarks with console captures in the ticket, or even better via regression test) by doing a before and after test for:\n\n</p><p></p><ol>\n<li>Confirm condor_userprio waits until end of negotiation cycle before patch, and responds immediately after patch -- and negotiator continues to operate correctly afterwards :).\n\n<p></p></li><li>Confirm that \"condor_off -fast\" waits until end of negotiation cycle before patch, and responds immediately after patch.\n\n<p></p></li><li>Confirm that both issuing a \"condor_reconfig\" or sending a SIGHUP waits until end of negotiation cycle both before and after patch, because iirc RH added code to make this always true and we want to make sure we didn't muck that up.\n</li></ol>\n\n<p><strong>Future Work</strong>\n\n</p><p>Would really like to see a list of daemon_core command ints passed to <code>ServiceCommandSocket()</code>.  We know that it is unlikely for every command to be safe to be handled this way, so the idea is the caller pass an explicit whitelist of safe command ints.  Probably would require adding a data member to the <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=SockEnt\" title=\"Sock Ent\">SockEnt</a></span> which contains the command int (once it is discovered), and any socket with command that does not match the white list is simply registered and thus the handler is not invoked until going back to the main daemoncore driver loop.\n\n</p><p></p><hr/>\n<em>2013-Apr-16 12:23:46 by samf:</em> <br/>\n\nResponding to the code review.\n\n<p></p><ol>\n<li>Sounds reasonable. Using <code>break</code> command to exit loop.\n\n<p></p></li><li>Had to make class <code>DaemonCommandProtocol</code> have <code>friend class DaemonCore;</code> (in theory). Then, adding to <code>SockEnt</code> the parameter <code>bool waiting_for_data</code>. This already will get initialized to false. We then set this to true in the function <code>Register_Socket</code>.\n\n<p></p></li><li>Adding another condition on the non-initial command socket. Easy.\n\n<p></p></li><li>The original code in <code>ServiceCommandSocket</code> has a do-while loop that selects on the initial command socket. There is a comment in the code that says, \"loop until no more commands waiting on socket\". While we are servicing a socket, more data could have come in and need to be read. So at least for the initial command socket, we need to call select multiple times. In such a case, we would need to confirm after each time we find that the selector is ready to ready data if the current socket we are examining is ready to be read by using <code>selector.fd_ready(i,Selector::IO_READ)</code> where <code>i</code> is the current socket index. We know that we will have to do this in the case where we have the initial command socket having a new command and another socket waiting for data. <code>selector.has_ready()</code> will return true. I do not see how this results in any fewer system calls. I also see this making the code harder to read because the loop will need to contain code to ask if the particular socket still has data to read.\n\n<p></p></li><li><code>CallSocketHandler()</code> when called on the initial command socket will perform an <code>accept</code> on the socket, which seems to be the desired behavior during the main <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=DaemonCore\" title=\"Daemon Core\">DaemonCore</a></span> loop. I don't think we want this behavior in <code>ServiceCommandSocket</code> and so we need to call the worker version. However, <code>CallSocketHandler()</code> does have a way to control the maximum number of accepts per cycle.\n<div class=\"code\">\n<pre class=\"code\">m_iMaxAcceptsPerCycle = param_integer(\"MAX_ACCEPTS_PER_CYCLE\", 8);\n</pre></div>\n\n\n<p></p></li><li>Added.\n</li></ol>\n\n<p></p><hr/>\n<em>2013-Apr-16 15:14:09 by samf:</em> <br/>\n\nCode Review Remark:\n\n<p>Point 4: Actually, I <strong>DO</strong> expect the list of fds to change. When we call a command that had previously been waiting for socket data, the socket will be removed from the list of registered sockets. I then will be later on possibly still be performing select on that fd. In which case, to ensure that <code>selector.execute()</code> does not go into the <code>FAILED</code> state, I would need to remove the fd from the selector. In order to accommodate this and deal with the fact <code>selector.fd_ready</code> needs cannot accommodate a non ready state, I see more reason to iterate through each socket via the selector rather than use the <code>fd_ready</code> command. I cannot use <code>FD_ISSET</code> directly because I don't have access to the read filters, and nor do I want to be maintaining this filter either.\n\n</p><p></p><hr/>\n<em>2013-Apr-16 15:56:43 by samf:</em> <br/>\n\nRegarding Future Work:\n\n<p>In the class <code>DaemonCommandProtocol</code> (defined in <code>daemon_command.h</code>), there are three integers in:\n\n</p><p></p><ol>\n<li><code>m_req</code> Comment says: the command that was sent\n</li><li><code>m_real_cmd</code> Comment says: for DC_AUTHENTICATE, the final command to execute\n</li><li><code>m_auth_cmd</code> Comment says: for DC_AUTHENTICATE, the command the security session will be used for\n</li></ol>\n\n<p><code>daemonCore-&gt;CommandNumToTableIndex(m_real_cmd,&amp;cmd_index)</code> is how we get the command integer. We could use the commnad <code>daemonCore::InServiceCommandSocket</code> to determine if we're in <code>ServiceCommandSocket</code>. To create a whitelist, this would be in <code>daemonCore::HandleReq</code> just before <code>doProtocol</code> gets called or somewhere in  <code>DaemonCommandProtocol::ExecCommand()</code>. We'd ask if we were indeed in <code>ServceCommandSocket</code> and if the <code>cmd_index</code> was on our white list, then we'd continue on. Otherwise, <code>ExecCommand()</code> should return <code>CommandProtocolInProgress</code>.\n\n</p><p>It's not perfect, but it's a start down this path.\n\n</p><p></p><hr/>\n<em>2013-Apr-16 16:39:38 by samf:</em> <br/>\n\nIn terms of the test plan,\n\n<p></p><ol>\n<li>condor_userprio can wait until the end of the negotiation cycle without the patch and does not wait with the patch. There is a knob that controls the implementation status of the patch.\n\n<p></p></li><li>condor_off -fast seems to finish before the negotiation cycle finishes even without the patch. This is good, yes? I suspect there is some condition I'm not properly testing.\n\n<p></p></li><li>condor_reconfig and sending a SIGHUP both indeed wait until the end of the negotiation cycle.\n</li></ol>\n\n<p></p><hr/>\n<em>2013-Apr-16 18:39:59 by samf:</em> <br/>\n\nThere's a lot more code to use when using multiple fds. Also, <code>CallSocketHandler()</code> actually seems to work, so we're using that now instead of <code>CallSocketHandler_worker()</code>.\n\n<p></p><hr/>\n<em>2013-May-10 10:54:27 by tannenba:</em> <br/>\n\nI noticed that v7.9.6 is now running on the UW CHTC central manager in beta testing, and condor_userprio still seems slow to respond; please investigate/explain. Thanks.\n\n<p>Also re test plan, I asked for \"remarks <em>with console captures in the ticket</em>, or even better via regression test\".  I see a remark on the testing, but it does not include console captures showing the explicit config/commands used such that someone could reproduce the test - for an example of this see <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=3255\" onclick=\"get_ticket_and_populate_wrapper('3255'); return false;\" title=\"Implement JobPrioArray and JobPrioArrayOverflow attrs in submitter ad\">#3255</a></span> or <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=2905\" onclick=\"get_ticket_and_populate_wrapper('2905'); return false;\" title=\"RFE: adding local resource limits to partionable slots\">#2905</a></span>.  When can this (or even better a regression test) happen?\n\n</p><p></p><hr/>\n<em>2013-May-10 13:58:17 by samf:</em> <br/>\n\nI just pulled the code from the 7.9.6 branch, built it, and condor_userprio does not take a long time for me. Can you explain what you did to replicate it taking a long time?\n\n<p>I have a code called <code>infinite_loop_condor_userprio.sh</code>\n</p><div class=\"code\">\n<pre class=\"code\">#!/bin/sh\nwhile true\ndo\n    date +\"%D %T:%N\"\n    condor_userprio\ndone\n</pre></div>\n\n\n<p>Results:\n</p><div class=\"code\">\n<pre class=\"code\">[samf@beaver] (33)$ ./infinite_loop_condor_userprio.sh &gt;&gt; userprio.log &amp;\n[1] 30986\n[samf@beaver] (34)$ less userprio.log\n</pre></div>\n\n\n<p>From <code>userprio.log</code>\n</p><div class=\"code\">\n<pre class=\"code\">05/10/13 13:38:44:671421054\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n05/10/13 13:38:44:771128507\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n05/10/13 13:38:44:880943321\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n05/10/13 13:38:44:998899321\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n05/10/13 13:38:45:073858036\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n05/10/13 13:38:45:183104445\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n05/10/13 13:38:45:292801859\nLast Priority Update:  5/10 13:38\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.51      1.00     16      9972.85    0+00:06\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9972.85    0+23:59\n</pre></div>\n\n\n<p>From <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=NegotiatorLog\" title=\"Negotiator Log\">NegotiatorLog</a></span>\n</p><div class=\"code\">\n<pre class=\"code\">05/10/13 13:38:44     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:44     Request 00158.03197:\n05/10/13 13:38:44 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:44       Rejected 158.3197 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:44 Getting state information from the accountant\n05/10/13 13:38:44     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:44     Getting reply from schedd ...\n05/10/13 13:38:44     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:44     Request 00158.03198:\n05/10/13 13:38:44 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:44       Rejected 158.3198 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:44 Getting state information from the accountant\n05/10/13 13:38:44     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:44     Getting reply from schedd ...\n05/10/13 13:38:44     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:44     Request 00158.03199:\n05/10/13 13:38:44 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:44       Rejected 158.3199 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:44 Getting state information from the accountant\n05/10/13 13:38:44     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:44     Getting reply from schedd ...\n05/10/13 13:38:44     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:44     Request 00158.03200:\n05/10/13 13:38:44 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:44       Rejected 158.3200 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:44 Getting state information from the accountant\n05/10/13 13:38:44     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:44     Getting reply from schedd ...\n05/10/13 13:38:44     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:44     Request 00158.03201:\n05/10/13 13:38:44 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:44       Rejected 158.3201 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:44 Getting state information from the accountant\n05/10/13 13:38:44     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:44     Getting reply from schedd ...\n05/10/13 13:38:44     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:44     Request 00158.03202:\n05/10/13 13:38:44 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:44       Rejected 158.3202 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:44 Getting state information from the accountant\n05/10/13 13:38:44     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:44     Getting reply from schedd ...\n05/10/13 13:38:45     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:45     Request 00158.03203:\n05/10/13 13:38:45 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:45       Rejected 158.3203 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:45 Getting state information from the accountant\n05/10/13 13:38:45     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:45     Getting reply from schedd ...\n05/10/13 13:38:45     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:45     Request 00158.03204:\n05/10/13 13:38:45 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:45       Rejected 158.3204 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n05/10/13 13:38:45 Getting state information from the accountant\n05/10/13 13:38:45     Sending SEND_JOB_INFO/eom\n05/10/13 13:38:45     Getting reply from schedd ...\n05/10/13 13:38:45     Got JOB_INFO command; getting classad/eom\n05/10/13 13:38:45     Request 00158.03205:\n05/10/13 13:38:45 matchmakingAlgorithm: limit 16.000000 used 16.000000 pieLeft 0.000000\n05/10/13 13:38:45       Rejected 158.3205 samf@beaver.cs.wisc.edu &lt;128.105.14.140:48414&gt;: no match found\n</pre></div>\n\n\n<p>In the Negotiator Log, I can see lines that say: <code>Getting state information from the accountant</code>. This is the line that gets printed in the Negotiator Log when condor_userprio returns successfully.\n\n</p><p>For my condor_config file:\n</p><div class=\"code\">\n<pre class=\"code\">######################################################################\n# Testing long times for fetching user priorities from negotiatior\n######################################################################\nNEGOTIATE_ALL_JOBS_IN_CLUSTER = True\nNEG_SLEEP = 0\nMAX_NEGOTIATOR_LOG = 1000000000\n#SERVICE_COMMAND_SOCKET_MAX_SOCKET_INDEX = 0\n</pre></div>\n\n\n<p>For a full console capture:\n</p><div class=\"code\">\n<pre class=\"code\">[samf@beaver] (89)$ condor_submit test/vanilla_universe/sleep.csf\nSubmitting job(s)................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n10000 job(s) submitted to cluster 176.\n[samf@beaver] (90)$ ./infinite_loop_condor_userprio.sh &gt;&gt; userprio.log &amp;\n[1] 15123\n[samf@beaver] (91)$ less log/NegotiatorLog\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9920 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09921:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9921 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09922:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9922 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09923:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9923 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09924:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9924 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09925:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9925 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09926:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n05/10/13 13:53:25 Attempting to use cached MatchList: Failed (MatchList length: 0, Autocluster: 1, Schedd Name: samf@beaver.cs.wisc.edu, Schedd Address: &lt;128.105.14.140:56435&gt;)\n05/10/13 13:53:25       Rejected 176.9926 samf@beaver.cs.wisc.edu &lt;128.105.14.140:56435&gt;: no match found\n05/10/13 13:53:25     Sending SEND_JOB_INFO/eom\n05/10/13 13:53:25     Getting reply from schedd ...\n05/10/13 13:53:25     Got JOB_INFO command; getting classad/eom\n05/10/13 13:53:25     Request 00176.09927:\n05/10/13 13:53:25 matchmakingAlgorithm: limit 0.000000 used 0.000000 pieLeft 0.000000\n\n[samf@beaver] (92)$ less userprio.log\nLast Priority Update:  5/10 13:53\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.57      1.00     16      9975.05      &lt;now&gt;\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9975.05    0+23:59\n05/10/13 13:53:25:214431575\nLast Priority Update:  5/10 13:53\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.57      1.00     16      9975.05      &lt;now&gt;\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9975.05    0+23:59\n05/10/13 13:53:25:235404549\nLast Priority Update:  5/10 13:53\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.57      1.00     16      9975.05      &lt;now&gt;\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9975.05    0+23:59\n05/10/13 13:53:25:255897275\nLast Priority Update:  5/10 13:53\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.57      1.00     16      9975.05      &lt;now&gt;\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9975.05    0+23:59\n05/10/13 13:53:25:276407720\nLast Priority Update:  5/10 13:53\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.57      1.00     16      9975.05      &lt;now&gt;\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9975.05    0+23:59\n05/10/13 13:53:25:296921960\nLast Priority Update:  5/10 13:53\n                         Effective   Priority   Res   Total Usage  Time Since\nUser Name                 Priority    Factor   In Use (wghted-hrs) Last Usage\n----------------------- ------------ --------- ------ ------------ ----------\nsamf@beaver.cs.wisc.edu         0.57      1.00     16      9975.05      &lt;now&gt;\n----------------------- ------------ --------- ------ ------------ ----------\nNumber of users: 1                                 16      9975.05    0+23:59\n05/10/13 13:53:25:320388447\n</pre></div>\n\n\n<p></p><hr/>\n<em>2013-May-24 16:26:43 by samf:</em> <br/>\n\nI've confirmed that when used on the main CHTC pool, <code>condor_userprio</code> still takes a long time. Next week, I plan on figuring out why it takes so long using GDB.\n\n<p></p><hr/>\n<em>2013-Jun-14 14:12:08 by samf:</em> <br/>\n\nI have had a lot of trouble attaching gdb to the <code>condor_negotiator</code>. What I do know is that on the cm, the negotiator enters <span class=\"wiki\"><a class=\"missing\" href=\"wiki?p=ServceCommandSocket\" title=\"Servce Command Socket\">ServceCommandSocket</a></span>, creates a Selector::selector (because of the print statement associated with Selector::reset commamnd), and then exits via one of the following return statements. If it didn't exit, we would expect to see more print statements associated with the Selector::add_fd command.</blockquote>", "derived_tickets": "", "attachments": "<html><head></head><body><blockquote>\n<ul>\n<li><a href=\"../files/710/0001-Ticket-3535.-Changed-ServiceCommandSocket-to-loop-ov.patch\">0001-Ticket-3535.-Changed-ServiceCommandSocket-to-loop-ov.patch</a>\n4204 bytes added by samf on 2013-Mar-22 21:00:33 UTC.\n<br/>\nProposed patch to <code>DaemonCore::ServiceCommandSocket()</code> in \"src/condor_daemon_core.V6/daemon_core.cpp\"<br/>\n</li><li><a href=\"../files/711/ServiceCommandSocket+Proposal.doc\">ServiceCommandSocket Proposal.doc</a>\n22016 bytes added by samf on 2013-Mar-25 14:05:20 UTC.\n<br/>\nDesign document for the fix. There was another slight change that I had to make that is not in the design doc, but is in the ticket.<br/>\n</li></ul>\n</blockquote></body></html>", "check_ins": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n<tbody><tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-19 12:49</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/16e5b578ab4a5126350f556c4f7f851f60d72758\">[35463]</a></span>: edit 7.9.6 version history item for <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=3535\" onclick=\"get_ticket_and_populate_wrapper('3535'); return false;\" title=\"Fetching user priorities from negotiator takes a long time\">#3535</a></span>  (By Karen Miller )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-17 15:38</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/1ac69ffa37496be79438209939dc131735711255\">[35444]</a></span>: Updating Version History file for Tickets <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=3535\" onclick=\"get_ticket_and_populate_wrapper('3535'); return false;\" title=\"Fetching user priorities from negotiator takes a long time\">#3535</a></span> and <span class=\"ticket\"><a class=\"defer\" href=\"/wiki-archive/tickets/?ticket=3390\" onclick=\"get_ticket_and_populate_wrapper('3390'); return false;\" title=\"MPI Parallel Universe jobs fail when USE_NFS=True - Developer Series\">#3390</a></span>.  (By Samuel Friedman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-16 18:48</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/f69bef4cea13dbc8bd5d26188f6b56102c3a964b\">[35434]</a></span>: Ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=3535\" onclick=\"get_ticket_and_populate_wrapper('3535'); return false;\" title=\"Fetching user priorities from negotiator takes a long time\">#3535</a></span>. Accidentially removed a comment in last commit. Readding it.  (By Samuel Friedman )</td></tr>\n<tr><td align=\"right\" valign=\"top\" width=\"160\">2013-Apr-16 18:40</td>\n<td align=\"center\" valign=\"top\" width=\"30\">\n<span class=\"icon dot\">\u00a0</span></td>\n<td align=\"left\" valign=\"top\"> \nCheck-in <span class=\"chng\"><a href=\"https://github.com/htcondor/htcondor/commit/800eb6cd5a3265e30d9786384d415b73c80ea1cf\">[35432]</a></span>: Ticket <span class=\"ticket\"><a class=\"resolved\" href=\"/wiki-archive/tickets/?ticket=3535\" onclick=\"get_ticket_and_populate_wrapper('3535'); return false;\" title=\"Fetching user priorities from negotiator takes a long time\">#3535</a></span>. Patch to fix long times when fetching user priorities from the negotiator. ===VersionHistory:Pending===  (By Samuel Friedman )</td></tr>\n</tbody></table>", "type": "enhance", "last_change": "2020-Aug-22 10:29", "status": "resolved", "created": "2013-Mar-11 15:02", "fixed_version": "2013-Mar-11 15:02", "broken_version": "v070806", "priority": "2", "subsystem": "Daemons", "assigned_to": "tannenba", "derived_from": "", "creator": "tannenba", "rust": "", "customer_group": "chtc", "visibility": "public", "notify": "tannenba@cs.wisc.edu, samf@cs.wisc.edu", "due_date": "20130314"}